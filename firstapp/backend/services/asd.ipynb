{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import START, MessagesState, StateGraph\n",
    "from task_utils import get_secret\n",
    "from openai import OpenAI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'SecretList': [{'ARN': 'arn:aws:secretsmanager:us-east-1:730335414940:secret:doai/openai/1015-tZkxgY', 'Name': 'doai/openai/1015', 'LastChangedDate': datetime.datetime(2025, 4, 30, 18, 53, 27, 622000, tzinfo=tzlocal()), 'LastAccessedDate': datetime.datetime(2025, 6, 28, 8, 0, tzinfo=tzlocal()), 'Tags': [], 'SecretVersionsToStages': {'4341c63f-4884-4c31-acce-c8c4ca95f5f8': ['AWSPREVIOUS'], 'e03510ea-71ac-44bf-b5d0-d9f81e55d534': ['AWSCURRENT']}, 'CreatedDate': datetime.datetime(2024, 10, 16, 14, 48, 50, 150000, tzinfo=tzlocal())}], 'ResponseMetadata': {'RequestId': '36ed15f2-43fb-4863-bd66-e8c755580db7', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': '36ed15f2-43fb-4863-bd66-e8c755580db7', 'content-type': 'application/x-amz-json-1.1', 'content-length': '371', 'date': 'Sat, 28 Jun 2025 07:57:49 GMT'}, 'RetryAttempts': 0}}\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import os\n",
    "\n",
    "os.environ[\"http_proxy\"] = \"http://127.0.0.1:7897\"\n",
    "os.environ[\"https_proxy\"] = \"http://127.0.0.1:7897\"\n",
    "\n",
    "client = boto3.client(\"secretsmanager\", region_name=\"us-east-1\")\n",
    "response = client.list_secrets()\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "asd workflow step completion guide\n",
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import aiohttp\n",
    "from typing import TypedDict\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin, urlparse\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import os\n",
    "from task_utils import get_secret\n",
    "\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")  # Efficient embedding model\n",
    "api_key = get_secret()\n",
    "os.environ[\"OPENAI_API_KEY\"] = api_key\n",
    "\n",
    "def get_subpages_from_homepage(url, max_links=10):\n",
    "    \"\"\"\n",
    "    Scrape subpage URLs from homepage by checking navbars and sitemap links.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        homepage = requests.get(url, timeout=5)\n",
    "        homepage.raise_for_status()\n",
    "        soup = BeautifulSoup(homepage.text, \"html.parser\")\n",
    "\n",
    "        links = set()\n",
    "\n",
    "        # 1. Try finding sitemap\n",
    "        sitemap_url = urljoin(url, \"/sitemap.xml\")\n",
    "        try:\n",
    "            sitemap = requests.get(sitemap_url, timeout=3)\n",
    "            if sitemap.status_code == 200:\n",
    "                sitemap_soup = BeautifulSoup(sitemap.text, \"xml\")\n",
    "                for loc in sitemap_soup.find_all(\"loc\"):\n",
    "                    links.add(loc.text)\n",
    "        except:\n",
    "            pass  # Fall back to navbar scraping\n",
    "\n",
    "        # 2. If no sitemap or to enrich, parse <a> tags in nav/menu\n",
    "        for tag in soup.find_all(\"a\", href=True):\n",
    "            href = tag[\"href\"]\n",
    "            full_url = urljoin(url, href)\n",
    "            if urlparse(full_url).netloc == urlparse(url).netloc:\n",
    "                links.add(full_url)\n",
    "\n",
    "        return list(links)[:max_links]\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Subpage scraping failed for {url}: {e}\")\n",
    "        return []\n",
    "\n",
    "def get_favicon(url):\n",
    "    \"\"\"Fetch the favicon URL from a website.\"\"\"\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        if response.status_code == 200:\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "            favicon_url = None\n",
    "            for link in soup.find_all('link', rel=['icon', 'shortcut icon', 'apple-touch-icon']):\n",
    "                favicon_url = link.get('href')\n",
    "                if favicon_url:\n",
    "                    break\n",
    "            \n",
    "            if favicon_url:\n",
    "                return urljoin(url, favicon_url)  # Ensure the favicon URL is absolute\n",
    "            else:\n",
    "                return None\n",
    "        else:\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "def similarity_score(query, search):\n",
    "    \"\"\"\n",
    "    Performs similarity search between a prompt and text partitions.\n",
    "\n",
    "    Args:\n",
    "        prompt (str): The search query.\n",
    "        partitions (list of str): List of partitioned text.\n",
    "        threshold (float): Minimum similarity score for filtering.\n",
    "\n",
    "    Returns:\n",
    "        list: Relevant partitions with similarity scores.\n",
    "    \"\"\"\n",
    "    # Generate embeddings\n",
    "    prompt_embedding = [model.encode(query)]\n",
    "    partition_embeddings = [model.encode(search)]\n",
    "    # print(prompt_embedding.shape, partition_embeddings.shape)\n",
    "\n",
    "\n",
    "    # Compute cosine similarity\n",
    "    similarity = cosine_similarity(prompt_embedding, partition_embeddings)\n",
    "\n",
    "    # Sort by relevance (descending similarity)\n",
    "    # filtered_partitions.sort(key=lambda x: x[\"score\"], reverse=True)\n",
    "\n",
    "    return similarity\n",
    "\n",
    "class SearchState(TypedDict):\n",
    "    step_name: str\n",
    "    workflow_structure: str\n",
    "    query: str\n",
    "\n",
    "\n",
    "# --- Query Generation Chain ---\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0.4)\n",
    "\n",
    "query_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are an expert researcher who crafts precise Google search queries.\"),\n",
    "    (\"user\", \n",
    "     \"\"\"Given the current workflow structure:\n",
    "{workflow_structure}\n",
    "\n",
    "And the current step:\n",
    "{step_name}\n",
    "\n",
    "Craft the best possible Google search query that would help someone find relevant information to complete the step in this workflow. Be specific, and assume the searcher is looking for practical resources or documentation. Reply with ONLY the query string.\"\"\")\n",
    "])\n",
    "\n",
    "query_chain = query_prompt | llm | StrOutputParser()\n",
    "\n",
    "def call_google_search_api(step, context):\n",
    "    \"\"\"\n",
    "    Calls the Google Search API to retrieve search results and also includes the website favicon.\n",
    "    Args:\n",
    "        query (str): The search query.\n",
    "    Returns:\n",
    "        dict: A dictionary containing evidence or an error message, including favicons.\n",
    "    \"\"\"\n",
    "    query = get_query(step, context)[1:-1]\n",
    "    print(query)\n",
    "    api_key = \"AIzaSyDYO5BSod8opzI20moUfGLfcYO1ez1vMQU\"\n",
    "    search_engine_id = \"c5297ee11db07449c\"  # Replace with your custom search engine ID\n",
    "    base_url = \"https://www.googleapis.com/customsearch/v1\"\n",
    "\n",
    "    params = {\"key\": api_key, \"cx\": search_engine_id, \"q\": query}\n",
    "\n",
    "    try:\n",
    "        response = requests.get(base_url, params=params)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "\n",
    "        if \"items\" not in data:\n",
    "            return {\"success\": False, \"error\": \"No results found.\"}\n",
    "\n",
    "        results = []\n",
    "        all_items = []\n",
    "\n",
    "        # Step 1: Process top search results\n",
    "        for item in data[\"items\"]:\n",
    "            print(1)\n",
    "            title = item.get(\"title\")\n",
    "            link = item.get(\"link\")\n",
    "            snippet = item.get(\"snippet\")\n",
    "            # favicon = get_favicon(link)\n",
    "            score = similarity_score(query, title)\n",
    "            all_items.append({\n",
    "                \"title\": title, \"link\": link, \"snippet\": snippet,\n",
    "                \"favicon\": 0, \"score\": float(score[0][0])\n",
    "            })\n",
    "            print(2)\n",
    "            if len(all_items)>8:\n",
    "                break\n",
    "\n",
    "        # Step 2: Scrape subpages of top 3 items\n",
    "        # for top_result in all_items[:3]:\n",
    "        #     subpages = get_subpages_from_homepage(top_result[\"link\"], max_links=10)\n",
    "        #     print(subpages)\n",
    "        #     for subpage in subpages:\n",
    "        #         sub_favicon = get_favicon(subpage)\n",
    "        #         sub_score = similarity_score(query, subpage)\n",
    "        #         all_items.append({\n",
    "        #             \"title\": subpage,  # No title, so using URL\n",
    "        #             \"link\": subpage,\n",
    "        #             \"snippet\": \"Subpage of \" + top_result[\"link\"],\n",
    "        #             \"favicon\": sub_favicon,\n",
    "        #             \"score\": float(sub_score[0][0])\n",
    "        #         })\n",
    "\n",
    "        # Step 3: Sort and return top 5\n",
    "        top_results = sorted(all_items, key=lambda x: x[\"score\"], reverse=True)[:8]\n",
    "        return {\"success\": True, \"evidence\": top_results}\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        return {\"success\": False, \"error\": str(e)}\n",
    "\n",
    "def get_query(step, context):\n",
    "\n",
    "    def generate_query_node(state: SearchState) -> SearchState:\n",
    "        query = query_chain.invoke({\n",
    "            \"workflow_structure\": state[\"workflow_structure\"],\n",
    "            \"step_name\": state[\"step_name\"]\n",
    "        })\n",
    "        return {\n",
    "            \"step_name\": state[\"step_name\"],\n",
    "            \"workflow_structure\": state[\"workflow_structure\"],\n",
    "            \"query\": query\n",
    "        }\n",
    "\n",
    "    # Build the LangGraph\n",
    "    graph = StateGraph(SearchState)\n",
    "    graph.add_node(\"generate_query\", RunnableLambda(generate_query_node))\n",
    "    graph.set_entry_point(\"generate_query\")\n",
    "    graph.add_edge(\"generate_query\", END)\n",
    "\n",
    "    app = graph.compile()\n",
    "\n",
    "    # --- Example Run ---\n",
    "    input_data = {\n",
    "        \"step_name\": step,\n",
    "        \"workflow_structure\": context,\n",
    "    }\n",
    "    result = app.invoke(input_data)\n",
    "    return result['query']\n",
    "\n",
    "A = call_google_search_api(\"asd\", \"asd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name = \"test0713\"\n",
    "if not pc.has_index(index_name):\n",
    "    pc.create_index_for_model(\n",
    "        name=index_name,\n",
    "        cloud=\"aws\",\n",
    "        region=\"us-east-1\",\n",
    "        embed={\n",
    "            \"model\":\"llama-text-embed-v2\",\n",
    "            \"field_map\":{\"text\": \"chunk_text\"}\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "PineconeApiException",
     "evalue": "(400)\nReason: Bad Request\nHTTP response headers: HTTPHeaderDict({'Date': 'Sun, 13 Jul 2025 05:45:54 GMT', 'Content-Type': 'text/plain; charset=utf-8', 'Content-Length': '116', 'Connection': 'keep-alive', 'x-envoy-upstream-service-time': '32', 'server': 'envoy'})\nHTTP response body: {\"error\":{\"code\":\"INVALID_ARGUMENT\",\"message\":\"Integrated inference is not configured for this index\"},\"status\":400}\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPineconeApiException\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[51], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m hashid \u001b[38;5;241m=\u001b[39m hashlib\u001b[38;5;241m.\u001b[39msha256(evidence\u001b[38;5;241m.\u001b[39mencode())\u001b[38;5;241m.\u001b[39mhexdigest()\n\u001b[1;32m      6\u001b[0m index \u001b[38;5;241m=\u001b[39m pc\u001b[38;5;241m.\u001b[39mIndex(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest0711\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# Locate index hax\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupsert_records\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnamespace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mhashid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mchunk_text\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mevidence\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pinecone/data/index.py:207\u001b[0m, in \u001b[0;36mIndex.upsert_records\u001b[0;34m(self, namespace, records)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupsert_records\u001b[39m(\u001b[38;5;28mself\u001b[39m, namespace: \u001b[38;5;28mstr\u001b[39m, records: List[Dict]):\n\u001b[1;32m    206\u001b[0m     args \u001b[38;5;241m=\u001b[39m IndexRequestFactory\u001b[38;5;241m.\u001b[39mupsert_records_args(namespace\u001b[38;5;241m=\u001b[39mnamespace, records\u001b[38;5;241m=\u001b[39mrecords)\n\u001b[0;32m--> 207\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_vector_api\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupsert_records_namespace\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pinecone/openapi_support/endpoint.py:102\u001b[0m, in \u001b[0;36mEndpoint.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     92\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"This method is invoked when endpoints are called\u001b[39;00m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;124;03m    Example:\u001b[39;00m\n\u001b[1;32m     94\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    100\u001b[0m \n\u001b[1;32m    101\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcallable\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pinecone/core/openapi/db_data/api/vector_operations_api.py:606\u001b[0m, in \u001b[0;36mVectorOperationsApi.__init__.<locals>.__upsert_records_namespace\u001b[0;34m(self, namespace, upsert_record, **kwargs)\u001b[0m\n\u001b[1;32m    604\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnamespace\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m namespace\n\u001b[1;32m    605\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mupsert_record\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m upsert_record\n\u001b[0;32m--> 606\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_with_http_info\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pinecone/openapi_support/endpoint.py:134\u001b[0m, in \u001b[0;36mEndpoint.call_with_http_info\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    124\u001b[0m params \u001b[38;5;241m=\u001b[39m EndpointUtils\u001b[38;5;241m.\u001b[39mgather_params(\n\u001b[1;32m    125\u001b[0m     attribute_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattribute_map,\n\u001b[1;32m    126\u001b[0m     location_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlocation_map,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    129\u001b[0m     kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[1;32m    130\u001b[0m )\n\u001b[1;32m    132\u001b[0m HeaderUtil\u001b[38;5;241m.\u001b[39mprepare_headers(headers_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mheaders_map, params\u001b[38;5;241m=\u001b[39mparams)\n\u001b[0;32m--> 134\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapi_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_api\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msettings\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mendpoint_path\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msettings\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhttp_method\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    137\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpath\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquery_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mquery\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    139\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheader_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mheader\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbody\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpost_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mform\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiles\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfile\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    143\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msettings\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_type\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauth_settings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msettings\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mauth\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    145\u001b[0m \u001b[43m    \u001b[49m\u001b[43masync_req\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43masync_req\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[43m    \u001b[49m\u001b[43masync_threadpool_executor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43masync_threadpool_executor\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_check_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m_check_return_type\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_return_http_data_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m_return_http_data_only\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_preload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m_preload_content\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_request_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m_request_timeout\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_host\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    152\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcollection_formats\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcollection_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    153\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pinecone/openapi_support/api_client.py:300\u001b[0m, in \u001b[0;36mApiClient.call_api\u001b[0;34m(self, resource_path, method, path_params, query_params, header_params, body, post_params, files, response_type, auth_settings, async_req, async_threadpool_executor, _return_http_data_only, collection_formats, _preload_content, _request_timeout, _host, _check_type)\u001b[0m\n\u001b[1;32m    279\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mthreadpool_executor\u001b[38;5;241m.\u001b[39msubmit(\n\u001b[1;32m    280\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__call_api,\n\u001b[1;32m    281\u001b[0m         resource_path,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    296\u001b[0m         _check_type,\n\u001b[1;32m    297\u001b[0m     )\n\u001b[1;32m    299\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m async_req:\n\u001b[0;32m--> 300\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__call_api\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    301\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresource_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    302\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    303\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    304\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    305\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheader_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    306\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    307\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpost_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    308\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfiles\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    309\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresponse_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    310\u001b[0m \u001b[43m        \u001b[49m\u001b[43mauth_settings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_return_http_data_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcollection_formats\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_preload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_request_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_host\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_check_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool\u001b[38;5;241m.\u001b[39mapply_async(\n\u001b[1;32m    320\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__call_api,\n\u001b[1;32m    321\u001b[0m     (\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    338\u001b[0m     ),\n\u001b[1;32m    339\u001b[0m )\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pinecone/openapi_support/api_client.py:178\u001b[0m, in \u001b[0;36mApiClient.__call_api\u001b[0;34m(self, resource_path, method, path_params, query_params, header_params, body, post_params, files, response_type, auth_settings, _return_http_data_only, collection_formats, _preload_content, _request_timeout, _host, _check_type)\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m PineconeApiException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    177\u001b[0m     e\u001b[38;5;241m.\u001b[39mbody \u001b[38;5;241m=\u001b[39m e\u001b[38;5;241m.\u001b[39mbody\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 178\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    180\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_response \u001b[38;5;241m=\u001b[39m response_data\n\u001b[1;32m    182\u001b[0m return_data \u001b[38;5;241m=\u001b[39m response_data\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pinecone/openapi_support/api_client.py:166\u001b[0m, in \u001b[0;36mApiClient.__call_api\u001b[0;34m(self, resource_path, method, path_params, query_params, header_params, body, post_params, files, response_type, auth_settings, _return_http_data_only, collection_formats, _preload_content, _request_timeout, _host, _check_type)\u001b[0m\n\u001b[1;32m    157\u001b[0m url \u001b[38;5;241m=\u001b[39m build_request_url(\n\u001b[1;32m    158\u001b[0m     config\u001b[38;5;241m=\u001b[39mconfig,\n\u001b[1;32m    159\u001b[0m     processed_path_params\u001b[38;5;241m=\u001b[39mpath_params_tuple,\n\u001b[1;32m    160\u001b[0m     resource_path\u001b[38;5;241m=\u001b[39mresource_path,\n\u001b[1;32m    161\u001b[0m     _host\u001b[38;5;241m=\u001b[39m_host,\n\u001b[1;32m    162\u001b[0m )\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;66;03m# perform request and return response\u001b[39;00m\n\u001b[0;32m--> 166\u001b[0m     response_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprocessed_query_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders_tuple\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpost_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprocessed_post_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_preload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_preload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_request_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_request_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m PineconeApiException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    177\u001b[0m     e\u001b[38;5;241m.\u001b[39mbody \u001b[38;5;241m=\u001b[39m e\u001b[38;5;241m.\u001b[39mbody\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pinecone/openapi_support/api_client.py:380\u001b[0m, in \u001b[0;36mApiClient.request\u001b[0;34m(self, method, url, query_params, headers, post_params, body, _preload_content, _request_timeout)\u001b[0m\n\u001b[1;32m    370\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrest_client\u001b[38;5;241m.\u001b[39mOPTIONS(\n\u001b[1;32m    371\u001b[0m         url,\n\u001b[1;32m    372\u001b[0m         query_params\u001b[38;5;241m=\u001b[39mquery_params,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    377\u001b[0m         body\u001b[38;5;241m=\u001b[39mbody,\n\u001b[1;32m    378\u001b[0m     )\n\u001b[1;32m    379\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPOST\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 380\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrest_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPOST\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    381\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    383\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    384\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpost_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpost_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    385\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_preload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_preload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    386\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_request_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_request_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    387\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    388\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    389\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPUT\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    390\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrest_client\u001b[38;5;241m.\u001b[39mPUT(\n\u001b[1;32m    391\u001b[0m         url,\n\u001b[1;32m    392\u001b[0m         query_params\u001b[38;5;241m=\u001b[39mquery_params,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    397\u001b[0m         body\u001b[38;5;241m=\u001b[39mbody,\n\u001b[1;32m    398\u001b[0m     )\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pinecone/openapi_support/rest_utils.py:146\u001b[0m, in \u001b[0;36mRestClientInterface.POST\u001b[0;34m(self, url, headers, query_params, post_params, body, _preload_content, _request_timeout)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mPOST\u001b[39m(\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    138\u001b[0m     url,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    144\u001b[0m     _request_timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    145\u001b[0m ):\n\u001b[0;32m--> 146\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPOST\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpost_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpost_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    152\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_preload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_preload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    153\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_request_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_request_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pinecone/openapi_support/rest_urllib3.py:260\u001b[0m, in \u001b[0;36mUrllib3RestClient.request\u001b[0;34m(self, method, url, query_params, headers, body, post_params, _preload_content, _request_timeout)\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[38;5;66;03m# log response body\u001b[39;00m\n\u001b[1;32m    258\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse body: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, r\u001b[38;5;241m.\u001b[39mdata)\n\u001b[0;32m--> 260\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mraise_exceptions_or_return\u001b[49m\u001b[43m(\u001b[49m\u001b[43mr\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pinecone/openapi_support/rest_utils.py:49\u001b[0m, in \u001b[0;36mraise_exceptions_or_return\u001b[0;34m(r)\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;241m500\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m r\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m599\u001b[39m:\n\u001b[1;32m     47\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ServiceException(http_resp\u001b[38;5;241m=\u001b[39mr)\n\u001b[0;32m---> 49\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PineconeApiException(http_resp\u001b[38;5;241m=\u001b[39mr)\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m r\n",
      "\u001b[0;31mPineconeApiException\u001b[0m: (400)\nReason: Bad Request\nHTTP response headers: HTTPHeaderDict({'Date': 'Sun, 13 Jul 2025 05:45:54 GMT', 'Content-Type': 'text/plain; charset=utf-8', 'Content-Length': '116', 'Connection': 'keep-alive', 'x-envoy-upstream-service-time': '32', 'server': 'envoy'})\nHTTP response body: {\"error\":{\"code\":\"INVALID_ARGUMENT\",\"message\":\"Integrated inference is not configured for this index\"},\"status\":400}\n"
     ]
    }
   ],
   "source": [
    "import hashlib\n",
    "\n",
    "namespace = f\"{userid}-{workflowid}\"\n",
    "evidence = \"AAA\"\n",
    "hashid = hashlib.sha256(evidence.encode()).hexdigest()\n",
    "index = pc.Index(\"test0711\")  # Locate index hax\n",
    "\n",
    "index.upsert_records(\n",
    "    namespace,\n",
    "    [\n",
    "        {\n",
    "            \"_id\": hashid,\n",
    "            \"chunk_text\": evidence,\n",
    "        }\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Index stats: {'dimension': 1024,\n",
      " 'index_fullness': 0.0,\n",
      " 'metric': 'cosine',\n",
      " 'namespaces': {'114214507913166948561-a884d54b-685f-46d7-b630-4437261e9d48': {'vector_count': 5}},\n",
      " 'total_vector_count': 5,\n",
      " 'vector_type': 'dense'}\n"
     ]
    }
   ],
   "source": [
    "pinecone_api_key = \"pcsk_37QAFP_MpCRebPKKbDM3D3wUbqFFK78jtP25cDEYexXxoEcw8U8PyMy5YEGfU8p13Y7Yqp\"\n",
    "pc = Pinecone(api_key=pinecone_api_key)\n",
    "index_description = pc.describe_index(\"test0713\")\n",
    "index = pc.Index(\"test0713\")  # Locate index hax\n",
    "userid = \"114214507913166948561\"\n",
    "workflowid = \"a884d54b-685f-46d7-b630-4437261e9d48\"\n",
    "namespace = f\"{userid}-{workflowid}\"\n",
    "stats = index.describe_index_stats()\n",
    "print(\"📊 Index stats:\", stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Several templates—adaptable guides for healthy eat- ing—have been developed that show how Americans can put these principles into action: the USDA Food Patterns, lacto-ovo vegetarian or vegan adaptations of the USDA Food Patterns, and the DASH72 Eating Plan. These templates translate and integrate dietary recommendations into an overall healthy way to eat. They identify average daily amounts of foods, in nutrient-dense forms, to eat from all food groups and include limits for some dietary components. Consumers, professionals, and organizations can make use of these templates to plan healthy eating patterns or assess food and beverage choices. Key Recommendations 6HOHFW\\x03DQ\\x03HDWLQJ\\x03SDWWHUQ\\x03WKDW\\x03PHHWV\\x03QXWULHQW\\x03 QHHGV\\x03RYHU\\x03WLPH\\x03DW\\x03DQ\\x03DSSURSULDWH\\x03FDORULH\\x03OHYHO\\x11\\x03 $FFRXQW\\x03IRU\\x03DOO\\x03IRRGV\\x03DQG\\x03EHYHUDJHV\\x03 FRQVXPHG\\x03DQG\\x03DVVHVV\\x03KRZ\\x03WKH\\\\\\x03ILW\\x03ZLWKLQ\\x03D\\x03 WRWDO\\x03KHDOWK\\\\\\x03HDWLQJ\\x03SDWWHUQ\\x11\\x03 )ROORZ\\x03IRRG\\x03VDIHW\\\\\\x03UHFRPPHQGDWLRQV\\x03ZKHQ\\x03 SUHSDULQJ\\x03DQG\\x03HDWLQJ\\x03IRRGV\\x03WR\\x03UHGXFH\\x03WKH\\x03 ULVN\\x03RI\\x03IRRGERUQH\\x03LOOQHVVHV\\x11\\x03 71. Dietary Guidelines for Americans, 2010 uses the term “eating pattern,” rather than the term “total diet” (the term used in the 2010 DGAC report), to refer to the combination of foods and beverages that constitute an individual’s complete dietary intake over time. The term “diet” may be misconstrued as an eating pattern intended for weight loss. 72. Dietary Approaches to Stop Hypertension. DIETARY GUIDELINES FOR AMERICANS, 2010 | Chapter Five RESEARCH INFORMS US ABOUT HEALTHY EATING PATTERNS Around the world and within the United States, people make strikingly different food choices and have differ- ent diet-related health outcomes. Although the study of eating patterns is complex, evidence from interna- tional scientiﬁc research has identiﬁed various eating patterns that may provide short- and long-term health beneﬁts, including a reduced risk of chronic disease. Many traditional eating patterns can provide health beneﬁts, and their variety demonstrates that people can eat healthfully in a number of ways. Several types of research studies have been con- ducted on these eating patterns, including clinical trials and prospective studies that measure speciﬁc health outcomes or health-related risk factors, and observational studies of traditional eating patterns.',\n",
       " 'However, a number of Federal ofﬁces were involved in the development of the Plan. DIETARY GUIDELINES FOR AMERICANS, 2010 | Chapter Six 59 Appendices Appendix 1 Guidance for Speciﬁc Population Groups Appendix 2 Key Consumer Behaviors and Potential Strategies for Professionals to Use in Implementing the 2010 Dietary Guidelines Appendix 3 Food Safety Principles and Guidance for Consumers Appendix 4 Using the Food Label to Track Calories, Nutrients, and Ingredients Appendix 5 Nutritional Goals for Age-Gender Groups, Based on Dietary Reference Intakes and Dietary Guidelines Recommendations Appendix 6 Estimated Calorie Needs per Day by Age, Gender, and Physical Activity Level (Detailed) Appendix 7 USDA Food Patterns Appendix 8 Lacto-ovo Vegetarian Adaptation of the USDA Food Patterns Appendix 9 Vegan Adaptation of the USDA Food Patterns Appendix 10 The DASH Eating Plan at Various Calorie Levels Appendix 11 Estimated EPA and DHA and Mercury Content in 4 Ounces of Selected Seafood Varieties Appendix 12 Selected Food Sources Ranked by Amounts of Potassium and Calories per Standard Food Portion Appendix 13 Selected Food Sources Ranked by Amounts of Dietary Fiber and Calories per Standard Food Portion Appendix 14 Selected Food Sources Ranked by Amounts of Calcium and Calories per Standard Food Portion Appendix 15 Selected Food Sources Ranked by Amounts of Vitamin D and Calories per Standard Food Portion Appendix 16 Glossary of Terms DIETARY GUIDELINES FOR AMERICANS, 2010 60 61 DIETARY GUIDELINES FOR AMERICANS, 2010 APPENDIX 1. GUIDANCE FOR SPECIFIC POPULATION GROUPS The Dietary Guidelines for Americans, 2010 is intended for Americans ages 2 years and older, including those who are at increased risk of chronic disease. Topic areas that provide additional guidance for speciﬁc population groups are listed below along with the chapter and page number where the information can be found. Topic Area Children and Adolescents Chapter Page No.',\n",
       " \"Research Education Research Education Appointments at Mayo Clinic Mayo Clinic offers appointments in Arizona, Florida and Minnesota and at Mayo Clinic Health System locations. Nutrition and healthy eating Vegetarian diet: How to get the best nutrition A well-planned vegetarian diet is a healthy way to meet your nutritional needs. Find out what you need to know about a plant-based diet. Vegetarian diets continue to increase in popularity. Reasons for following a vegetarian diet vary but include health benefits. Following a vegetarian diet may reduce the risk of heart disease, diabetes and some cancers. But some vegetarian diets may rely too heavily on processed foods with too many calories, and too much sugar, fat and salt. These diets may not include enough fruits, vegetables, whole grains and nutrient-rich foods. With planning, a vegetarian diet can meet the needs of people of all ages, as well as people who are pregnant or breastfeeding. The key is to be aware of your nutritional needs so that you plan a diet that meets them. Types of vegetarian diets Vegetarian diets vary in what foods they include and exclude: Some people follow a diet that is mostly plant-based, but they still eat meat, dairy, eggs, poultry and fish on occasion or in small quantities. This is sometimes called a flexitarian diet. Planning a healthy vegetarian diet To get the most out of a vegetarian diet, choose a variety of healthy plant-based foods. These include whole fruits and vegetables and whole grains. Nuts and legumes, such as lentils, beans and peanuts, also are considered healthy plant-based foods. At the same time, cut back on less healthy choices. These include sugar-sweetened beverages, fruit juices and refined grains. A registered dietitian can help you create a vegetarian plan that's right for you.\",\n",
       " \"For this reason, it's important for vegans to consider vitamin supplements, vitamin-enriched cereals and fortified soy products. Protein Protein helps keep skin, bones, muscles and organs healthy. Eggs and dairy products are good sources, and you don't need to eat large amounts to meet your protein needs. Eating a variety of plant-based foods throughout the day also can provide enough protein. Plant sources include soy products and meat substitutes, legumes, lentils, nuts, seeds, and whole grains. Omega-3 fatty acids Omega-3 fatty acids are found in fish, canola oil, soy oil, walnuts, ground flaxseed and soybeans. Vegetarian diets that do not include fish may be low in two types of omega-3 fatty acids called DHA and EPA. Some evidence suggests that taking in EPA and DHA omega-3 fatty acids may lower the risk for heart disease. Also, these two omega-3s may be important during pregnancy for fetal development. Research on other health effects of EPA and DHA varies. Vegetarians who do not eat fish or include sources of omega-3 fatty acids in their diet may consider adding fortified products to their diet. Iron and zinc Iron is important to red blood cells. Dried beans and peas, lentils, enriched cereals, whole-grain products, dark leafy green vegetables, and dried fruit are sources of iron. But the body doesn't absorb iron from plant sources as easily as animal sources. So the recommended intake of iron for vegetarians is almost double that recommended for nonvegetarians. To help your body absorb iron from plants, eat foods rich in vitamin C at the same time as you're eating iron-containing foods. Vitamin C-rich foods include peppers, strawberries, citrus fruits, tomatoes, cabbage and broccoli. Like iron, zinc is not as easily absorbed from plant sources as it is from animal products.\",\n",
       " \"Fish, including crab and shrimp, are sources of zinc for pescatarians. Cheese and yogurt are sources of zinc if you eat dairy products. Plant sources include whole grains, soy products, lentils, beans, nuts and wheat germ. Zinc helps the body make proteins and grow cells. Research on zinc in the diet has found that it supports the immune system and vision, specifically. Iodine Thyroid hormones are made partly of iodine. Thyroid hormones help control the body's metabolism and play an important role in muscle growth. Iodine can easily be added to food by using iodized salt. Seafood and dairy also are sources of iodine. People who do not eat seafood or dairy may be at risk of iodine deficiency if they do not use iodized salt. Iodine deficiency can lead to the thyroid getting bigger as it tries to meet the body's need for thyroid hormones. When that happens to the thyroid it's called goiter. Seaweed is vegetarian option for dietary iodine. Getting started One way to start on a vegetarian diet is to slowly reduce the meat in your diet. At the same time, increase the amount of fruits and vegetables in your diet. Here are a few tips to help you get started: There is a problem with information submitted for this request. Review/update the information highlighted below and resubmit the form. From Mayo Clinic to your inbox Sign up for free and stay up to date on research advancements, health tips, current health topics, and expertise on managing health. Click here for an email preview. ErrorEmail field is required ErrorInclude a valid email address We use the data you provide to deliver you the content you requested.\"]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"Verify collected recipes against dietary guidelines\"\n",
    "dense_index = pc.Index(\"test0713\")  # Locate index hax\n",
    "\n",
    "# Search the dense index\n",
    "results = dense_index.search(\n",
    "    namespace=f\"{userid}-{workflowid}\",\n",
    "    query={\n",
    "        \"top_k\": 10,\n",
    "        \"inputs\": {\n",
    "            'text': query\n",
    "        }\n",
    "    }\n",
    ")\n",
    "[hit['fields']['chunk_text'] for hit in results['result']['hits']]\n",
    "# Print the results\n",
    "# for hit in results['result']['hits']:\n",
    "#         print(f\"id: {hit['_id']:<5} | score: {round(hit['_score'], 2):<5} | text: {hit['fields']['chunk_text']:<50}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Index stats: {'dimension': 1024,\n",
      " 'index_fullness': 0.0,\n",
      " 'metric': 'cosine',\n",
      " 'namespaces': {'114214507913166948561-72dd6f31-a97e-4605-835f-22947f44f853': {'vector_count': 1}},\n",
      " 'total_vector_count': 1,\n",
      " 'vector_type': 'dense'}\n"
     ]
    },
    {
     "ename": "PineconeApiException",
     "evalue": "(400)\nReason: Bad Request\nHTTP response headers: HTTPHeaderDict({'Date': 'Sat, 12 Jul 2025 09:30:44 GMT', 'Content-Type': 'application/json', 'Content-Length': '104', 'Connection': 'keep-alive', 'x-pinecone-request-latency-ms': '15', 'x-pinecone-request-id': '4034052298567691213', 'x-envoy-upstream-service-time': '1', 'server': 'envoy'})\nHTTP response body: {\"code\":3,\"message\":\"Vector dimension 1536 does not match the dimension of the index 1024\",\"details\":[]}\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPineconeApiException\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[48], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m stats \u001b[38;5;241m=\u001b[39m index\u001b[38;5;241m.\u001b[39mdescribe_index_stats()\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m📊 Index stats:\u001b[39m\u001b[38;5;124m\"\u001b[39m, stats)\n\u001b[0;32m---> 13\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnamespace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnamespace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvector\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0.0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1536\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# dummy vector to trigger return\u001b[39;49;00m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43minclude_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m     18\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m🔎 Documents in namespace \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnamespace\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m match \u001b[38;5;129;01min\u001b[39;00m res[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmatches\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pinecone/utils/error_handling.py:11\u001b[0m, in \u001b[0;36mvalidate_and_convert_errors.<locals>.inner_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner_func\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 11\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m MaxRetryError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     13\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e\u001b[38;5;241m.\u001b[39mreason, ProtocolError):\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pinecone/data/index.py:274\u001b[0m, in \u001b[0;36mIndex.query\u001b[0;34m(self, top_k, vector, id, namespace, filter, include_values, include_metadata, sparse_vector, *args, **kwargs)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;129m@validate_and_convert_errors\u001b[39m\n\u001b[1;32m    261\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mquery\u001b[39m(\n\u001b[1;32m    262\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    272\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    273\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[QueryResponse, ApplyResult]:\n\u001b[0;32m--> 274\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_query\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    276\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtop_k\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    277\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvector\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvector\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    278\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mid\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mid\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    279\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnamespace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnamespace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    280\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mfilter\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mfilter\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    281\u001b[0m \u001b[43m        \u001b[49m\u001b[43minclude_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    282\u001b[0m \u001b[43m        \u001b[49m\u001b[43minclude_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    283\u001b[0m \u001b[43m        \u001b[49m\u001b[43msparse_vector\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msparse_vector\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    285\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124masync_req\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;129;01mor\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124masync_threadpool_executor\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pinecone/data/index.py:324\u001b[0m, in \u001b[0;36mIndex._query\u001b[0;34m(self, top_k, vector, id, namespace, filter, include_values, include_metadata, sparse_vector, *args, **kwargs)\u001b[0m\n\u001b[1;32m    311\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_k must be a positive integer\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    313\u001b[0m request \u001b[38;5;241m=\u001b[39m IndexRequestFactory\u001b[38;5;241m.\u001b[39mquery_request(\n\u001b[1;32m    314\u001b[0m     top_k\u001b[38;5;241m=\u001b[39mtop_k,\n\u001b[1;32m    315\u001b[0m     vector\u001b[38;5;241m=\u001b[39mvector,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    323\u001b[0m )\n\u001b[0;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_vector_api\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery_vectors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_openapi_kwargs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pinecone/openapi_support/endpoint.py:102\u001b[0m, in \u001b[0;36mEndpoint.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     92\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"This method is invoked when endpoints are called\u001b[39;00m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;124;03m    Example:\u001b[39;00m\n\u001b[1;32m     94\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    100\u001b[0m \n\u001b[1;32m    101\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcallable\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pinecone/core/openapi/db_data/api/vector_operations_api.py:388\u001b[0m, in \u001b[0;36mVectorOperationsApi.__init__.<locals>.__query_vectors\u001b[0;34m(self, query_request, **kwargs)\u001b[0m\n\u001b[1;32m    386\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_openapi_kwargs(kwargs)\n\u001b[1;32m    387\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquery_request\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m query_request\n\u001b[0;32m--> 388\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_with_http_info\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pinecone/openapi_support/endpoint.py:134\u001b[0m, in \u001b[0;36mEndpoint.call_with_http_info\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    124\u001b[0m params \u001b[38;5;241m=\u001b[39m EndpointUtils\u001b[38;5;241m.\u001b[39mgather_params(\n\u001b[1;32m    125\u001b[0m     attribute_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattribute_map,\n\u001b[1;32m    126\u001b[0m     location_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlocation_map,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    129\u001b[0m     kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[1;32m    130\u001b[0m )\n\u001b[1;32m    132\u001b[0m HeaderUtil\u001b[38;5;241m.\u001b[39mprepare_headers(headers_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mheaders_map, params\u001b[38;5;241m=\u001b[39mparams)\n\u001b[0;32m--> 134\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapi_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_api\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msettings\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mendpoint_path\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msettings\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhttp_method\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    137\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpath\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquery_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mquery\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    139\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheader_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mheader\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbody\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpost_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mform\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiles\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfile\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    143\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msettings\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_type\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauth_settings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msettings\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mauth\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    145\u001b[0m \u001b[43m    \u001b[49m\u001b[43masync_req\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43masync_req\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[43m    \u001b[49m\u001b[43masync_threadpool_executor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43masync_threadpool_executor\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_check_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m_check_return_type\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_return_http_data_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m_return_http_data_only\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_preload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m_preload_content\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_request_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m_request_timeout\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_host\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    152\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcollection_formats\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcollection_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    153\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pinecone/openapi_support/api_client.py:300\u001b[0m, in \u001b[0;36mApiClient.call_api\u001b[0;34m(self, resource_path, method, path_params, query_params, header_params, body, post_params, files, response_type, auth_settings, async_req, async_threadpool_executor, _return_http_data_only, collection_formats, _preload_content, _request_timeout, _host, _check_type)\u001b[0m\n\u001b[1;32m    279\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mthreadpool_executor\u001b[38;5;241m.\u001b[39msubmit(\n\u001b[1;32m    280\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__call_api,\n\u001b[1;32m    281\u001b[0m         resource_path,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    296\u001b[0m         _check_type,\n\u001b[1;32m    297\u001b[0m     )\n\u001b[1;32m    299\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m async_req:\n\u001b[0;32m--> 300\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__call_api\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    301\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresource_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    302\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    303\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    304\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    305\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheader_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    306\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    307\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpost_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    308\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfiles\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    309\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresponse_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    310\u001b[0m \u001b[43m        \u001b[49m\u001b[43mauth_settings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_return_http_data_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcollection_formats\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_preload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_request_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_host\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_check_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool\u001b[38;5;241m.\u001b[39mapply_async(\n\u001b[1;32m    320\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__call_api,\n\u001b[1;32m    321\u001b[0m     (\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    338\u001b[0m     ),\n\u001b[1;32m    339\u001b[0m )\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pinecone/openapi_support/api_client.py:178\u001b[0m, in \u001b[0;36mApiClient.__call_api\u001b[0;34m(self, resource_path, method, path_params, query_params, header_params, body, post_params, files, response_type, auth_settings, _return_http_data_only, collection_formats, _preload_content, _request_timeout, _host, _check_type)\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m PineconeApiException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    177\u001b[0m     e\u001b[38;5;241m.\u001b[39mbody \u001b[38;5;241m=\u001b[39m e\u001b[38;5;241m.\u001b[39mbody\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 178\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    180\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_response \u001b[38;5;241m=\u001b[39m response_data\n\u001b[1;32m    182\u001b[0m return_data \u001b[38;5;241m=\u001b[39m response_data\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pinecone/openapi_support/api_client.py:166\u001b[0m, in \u001b[0;36mApiClient.__call_api\u001b[0;34m(self, resource_path, method, path_params, query_params, header_params, body, post_params, files, response_type, auth_settings, _return_http_data_only, collection_formats, _preload_content, _request_timeout, _host, _check_type)\u001b[0m\n\u001b[1;32m    157\u001b[0m url \u001b[38;5;241m=\u001b[39m build_request_url(\n\u001b[1;32m    158\u001b[0m     config\u001b[38;5;241m=\u001b[39mconfig,\n\u001b[1;32m    159\u001b[0m     processed_path_params\u001b[38;5;241m=\u001b[39mpath_params_tuple,\n\u001b[1;32m    160\u001b[0m     resource_path\u001b[38;5;241m=\u001b[39mresource_path,\n\u001b[1;32m    161\u001b[0m     _host\u001b[38;5;241m=\u001b[39m_host,\n\u001b[1;32m    162\u001b[0m )\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;66;03m# perform request and return response\u001b[39;00m\n\u001b[0;32m--> 166\u001b[0m     response_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprocessed_query_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders_tuple\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpost_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprocessed_post_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_preload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_preload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_request_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_request_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m PineconeApiException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    177\u001b[0m     e\u001b[38;5;241m.\u001b[39mbody \u001b[38;5;241m=\u001b[39m e\u001b[38;5;241m.\u001b[39mbody\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pinecone/openapi_support/api_client.py:380\u001b[0m, in \u001b[0;36mApiClient.request\u001b[0;34m(self, method, url, query_params, headers, post_params, body, _preload_content, _request_timeout)\u001b[0m\n\u001b[1;32m    370\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrest_client\u001b[38;5;241m.\u001b[39mOPTIONS(\n\u001b[1;32m    371\u001b[0m         url,\n\u001b[1;32m    372\u001b[0m         query_params\u001b[38;5;241m=\u001b[39mquery_params,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    377\u001b[0m         body\u001b[38;5;241m=\u001b[39mbody,\n\u001b[1;32m    378\u001b[0m     )\n\u001b[1;32m    379\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPOST\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 380\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrest_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPOST\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    381\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    383\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    384\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpost_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpost_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    385\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_preload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_preload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    386\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_request_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_request_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    387\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    388\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    389\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPUT\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    390\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrest_client\u001b[38;5;241m.\u001b[39mPUT(\n\u001b[1;32m    391\u001b[0m         url,\n\u001b[1;32m    392\u001b[0m         query_params\u001b[38;5;241m=\u001b[39mquery_params,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    397\u001b[0m         body\u001b[38;5;241m=\u001b[39mbody,\n\u001b[1;32m    398\u001b[0m     )\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pinecone/openapi_support/rest_utils.py:146\u001b[0m, in \u001b[0;36mRestClientInterface.POST\u001b[0;34m(self, url, headers, query_params, post_params, body, _preload_content, _request_timeout)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mPOST\u001b[39m(\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    138\u001b[0m     url,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    144\u001b[0m     _request_timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    145\u001b[0m ):\n\u001b[0;32m--> 146\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPOST\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpost_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpost_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    152\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_preload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_preload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    153\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_request_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_request_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pinecone/openapi_support/rest_urllib3.py:260\u001b[0m, in \u001b[0;36mUrllib3RestClient.request\u001b[0;34m(self, method, url, query_params, headers, body, post_params, _preload_content, _request_timeout)\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[38;5;66;03m# log response body\u001b[39;00m\n\u001b[1;32m    258\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse body: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, r\u001b[38;5;241m.\u001b[39mdata)\n\u001b[0;32m--> 260\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mraise_exceptions_or_return\u001b[49m\u001b[43m(\u001b[49m\u001b[43mr\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pinecone/openapi_support/rest_utils.py:49\u001b[0m, in \u001b[0;36mraise_exceptions_or_return\u001b[0;34m(r)\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;241m500\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m r\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m599\u001b[39m:\n\u001b[1;32m     47\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ServiceException(http_resp\u001b[38;5;241m=\u001b[39mr)\n\u001b[0;32m---> 49\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PineconeApiException(http_resp\u001b[38;5;241m=\u001b[39mr)\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m r\n",
      "\u001b[0;31mPineconeApiException\u001b[0m: (400)\nReason: Bad Request\nHTTP response headers: HTTPHeaderDict({'Date': 'Sat, 12 Jul 2025 09:30:44 GMT', 'Content-Type': 'application/json', 'Content-Length': '104', 'Connection': 'keep-alive', 'x-pinecone-request-latency-ms': '15', 'x-pinecone-request-id': '4034052298567691213', 'x-envoy-upstream-service-time': '1', 'server': 'envoy'})\nHTTP response body: {\"code\":3,\"message\":\"Vector dimension 1536 does not match the dimension of the index 1024\",\"details\":[]}\n"
     ]
    }
   ],
   "source": [
    "from pinecone import Pinecone, ServerlessSpec\n",
    "\n",
    "pinecone_api_key = \"pcsk_37QAFP_MpCRebPKKbDM3D3wUbqFFK78jtP25cDEYexXxoEcw8U8PyMy5YEGfU8p13Y7Yqp\"\n",
    "pc = Pinecone(api_key=pinecone_api_key)\n",
    "index_description = pc.describe_index(\"test0711\")\n",
    "index = pc.Index(\"quickstart\")  # Locate index hax\n",
    "userid = \"114214507913166948561\"\n",
    "workflowid = \"72dd6f31-a97e-4605-835f-22947f44f853\"\n",
    "namespace = f\"{userid}-{workflowid}\"\n",
    "stats = index.describe_index_stats()\n",
    "print(\"📊 Index stats:\", stats)\n",
    "\n",
    "res = index.query(\n",
    "    namespace=namespace,\n",
    "    vector=[0.0] * 1536,  # dummy vector to trigger return\n",
    "    top_k=10,\n",
    "    include_metadata=True\n",
    ")\n",
    "print(f\"🔎 Documents in namespace {namespace}:\")\n",
    "for match in res[\"matches\"]:\n",
    "    print(match[\"metadata\"].get(\"chunk_text\", \"NO TEXT FOUND\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "{\n",
      "  \"kind\": \"customsearch#search\",\n",
      "  \"url\": {\n",
      "    \"type\": \"application/json\",\n",
      "    \"template\": \"https://www.googleapis.com/customsearch/v1?q={searchTerms}&num={count?}&start={startIndex?}&lr={language?}&safe={safe?}&cx={cx?}&sort={sort?}&filter={filter?}&gl={gl?}&cr={cr?}&googlehost={googleHost?}&c2coff={disableCnTwTranslation?}&hq={hq?}&hl={hl?}&siteSearch={siteSearch?}&siteSearchFilter={siteSearchFilter?}&exactTerms={exactTerms?}&excludeTerms={excludeTerms?}&linkSite={linkSite?}&orTerms={orTerms?}&dateRestrict={dateRestrict?}&lowRange={lowRange?}&highRange={highRange?}&searchType={searchType}&fileType={fileType?}&rights={rights?}&imgSize={imgSize?}&imgType={imgType?}&imgColorType={imgColorType?}&imgDominantColor={imgDominantColor?}&alt=json\"\n",
      "  },\n",
      "  \"queries\": {\n",
      "    \"request\": [\n",
      "      {\n",
      "        \"title\": \"Google Custom Search - OpenAI\",\n",
      "        \"totalResults\": \"223000000\",\n",
      "        \"searchTerms\": \"OpenAI\",\n",
      "        \"count\": 10,\n",
      "        \"startIndex\": 1,\n",
      "        \"inputEncoding\": \"utf8\",\n",
      "        \"outputEncoding\": \"utf8\",\n",
      "        \"safe\": \"off\",\n",
      "        \"cx\": \"c5297ee11db07449c\"\n",
      "      }\n",
      "    ],\n",
      "    \"nextPage\": [\n",
      "      {\n",
      "        \"title\": \"Google Custom Search - OpenAI\",\n",
      "        \"totalResults\": \"223000000\",\n",
      "        \"searchTerms\": \"OpenAI\",\n",
      "        \"count\": 10,\n",
      "        \"startIndex\": 11,\n",
      "        \"inputEncoding\": \"utf8\",\n",
      "        \"outputEncoding\": \"utf8\",\n",
      "        \"safe\": \"off\",\n",
      "        \"cx\": \"c5297ee11db07449c\"\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  \"context\": {\n",
      "    \"title\": \"doai\"\n",
      "  },\n",
      "  \"searchInformation\": {\n",
      "    \"searchTime\": 0.292323,\n",
      "    \"formattedSearchTime\": \"0.29\",\n",
      "    \"totalResults\": \"223000000\",\n",
      "    \"formattedTotalResults\": \"223,000,000\"\n",
      "  },\n",
      "  \"items\": [\n",
      "    {\n",
      "      \"kind\": \"customsearch#result\",\n",
      "      \"title\": \"OpenAI\",\n",
      "      \"htmlTitle\": \"\\u003cb\\u003eOpenAI\\u003c/b\\u003e\",\n",
      "      \"link\": \"https://openai.com/\",\n",
      "      \"displayLink\": \"openai.com\",\n",
      "      \"snippet\": \"Latest news · Stories · Latest research · OpenAI for business · Get started with ChatGPT. Download. Our Research. Research Index · Research Overview · Research ...\",\n",
      "      \"htmlSnippet\": \"Latest news &middot; Stories &middot; Latest research &middot; \\u003cb\\u003eOpenAI\\u003c/b\\u003e for business &middot; Get started with ChatGPT. Download. Our Research. Research Index &middot; Research Overview &middot; Research&nbsp;...\",\n",
      "      \"formattedUrl\": \"https://openai.com/\",\n",
      "      \"htmlFormattedUrl\": \"https://\\u003cb\\u003eopenai\\u003c/b\\u003e.com/\",\n",
      "      \"pagemap\": {\n",
      "        \"cse_thumbnail\": [\n",
      "          {\n",
      "            \"src\": \"https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQlIDxZGhkQPYuowrZ56KV_0VInKUKS5RrF-AS65uF1Hi0HWGnwQwPf3Tw&s\",\n",
      "            \"width\": \"300\",\n",
      "            \"height\": \"168\"\n",
      "          }\n",
      "        ],\n",
      "        \"metatags\": [\n",
      "          {\n",
      "            \"og:image\": \"https://images.ctfassets.net/kftzwdyauwt9/3KGOHkSXu53naMuSFNaiwv/aa2f914943c839ce6b75b8620a46b340/SEO_Banner_2560x1440_02.png?w=1600&h=900&fit=fill\",\n",
      "            \"og:image:width\": \"1600\",\n",
      "            \"og:type\": \"website\",\n",
      "            \"twitter:card\": \"summary_large_image\",\n",
      "            \"twitter:title\": \"OpenAI\",\n",
      "            \"og:title\": \"OpenAI\",\n",
      "            \"og:image:height\": \"900\",\n",
      "            \"twitter:image:height\": \"900\",\n",
      "            \"og:description\": \"We believe our research will eventually lead to artificial general intelligence, a system that can solve human-level problems. Building safe and beneficial AGI is our mission.\",\n",
      "            \"twitter:image\": \"https://images.ctfassets.net/kftzwdyauwt9/3KGOHkSXu53naMuSFNaiwv/aa2f914943c839ce6b75b8620a46b340/SEO_Banner_2560x1440_02.png?w=1600&h=900&fit=fill\",\n",
      "            \"twitter:site\": \"@OpenAI\",\n",
      "            \"twitter:image:width\": \"1600\",\n",
      "            \"viewport\": \"width=device-width, initial-scale=1\",\n",
      "            \"twitter:description\": \"We believe our research will eventually lead to artificial general intelligence, a system that can solve human-level problems. Building safe and beneficial AGI is our mission.\",\n",
      "            \"og:locale\": \"en-US\"\n",
      "          }\n",
      "        ],\n",
      "        \"cse_image\": [\n",
      "          {\n",
      "            \"src\": \"https://images.ctfassets.net/kftzwdyauwt9/3KGOHkSXu53naMuSFNaiwv/aa2f914943c839ce6b75b8620a46b340/SEO_Banner_2560x1440_02.png?w=1600&h=900&fit=fill\"\n",
      "          }\n",
      "        ]\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"kind\": \"customsearch#result\",\n",
      "      \"title\": \"OpenAI - Wikipedia\",\n",
      "      \"htmlTitle\": \"\\u003cb\\u003eOpenAI\\u003c/b\\u003e - Wikipedia\",\n",
      "      \"link\": \"https://en.wikipedia.org/wiki/OpenAI\",\n",
      "      \"displayLink\": \"en.wikipedia.org\",\n",
      "      \"snippet\": \"Microsoft has invested US$13 billion in OpenAI, and is entitled to 49% of OpenAI Global, LLC's profits, capped at an estimated 10x their investment. ... Microsoft ...\",\n",
      "      \"htmlSnippet\": \"Microsoft has invested US$13 billion in \\u003cb\\u003eOpenAI\\u003c/b\\u003e, and is entitled to 49% of \\u003cb\\u003eOpenAI\\u003c/b\\u003e Global, LLC&#39;s profits, capped at an estimated 10x their investment. ... Microsoft&nbsp;...\",\n",
      "      \"formattedUrl\": \"https://en.wikipedia.org/wiki/OpenAI\",\n",
      "      \"htmlFormattedUrl\": \"https://en.wikipedia.org/wiki/\\u003cb\\u003eOpenAI\\u003c/b\\u003e\",\n",
      "      \"pagemap\": {\n",
      "        \"hcard\": [\n",
      "          {\n",
      "            \"url_text\": \"openai.com\",\n",
      "            \"bday\": \"2015-12-08\",\n",
      "            \"fn\": \"OpenAI\",\n",
      "            \"label\": \"1455 3rd Street, San Francisco, California, U.S.[2]\",\n",
      "            \"category\": \"Private\",\n",
      "            \"url\": \"openai.com\"\n",
      "          }\n",
      "        ],\n",
      "        \"metatags\": [\n",
      "          {\n",
      "            \"referrer\": \"origin\",\n",
      "            \"theme-color\": \"#eaecf0\",\n",
      "            \"og:type\": \"website\",\n",
      "            \"viewport\": \"width=device-width, initial-scale=1.0, user-scalable=yes, minimum-scale=0.25, maximum-scale=5.0\",\n",
      "            \"og:title\": \"OpenAI - Wikipedia\",\n",
      "            \"format-detection\": \"telephone=no\"\n",
      "          }\n",
      "        ]\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"kind\": \"customsearch#result\",\n",
      "      \"title\": \"API Platform | OpenAI\",\n",
      "      \"htmlTitle\": \"API Platform | \\u003cb\\u003eOpenAI\\u003c/b\\u003e\",\n",
      "      \"link\": \"https://openai.com/api/\",\n",
      "      \"displayLink\": \"openai.com\",\n",
      "      \"snippet\": \"The fastest and most powerful platform for building AI products · Flagship Models · Access the power of our models with APIs · Responses API · Extend model ...\",\n",
      "      \"htmlSnippet\": \"The fastest and most powerful platform for building AI products &middot; Flagship Models &middot; Access the power of our models with APIs &middot; Responses API &middot; Extend model&nbsp;...\",\n",
      "      \"formattedUrl\": \"https://openai.com/api/\",\n",
      "      \"htmlFormattedUrl\": \"https://\\u003cb\\u003eopenai\\u003c/b\\u003e.com/api/\",\n",
      "      \"pagemap\": {\n",
      "        \"cse_thumbnail\": [\n",
      "          {\n",
      "            \"src\": \"https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTdWtHTNF-8uDqmqKaRKC2IsP_fmKAMwP3B5l9gr_g5u5knBq8bS4a9Jw6u&s\",\n",
      "            \"width\": \"300\",\n",
      "            \"height\": \"168\"\n",
      "          }\n",
      "        ],\n",
      "        \"metatags\": [\n",
      "          {\n",
      "            \"og:image\": \"https://images.ctfassets.net/kftzwdyauwt9/557a9f70-0bf6-4d72-56450f68a4c8/96709c7557425f638b390a7c5dbf3017/stangel-2022-0602.jpg?w=1600&h=900&fit=fill\",\n",
      "            \"og:image:width\": \"1600\",\n",
      "            \"og:image:alt\": \"Aerial shot of two people sitting together and looking at a laptop with sunlight casting shadows over it, one person pointing to something on screen\",\n",
      "            \"og:type\": \"website\",\n",
      "            \"twitter:card\": \"summary_large_image\",\n",
      "            \"twitter:title\": \"API Platform\",\n",
      "            \"og:title\": \"API Platform\",\n",
      "            \"og:image:height\": \"900\",\n",
      "            \"twitter:image:height\": \"900\",\n",
      "            \"og:description\": \"Our API platform offers our latest models and guides for safety best practices.\",\n",
      "            \"twitter:image\": \"https://images.ctfassets.net/kftzwdyauwt9/557a9f70-0bf6-4d72-56450f68a4c8/96709c7557425f638b390a7c5dbf3017/stangel-2022-0602.jpg?w=1600&h=900&fit=fill\",\n",
      "            \"twitter:image:alt\": \"Aerial shot of two people sitting together and looking at a laptop with sunlight casting shadows over it, one person pointing to something on screen\",\n",
      "            \"twitter:site\": \"@OpenAI\",\n",
      "            \"twitter:image:width\": \"1600\",\n",
      "            \"viewport\": \"width=device-width, initial-scale=1\",\n",
      "            \"twitter:description\": \"Our API platform offers our latest models and guides for safety best practices.\",\n",
      "            \"og:locale\": \"en-US\"\n",
      "          }\n",
      "        ],\n",
      "        \"cse_image\": [\n",
      "          {\n",
      "            \"src\": \"https://images.ctfassets.net/kftzwdyauwt9/557a9f70-0bf6-4d72-56450f68a4c8/96709c7557425f638b390a7c5dbf3017/stangel-2022-0602.jpg?w=1600&h=900&fit=fill\"\n",
      "          }\n",
      "        ]\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"kind\": \"customsearch#result\",\n",
      "      \"title\": \"Login to OpenAI Platform Dashboard\",\n",
      "      \"htmlTitle\": \"Login to \\u003cb\\u003eOpenAI\\u003c/b\\u003e Platform Dashboard\",\n",
      "      \"link\": \"https://platform.openai.com/login\",\n",
      "      \"displayLink\": \"platform.openai.com\",\n",
      "      \"snippet\": \"Explore resources, tutorials, API docs, and dynamic examples to get the most out of OpenAI's developer platform.\",\n",
      "      \"htmlSnippet\": \"Explore resources, tutorials, API docs, and dynamic examples to get the most out of \\u003cb\\u003eOpenAI&#39;s\\u003c/b\\u003e developer platform.\",\n",
      "      \"formattedUrl\": \"https://platform.openai.com/login\",\n",
      "      \"htmlFormattedUrl\": \"https://platform.\\u003cb\\u003eopenai\\u003c/b\\u003e.com/login\",\n",
      "      \"pagemap\": {\n",
      "        \"cse_thumbnail\": [\n",
      "          {\n",
      "            \"src\": \"https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRw3_W_FoODv8iw5OuiI9DoxFAunCOA0S7ltEFw7kE7zVONFJccoUJxj0G6&s\",\n",
      "            \"width\": \"311\",\n",
      "            \"height\": \"162\"\n",
      "          }\n",
      "        ],\n",
      "        \"metatags\": [\n",
      "          {\n",
      "            \"og:image\": \"https://cdn.openai.com/API/images/platform-opengraph.png\",\n",
      "            \"theme-color\": \"#000000\",\n",
      "            \"og:type\": \"website\",\n",
      "            \"twitter:card\": \"summary_large_image\",\n",
      "            \"twitter:title\": \"OpenAI Platform\",\n",
      "            \"twitter:domain\": \"platform.openai.com\",\n",
      "            \"twitter:url\": \"https://platform.openai.com\",\n",
      "            \"og:title\": \"OpenAI Platform\",\n",
      "            \"og:description\": \"Explore developer resources, tutorials, API docs, and dynamic examples to get the most out of OpenAI's platform.\",\n",
      "            \"twitter:image\": \"https://cdn.openai.com/API/images/platform-opengraph.png\",\n",
      "            \"viewport\": \"width=device-width, initial-scale=1\",\n",
      "            \"twitter:description\": \"Explore developer resources, tutorials, API docs, and dynamic examples to get the most out of OpenAI's platform.\",\n",
      "            \"og:url\": \"https://platform.openai.com\"\n",
      "          }\n",
      "        ],\n",
      "        \"cse_image\": [\n",
      "          {\n",
      "            \"src\": \"https://cdn.openai.com/API/images/platform-opengraph.png\"\n",
      "          }\n",
      "        ]\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"kind\": \"customsearch#result\",\n",
      "      \"title\": \"ChatGPT | OpenAI\",\n",
      "      \"htmlTitle\": \"ChatGPT | \\u003cb\\u003eOpenAI\\u003c/b\\u003e\",\n",
      "      \"link\": \"https://openai.com/chatgpt/overview/\",\n",
      "      \"displayLink\": \"openai.com\",\n",
      "      \"snippet\": \"Type, talk, and use it your way. With ChatGPT, you can type or start a real-time voice conversation by tapping the soundwave icon in the mobile app.\",\n",
      "      \"htmlSnippet\": \"Type, talk, and use it your way. With ChatGPT, you can type or start a real-time voice conversation by tapping the soundwave icon in the mobile app.\",\n",
      "      \"formattedUrl\": \"https://openai.com/chatgpt/overview/\",\n",
      "      \"htmlFormattedUrl\": \"https://\\u003cb\\u003eopenai\\u003c/b\\u003e.com/chatgpt/overview/\",\n",
      "      \"pagemap\": {\n",
      "        \"cse_thumbnail\": [\n",
      "          {\n",
      "            \"src\": \"https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcScme1Np_uotvd4t7dXMgFSWdrVlgMwuViWbXiH7Tf9n4YSZ1YuTKJHfns&s\",\n",
      "            \"width\": \"300\",\n",
      "            \"height\": \"168\"\n",
      "          }\n",
      "        ],\n",
      "        \"metatags\": [\n",
      "          {\n",
      "            \"og:image\": \"https://images.ctfassets.net/kftzwdyauwt9/f8db487e-5192-491b-ab9a74c60a07/cdb9f0ca4c4e06223141a32b7a987c05/overview-og-16x9.png?w=1600&h=900&fit=fill\",\n",
      "            \"og:image:width\": \"1600\",\n",
      "            \"og:type\": \"website\",\n",
      "            \"twitter:card\": \"summary_large_image\",\n",
      "            \"twitter:title\": \"ChatGPT\",\n",
      "            \"og:title\": \"ChatGPT\",\n",
      "            \"og:image:height\": \"900\",\n",
      "            \"twitter:image:height\": \"900\",\n",
      "            \"og:description\": \"ChatGPT helps you get answers, find inspiration and be more productive. It is free to use and easy to try. Just ask and ChatGPT can help with writing, learning, brainstorming and more.\",\n",
      "            \"twitter:image\": \"https://images.ctfassets.net/kftzwdyauwt9/f8db487e-5192-491b-ab9a74c60a07/cdb9f0ca4c4e06223141a32b7a987c05/overview-og-16x9.png?w=1600&h=900&fit=fill\",\n",
      "            \"twitter:site\": \"@OpenAI\",\n",
      "            \"twitter:image:width\": \"1600\",\n",
      "            \"viewport\": \"width=device-width, initial-scale=1\",\n",
      "            \"twitter:description\": \"ChatGPT helps you get answers, find inspiration and be more productive. It is free to use and easy to try. Just ask and ChatGPT can help with writing, learning, brainstorming and more.\",\n",
      "            \"og:locale\": \"en-US\"\n",
      "          }\n",
      "        ],\n",
      "        \"cse_image\": [\n",
      "          {\n",
      "            \"src\": \"https://images.ctfassets.net/kftzwdyauwt9/f8db487e-5192-491b-ab9a74c60a07/cdb9f0ca4c4e06223141a32b7a987c05/overview-og-16x9.png?w=1600&h=900&fit=fill\"\n",
      "          }\n",
      "        ]\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"kind\": \"customsearch#result\",\n",
      "      \"title\": \"OpenAI Playground\",\n",
      "      \"htmlTitle\": \"\\u003cb\\u003eOpenAI\\u003c/b\\u003e Playground\",\n",
      "      \"link\": \"https://platform.openai.com/playground\",\n",
      "      \"displayLink\": \"platform.openai.com\",\n",
      "      \"snippet\": \"Explore resources, tutorials, API docs, and dynamic examples to get the most out of OpenAI's developer platform.\",\n",
      "      \"htmlSnippet\": \"Explore resources, tutorials, API docs, and dynamic examples to get the most out of \\u003cb\\u003eOpenAI&#39;s\\u003c/b\\u003e developer platform.\",\n",
      "      \"formattedUrl\": \"https://platform.openai.com/playground\",\n",
      "      \"htmlFormattedUrl\": \"https://platform.\\u003cb\\u003eopenai\\u003c/b\\u003e.com/playground\",\n",
      "      \"pagemap\": {\n",
      "        \"cse_thumbnail\": [\n",
      "          {\n",
      "            \"src\": \"https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRw3_W_FoODv8iw5OuiI9DoxFAunCOA0S7ltEFw7kE7zVONFJccoUJxj0G6&s\",\n",
      "            \"width\": \"311\",\n",
      "            \"height\": \"162\"\n",
      "          }\n",
      "        ],\n",
      "        \"metatags\": [\n",
      "          {\n",
      "            \"og:image\": \"https://cdn.openai.com/API/images/platform-opengraph.png\",\n",
      "            \"theme-color\": \"#000000\",\n",
      "            \"og:type\": \"website\",\n",
      "            \"twitter:card\": \"summary_large_image\",\n",
      "            \"twitter:title\": \"OpenAI Platform\",\n",
      "            \"twitter:domain\": \"platform.openai.com\",\n",
      "            \"twitter:url\": \"https://platform.openai.com\",\n",
      "            \"og:title\": \"OpenAI Platform\",\n",
      "            \"og:description\": \"Explore developer resources, tutorials, API docs, and dynamic examples to get the most out of OpenAI's platform.\",\n",
      "            \"twitter:image\": \"https://cdn.openai.com/API/images/platform-opengraph.png\",\n",
      "            \"viewport\": \"width=device-width, initial-scale=1\",\n",
      "            \"twitter:description\": \"Explore developer resources, tutorials, API docs, and dynamic examples to get the most out of OpenAI's platform.\",\n",
      "            \"og:url\": \"https://platform.openai.com\"\n",
      "          }\n",
      "        ],\n",
      "        \"cse_image\": [\n",
      "          {\n",
      "            \"src\": \"https://cdn.openai.com/API/images/platform-opengraph.png\"\n",
      "          }\n",
      "        ]\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"kind\": \"customsearch#result\",\n",
      "      \"title\": \"Introducing ChatGPT | OpenAI\",\n",
      "      \"htmlTitle\": \"Introducing ChatGPT | \\u003cb\\u003eOpenAI\\u003c/b\\u003e\",\n",
      "      \"link\": \"https://openai.com/index/chatgpt/\",\n",
      "      \"displayLink\": \"openai.com\",\n",
      "      \"snippet\": \"Nov 30, 2022 ... Introducing ChatGPT ... We've trained a model called ChatGPT which interacts in a conversational way. The dialogue format makes it possible for ...\",\n",
      "      \"htmlSnippet\": \"Nov 30, 2022 \\u003cb\\u003e...\\u003c/b\\u003e Introducing ChatGPT ... We&#39;ve trained a model called ChatGPT which interacts in a conversational way. The dialogue format makes it possible for&nbsp;...\",\n",
      "      \"formattedUrl\": \"https://openai.com/index/chatgpt/\",\n",
      "      \"htmlFormattedUrl\": \"https://\\u003cb\\u003eopenai\\u003c/b\\u003e.com/index/chatgpt/\",\n",
      "      \"pagemap\": {\n",
      "        \"cse_thumbnail\": [\n",
      "          {\n",
      "            \"src\": \"https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQksmreBO6Pt19AG64itf27_2h6lLutX4rsh-C-V5dYHUOusTXDeJi_PMKF&s\",\n",
      "            \"width\": \"300\",\n",
      "            \"height\": \"168\"\n",
      "          }\n",
      "        ],\n",
      "        \"metatags\": [\n",
      "          {\n",
      "            \"og:image\": \"https://images.ctfassets.net/kftzwdyauwt9/7f6c5b76-875f-455d-ebb8813e1022/c16e0d3c81f4b9bcc9d9c65ed69b203d/chatgpt-og.jpg?w=1600&h=900&fit=fill\",\n",
      "            \"og:image:width\": \"1600\",\n",
      "            \"og:type\": \"website\",\n",
      "            \"twitter:card\": \"summary_large_image\",\n",
      "            \"twitter:title\": \"Introducing ChatGPT\",\n",
      "            \"og:title\": \"Introducing ChatGPT\",\n",
      "            \"og:image:height\": \"900\",\n",
      "            \"twitter:image:height\": \"900\",\n",
      "            \"og:description\": \"We’ve trained a model called ChatGPT which interacts in a conversational way. The dialogue format makes it possible for ChatGPT to answer followup questions, admit its mistakes, challenge incorrect premises, and reject inappropriate requests.\",\n",
      "            \"twitter:image\": \"https://images.ctfassets.net/kftzwdyauwt9/7f6c5b76-875f-455d-ebb8813e1022/c16e0d3c81f4b9bcc9d9c65ed69b203d/chatgpt-og.jpg?w=1600&h=900&fit=fill\",\n",
      "            \"twitter:site\": \"@OpenAI\",\n",
      "            \"twitter:image:width\": \"1600\",\n",
      "            \"viewport\": \"width=device-width, initial-scale=1\",\n",
      "            \"twitter:description\": \"We’ve trained a model called ChatGPT which interacts in a conversational way. The dialogue format makes it possible for ChatGPT to answer followup questions, admit its mistakes, challenge incorrect premises, and reject inappropriate requests.\",\n",
      "            \"og:locale\": \"en-US\"\n",
      "          }\n",
      "        ],\n",
      "        \"cse_image\": [\n",
      "          {\n",
      "            \"src\": \"https://images.ctfassets.net/kftzwdyauwt9/7f6c5b76-875f-455d-ebb8813e1022/c16e0d3c81f4b9bcc9d9c65ed69b203d/chatgpt-og.jpg?w=1600&h=900&fit=fill\"\n",
      "          }\n",
      "        ]\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"kind\": \"customsearch#result\",\n",
      "      \"title\": \"API key from the OpenAI platform\",\n",
      "      \"htmlTitle\": \"API key from the \\u003cb\\u003eOpenAI\\u003c/b\\u003e platform\",\n",
      "      \"link\": \"https://platform.openai.com/api-keys\",\n",
      "      \"displayLink\": \"platform.openai.com\",\n",
      "      \"snippet\": \"Explore resources, tutorials, API docs, and dynamic examples to get the most out of OpenAI's developer platform.\",\n",
      "      \"htmlSnippet\": \"Explore resources, tutorials, API docs, and dynamic examples to get the most out of \\u003cb\\u003eOpenAI&#39;s\\u003c/b\\u003e developer platform.\",\n",
      "      \"formattedUrl\": \"https://platform.openai.com/api-keys\",\n",
      "      \"htmlFormattedUrl\": \"https://platform.\\u003cb\\u003eopenai\\u003c/b\\u003e.com/api-keys\",\n",
      "      \"pagemap\": {\n",
      "        \"cse_thumbnail\": [\n",
      "          {\n",
      "            \"src\": \"https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRw3_W_FoODv8iw5OuiI9DoxFAunCOA0S7ltEFw7kE7zVONFJccoUJxj0G6&s\",\n",
      "            \"width\": \"311\",\n",
      "            \"height\": \"162\"\n",
      "          }\n",
      "        ],\n",
      "        \"metatags\": [\n",
      "          {\n",
      "            \"og:image\": \"https://cdn.openai.com/API/images/platform-opengraph.png\",\n",
      "            \"theme-color\": \"#000000\",\n",
      "            \"og:type\": \"website\",\n",
      "            \"twitter:card\": \"summary_large_image\",\n",
      "            \"twitter:title\": \"OpenAI Platform\",\n",
      "            \"twitter:domain\": \"platform.openai.com\",\n",
      "            \"twitter:url\": \"https://platform.openai.com\",\n",
      "            \"og:title\": \"OpenAI Platform\",\n",
      "            \"og:description\": \"Explore developer resources, tutorials, API docs, and dynamic examples to get the most out of OpenAI's platform.\",\n",
      "            \"twitter:image\": \"https://cdn.openai.com/API/images/platform-opengraph.png\",\n",
      "            \"viewport\": \"width=device-width, initial-scale=1\",\n",
      "            \"twitter:description\": \"Explore developer resources, tutorials, API docs, and dynamic examples to get the most out of OpenAI's platform.\",\n",
      "            \"og:url\": \"https://platform.openai.com\"\n",
      "          }\n",
      "        ],\n",
      "        \"cse_image\": [\n",
      "          {\n",
      "            \"src\": \"https://cdn.openai.com/API/images/platform-opengraph.png\"\n",
      "          }\n",
      "        ]\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"kind\": \"customsearch#result\",\n",
      "      \"title\": \"OpenAI Status\",\n",
      "      \"htmlTitle\": \"\\u003cb\\u003eOpenAI\\u003c/b\\u003e Status\",\n",
      "      \"link\": \"https://status.openai.com/\",\n",
      "      \"displayLink\": \"status.openai.com\",\n",
      "      \"snippet\": \"OpenAI ... We have identified the issue and have implemented a fix. Video and image generation is now operational. We are continuing to monitor. Monitoring·.\",\n",
      "      \"htmlSnippet\": \"\\u003cb\\u003eOpenAI\\u003c/b\\u003e ... We have identified the issue and have implemented a fix. Video and image generation is now operational. We are continuing to monitor. Monitoring·.\",\n",
      "      \"formattedUrl\": \"https://status.openai.com/\",\n",
      "      \"htmlFormattedUrl\": \"https://status.\\u003cb\\u003eopenai\\u003c/b\\u003e.com/\",\n",
      "      \"pagemap\": {\n",
      "        \"metatags\": [\n",
      "          {\n",
      "            \"theme-color\": \"#15171c\",\n",
      "            \"og:type\": \"website\",\n",
      "            \"twitter:card\": \"summary\",\n",
      "            \"twitter:title\": \"OpenAI Status\",\n",
      "            \"og:site_name\": \"OpenAI Status\",\n",
      "            \"viewport\": \"width=device-width, initial-scale=1\",\n",
      "            \"twitter:description\": \"Latest service status for OpenAI\",\n",
      "            \"og:title\": \"OpenAI Status\",\n",
      "            \"og:locale\": \"en-US\",\n",
      "            \"color-scheme\": \"dark\",\n",
      "            \"og:url\": \"https://status.openai.com\",\n",
      "            \"og:description\": \"Latest service status for OpenAI\"\n",
      "          }\n",
      "        ]\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"kind\": \"customsearch#result\",\n",
      "      \"title\": \"OpenAI Platform\",\n",
      "      \"htmlTitle\": \"\\u003cb\\u003eOpenAI\\u003c/b\\u003e Platform\",\n",
      "      \"link\": \"https://platform.openai.com/\",\n",
      "      \"displayLink\": \"platform.openai.com\",\n",
      "      \"snippet\": \"Explore resources, tutorials, API docs, and dynamic examples to get the most out of OpenAI's developer platform.\",\n",
      "      \"htmlSnippet\": \"Explore resources, tutorials, API docs, and dynamic examples to get the most out of \\u003cb\\u003eOpenAI&#39;s\\u003c/b\\u003e developer platform.\",\n",
      "      \"formattedUrl\": \"https://platform.openai.com/\",\n",
      "      \"htmlFormattedUrl\": \"https://platform.\\u003cb\\u003eopenai\\u003c/b\\u003e.com/\",\n",
      "      \"pagemap\": {\n",
      "        \"cse_thumbnail\": [\n",
      "          {\n",
      "            \"src\": \"https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRw3_W_FoODv8iw5OuiI9DoxFAunCOA0S7ltEFw7kE7zVONFJccoUJxj0G6&s\",\n",
      "            \"width\": \"311\",\n",
      "            \"height\": \"162\"\n",
      "          }\n",
      "        ],\n",
      "        \"metatags\": [\n",
      "          {\n",
      "            \"og:image\": \"https://cdn.openai.com/API/images/platform-opengraph.png\",\n",
      "            \"theme-color\": \"#000000\",\n",
      "            \"og:type\": \"website\",\n",
      "            \"twitter:card\": \"summary_large_image\",\n",
      "            \"twitter:title\": \"OpenAI Platform\",\n",
      "            \"twitter:domain\": \"platform.openai.com\",\n",
      "            \"twitter:url\": \"https://platform.openai.com\",\n",
      "            \"og:title\": \"OpenAI Platform\",\n",
      "            \"og:description\": \"Explore developer resources, tutorials, API docs, and dynamic examples to get the most out of OpenAI's platform.\",\n",
      "            \"twitter:image\": \"https://cdn.openai.com/API/images/platform-opengraph.png\",\n",
      "            \"viewport\": \"width=device-width, initial-scale=1\",\n",
      "            \"twitter:description\": \"Explore developer resources, tutorials, API docs, and dynamic examples to get the most out of OpenAI's platform.\",\n",
      "            \"og:url\": \"https://platform.openai.com\"\n",
      "          }\n",
      "        ],\n",
      "        \"cse_image\": [\n",
      "          {\n",
      "            \"src\": \"https://cdn.openai.com/API/images/platform-opengraph.png\"\n",
      "          }\n",
      "        ]\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import httpx\n",
    "\n",
    "with httpx.Client(http2=False) as client:\n",
    "    r = client.get(\n",
    "        \"https://www.googleapis.com/customsearch/v1\",\n",
    "        params={\n",
    "            \"key\": \"AIzaSyDYO5BSod8opzI20moUfGLfcYO1ez1vMQU\",\n",
    "            \"cx\": \"c5297ee11db07449c\",\n",
    "            \"q\": \"OpenAI\"\n",
    "        }\n",
    "    )\n",
    "    print(r.status_code)\n",
    "    print(r.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "api_key = \"AIzaSyDYO5BSod8opzI20moUfGLfcYO1ez1vMQU\"\n",
    "search_engine_id = \"c5297ee11db07449c\"\n",
    "query = \"OpenAI\"\n",
    "\n",
    "response = requests.get(\n",
    "    \"https://www.googleapis.com/customsearch/v1\",\n",
    "    params={\n",
    "        \"key\": api_key,\n",
    "        \"cx\": search_engine_id,\n",
    "        \"q\": query\n",
    "    }\n",
    ")\n",
    "\n",
    "print(response.status_code)\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.      ,  0.      ,  0.      ],\n",
       "       [ 0.4224  ,  0.48716 , -0.08208 ],\n",
       "       [ 0.48716 ,  0.589119,  0.069228],\n",
       "       [-0.08208 ,  0.069228,  0.988336]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.84451155  0.50490945  0.12622736 -0.12622736]]\n",
      "[[-0.42639951 -0.85280372 -0.21320093  0.21320093]\n",
      " [-0.85280372  0.49013289 -0.12746678  0.12746678]\n",
      " [-0.21320093 -0.12746678  0.96813331  0.03186669]\n",
      " [ 0.21320093  0.12746678  0.03186669  0.96813331]]\n",
      "[[-4.69041576e+00 -2.98481067e+00  0.00000000e+00]\n",
      " [-9.42234412e-06 -3.82405041e-01  0.00000000e+00]\n",
      " [-2.35558603e-06  2.40439874e+00  0.00000000e+00]\n",
      " [ 2.35558603e-06 -4.04398740e-01  0.00000000e+00]]\n",
      "[[-0.42639951 -0.11036986 -0.83938528  0.31870469]\n",
      " [-0.85280372 -0.221187    0.4724754   0.02638448]\n",
      " [-0.21320093  0.95782325  0.05277685  0.18609212]\n",
      " [ 0.21320093 -0.14766325  0.26391715  0.92903588]]\n",
      "[[ 2.          1.00053133  0.        ]\n",
      " [ 4.          1.99949094  0.        ]\n",
      " [ 1.          3.0007767   0.        ]\n",
      " [-1.         -1.0001969   0.        ]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "A = np.array([[2, 4, 1, -1], [1, 2, 3, -1], [0, 0, 0, 0]]).T\n",
    "B = np.array([[6.6904, 4, 1, -1]])\n",
    "u = B / np.linalg.norm(B)\n",
    "print(u)\n",
    "# u = np.array([[0.836, 0.5, 0.125, -0.125]])\n",
    "Q1 = np.identity(4) - 2* np.dot(u.T, u)\n",
    "print(Q1)\n",
    "print(np.dot(Q1, A))\n",
    "u2 = np.array([[-0.76, 0.641, -0.108]])\n",
    "Q2 = np.identity(3) - 2 * np.dot(u2.T, u2)\n",
    "Q2 = np.vstack([np.array([[0, 0, 0]]), Q2])\n",
    "Q2 = np.hstack([np.array([[1, 0, 0, 0]]).T, Q2])\n",
    "R = np.dot(Q2, np.dot(Q1, A))\n",
    "print(np.dot(Q1, Q2))\n",
    "print(np.dot(np.dot(Q1, Q2), R))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of principal components to preserve at least 85% variance: 4\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Given singular values\n",
    "singular_values = np.array([2.75, 2.3, 2.0, 1.98, 1.5, 1.0, 0.6])\n",
    "\n",
    "# Compute the variance explained (square of singular values)\n",
    "variance = singular_values ** 2\n",
    "total_variance = np.sum(variance)\n",
    "\n",
    "# Cumulative explained variance ratio\n",
    "cumulative_ratio = np.cumsum(variance) / total_variance\n",
    "\n",
    "# Determine the number of components needed to preserve at least 85% variance\n",
    "threshold = 0.85\n",
    "num_components = np.searchsorted(cumulative_ratio, threshold) + 1\n",
    "\n",
    "print(f\"Number of principal components to preserve at least 85% variance: {num_components}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.31015589, 0.52711121, 0.69116061, 0.85194542, 0.94422321,\n",
       "       0.98523555, 1.        ])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cumulative_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity_search(prompt, partitions, threshold=0.5):\n",
    "    \"\"\"\n",
    "    Performs similarity search between a prompt and text partitions.\n",
    "\n",
    "    Args:\n",
    "        prompt (str): The search query.\n",
    "        partitions (list of str): List of partitioned text.\n",
    "        threshold (float): Minimum similarity score for filtering.\n",
    "\n",
    "    Returns:\n",
    "        list: Relevant partitions with similarity scores.\n",
    "    \"\"\"\n",
    "    model = SentenceTransformer(\"all-MiniLM-L6-v2\")  # Efficient embedding model\n",
    "    # Generate embeddings\n",
    "    prompt_embedding = model.encode([prompt])\n",
    "    partition_embeddings = model.encode(partitions)\n",
    "    # print(prompt_embedding.shape, partition_embeddings.shape)\n",
    "\n",
    "\n",
    "    # Compute cosine similarity\n",
    "    similarity = cosine_similarity(prompt_embedding, partition_embeddings)[0]\n",
    "\n",
    "        # Filter partitions based on threshold\n",
    "    filtered_partitions = [\n",
    "        {\"text\": partitions[i]}\n",
    "        for i in range(len(partitions))\n",
    "        if similarity[i] > threshold\n",
    "    ]\n",
    "    print(similarity)\n",
    "\n",
    "    # Sort by relevance (descending similarity)\n",
    "    # filtered_partitions.sort(key=lambda x: x[\"score\"], reverse=True)\n",
    "\n",
    "    return filtered_partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'similarity_search' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 62\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m link, text \u001b[38;5;129;01min\u001b[39;00m sublinks[\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m20\u001b[39m]:\n\u001b[1;32m     61\u001b[0m     combined \u001b[38;5;241m=\u001b[39m extract_minimal_text_for_similarity(link)\n\u001b[0;32m---> 62\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[43msimilarity_search\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGather Carnegie Mellon University Computer Science graduate program\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms application requirements specifics\u001b[39m\u001b[38;5;124m\"\u001b[39m, [combined] ))\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLink: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlink\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mText: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtext\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'similarity_search' is not defined"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin\n",
    "import re\n",
    "\n",
    "def get_sublinks_and_text(url):\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to fetch {url}: {e}\")\n",
    "        return []\n",
    "\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    links = soup.find_all('a', href=True)\n",
    "\n",
    "    result = []\n",
    "    for link in links:\n",
    "        full_url = urljoin(url, link['href'])  # Handle relative URLs\n",
    "        text = link.get_text(strip=True)\n",
    "        result.append((full_url, text))\n",
    "\n",
    "    return result\n",
    "\n",
    "def extract_minimal_text_for_similarity(url: str, timeout: int = 5) -> str:\n",
    "    try:\n",
    "        headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "        session = requests.Session()\n",
    "        session.headers.update(headers)\n",
    "\n",
    "        response = session.get(url, timeout=timeout)\n",
    "        response.raise_for_status()\n",
    "    except Exception as e:\n",
    "        print(f\"[Error fetching {url}]: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # Extract title\n",
    "    title = soup.title.string.strip() if soup.title and soup.title.string else \"\"\n",
    "\n",
    "    # Extract h1-h3 headers (which often summarize sections)\n",
    "    headers = [h.get_text(strip=True) for h in soup.find_all(['h1', 'h2', 'h3'])]\n",
    "\n",
    "    # Extract body paragraphs\n",
    "    paragraphs = [p.get_text(strip=True) for p in soup.find_all('p')]\n",
    "    body_text = \" \".join(paragraphs)\n",
    "    \n",
    "    # Clean and truncate to ~500 words max\n",
    "    body_text = re.sub(r'\\s+', ' ', body_text)\n",
    "    truncated_body = \" \".join(body_text.split()[:500])\n",
    "\n",
    "    # Combine all parts\n",
    "    combined = \"\\n\".join([title] + headers + [truncated_body])\n",
    "    return combined\n",
    "\n",
    "# Example usage:\n",
    "url = \"http://coursecatalog.web.cmu.edu/schools-colleges/schoolofcomputerscience/undergraduatecomputerscience/\"\n",
    "sublinks = get_sublinks_and_text(url)\n",
    "for link, text in sublinks[0:20]:\n",
    "    combined = extract_minimal_text_for_similarity(link)\n",
    "    print(similarity_search(\"Gather Carnegie Mellon University Computer Science graduate program's application requirements specifics\", [combined] ))\n",
    "    print(f\"Link: {link}\\nText: {text}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5835358]\n",
      "[{'text': 'How to Apply - Carnegie Mellon University in Qatar\\nExplore\\nEngage\\nApply\\nEnroll\\nAdmission\\nHow to apply\\nIs CMU-Q the right university for you?\\nStart here\\nSteps to apply\\nOnline application form\\nWriting Supplement Essay\\nOfficial and complete academic transcripts\\nOfficial TOEFL, IELTS or Duolingo results\\nLetters of recommendation\\nPassport and biographical information\\nOfficial SAT or ACT results (optional)\\nInterview (optional)\\nApplication fee\\nImportant application dates\\nContact the Office of Admission\\nHomeAdmissionHow to Apply The deadline for Fall 2025 applications was January 15.Learn more about submitting a late application. Applications for Fall 2026 admission will open on September 1, 2025. If you’ve already decided CMU-Q is your first choice among schools and meet the eligibility requirements. If you have completed at least one semester as a degree candidate at another college or university. If you are currently in your last year of high school, have completed high school, or have completed a high school equivalency. Carnegie Mellon uses theCommon Appexclusively, and all applications must be submitted online. The Writing Supplement Essay will give us a sense of who you are as a person, beyond your grades and test scores. The statement also demonstrates your ability to organize thoughts and express yourself. The question for the Writing Supplement Essay can be found in CMU-Q’s Writing Supplement section within the Common Application. Please note that while the Writing Supplement Essay is required, there is also an essay in the common part of the Common Application. This essay is optional for applicants to CMU-Q. All transcripts and official results are submitted by your college counselor, principal or academic advisor through the Common Application. Please invite your school official through the feature inside your CMU-Q Common App. Your academic transcripts show us your secondary school performance, which is the main factor in our admission decision. We pay close attention to the curriculum rigor and the grades you have earned. We require: To demonstrate your proficiency in English, CMU-Q requires applicants to submit official TOEFL, IELTS, or Duolingo results. TOEFL CMU-Q accepts both theTOEFL iBTand the newTOEFL iBT Special Home Edition. Please follow the links for further information on test dates and locations. Use code4246for TOEFL score reports to be sent to Carnegie Mellon. IELTS CMU-Q accepts bothIELTS Academics and IELTS for UKVIand the newIELTS Indicator. Please follow the links for further information on test dates and locations. Please note, the IELTS Indicator is currently not offered by the British Council to residents in Qatar. You can also register for a test directly with the British Council office in your country. In Qatar, the British Council office in Doha can be contacted on 800 5501. Duolingo CMU-Q accepts the Duolingo English Test as an equivalent for the TOEFL or IELTS. To learn more about the Duolingo English Test and how to send results, please visitDuolingo’s site. Waiver Policy for TOEFL/IELTS/Duolingo The TOEFL/IELTS/Duolingo requirement may be waived if an applicant qualifies under our waiver policy. Option 1: Waiving the TOEFL/IELTS/Duolingo requirement through SAT/ACT score If you have a score of 600 or higher on the SAT Reading and Writing Section OR a score of 26 or higher on both the English and Reading sections of the ACT, you will automatically qualify for a waiver from the TOEFL/IELTS/Duolingo. There is no need to initiate a request for waiver through the Office of Admission. Option 2: Waiving the TOEFL/IELTS/Duolingo requirement through primary and native language confirmation If English is'}]\n"
     ]
    }
   ],
   "source": [
    "new = \"https://www.qatar.cmu.edu/admission/how-to-apply/\"\n",
    "combined = extract_minimal_text_for_similarity(new)\n",
    "print(similarity_search(\"Gather Carnegie Mellon University Computer Science graduate program's application requirements specifics\", [combined] ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = get_secret()\n",
    "os.environ[\"OPENAI_API_KEY\"] = api_key\n",
    "def rec_send(chatbot_response, original_prompt):\n",
    "    # Define a secondary chatbot model for recommendations\n",
    "    rec_chat = ChatOpenAI(model=\"gpt-4o\", temperature=0.7)\n",
    "\n",
    "    # System prompt to generate helpful recommendations\n",
    "    rec_prompt = \"\"\"You are assisting a user who is unsure how to respond to an advisor's question. \n",
    "    The advisor wants to help the user who wants to {original_prompt} . Thus, the advisor just asked the user: \"{chatbot_response}\".\n",
    "    \n",
    "    Your task is to provide six diverse and thoughtful example responses that the user might consider. \n",
    "    These examples should be concise yet informative, covering different angles or perspectives that \n",
    "    a user might take when answering the question. They should consist of around 50 characters or less than 6 words.\n",
    "    \n",
    "    Format your response exactly as a list of six distinct suggestions below.\n",
    "    Recommendation 1 | Recommendataion 2 | Recommendation 3 | Recommendation 4 | Recommendation 5 | Recommendation 6\n",
    "\n",
    "    Start your recommendation directly and don't add something like \"Recommendation 1:\".\n",
    "    \"\"\"\n",
    "\n",
    "    rec_prompt_template = ChatPromptTemplate.from_messages(\n",
    "        [(\"user\", rec_prompt)]\n",
    "    )\n",
    "\n",
    "    parser = StrOutputParser()\n",
    "\n",
    "    # Chain to elaborate the task\n",
    "    task_elaboration_chain = rec_prompt_template | rec_chat | parser\n",
    "    elaborated_task = task_elaboration_chain.invoke({\"original_prompt\":original_prompt, \"chatbot_response\": chatbot_response})\n",
    "    \n",
    "    return {\"recommendations\": elaborated_task.split(\"|\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence_transformers\n",
      "  Obtaining dependency information for sentence_transformers from https://files.pythonhosted.org/packages/05/89/7eb147a37b7f31d3c815543df539d8b8d0425e93296c875cc87719d65232/sentence_transformers-3.4.1-py3-none-any.whl.metadata\n",
      "  Downloading sentence_transformers-3.4.1-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting transformers<5.0.0,>=4.41.0 (from sentence_transformers)\n",
      "  Obtaining dependency information for transformers<5.0.0,>=4.41.0 from https://files.pythonhosted.org/packages/20/37/1f29af63e9c30156a3ed6ebc2754077016577c094f31de7b2631e5d379eb/transformers-4.49.0-py3-none-any.whl.metadata\n",
      "  Downloading transformers-4.49.0-py3-none-any.whl.metadata (44 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.0/44.0 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /opt/homebrew/lib/python3.11/site-packages (from sentence_transformers) (4.65.0)\n",
      "Requirement already satisfied: torch>=1.11.0 in /opt/homebrew/lib/python3.11/site-packages (from sentence_transformers) (2.0.1)\n",
      "Requirement already satisfied: scikit-learn in /opt/homebrew/lib/python3.11/site-packages (from sentence_transformers) (1.4.0)\n",
      "Requirement already satisfied: scipy in /opt/homebrew/lib/python3.11/site-packages (from sentence_transformers) (1.11.4)\n",
      "Collecting huggingface-hub>=0.20.0 (from sentence_transformers)\n",
      "  Obtaining dependency information for huggingface-hub>=0.20.0 from https://files.pythonhosted.org/packages/ae/05/75b90de9093de0aadafc868bb2fa7c57651fd8f45384adf39bd77f63980d/huggingface_hub-0.29.1-py3-none-any.whl.metadata\n",
      "  Downloading huggingface_hub-0.29.1-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: Pillow in /opt/homebrew/lib/python3.11/site-packages (from sentence_transformers) (9.5.0)\n",
      "Requirement already satisfied: filelock in /opt/homebrew/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (3.12.0)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub>=0.20.0->sentence_transformers)\n",
      "  Obtaining dependency information for fsspec>=2023.5.0 from https://files.pythonhosted.org/packages/e2/94/758680531a00d06e471ef649e4ec2ed6bf185356a7f9fbfbb7368a40bd49/fsspec-2025.2.0-py3-none-any.whl.metadata\n",
      "  Downloading fsspec-2025.2.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/homebrew/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/homebrew/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (6.0)\n",
      "Requirement already satisfied: requests in /opt/homebrew/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (2.31.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/homebrew/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (4.12.2)\n",
      "Requirement already satisfied: sympy in /opt/homebrew/lib/python3.11/site-packages (from torch>=1.11.0->sentence_transformers) (1.11.1)\n",
      "Requirement already satisfied: networkx in /opt/homebrew/lib/python3.11/site-packages (from torch>=1.11.0->sentence_transformers) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/homebrew/lib/python3.11/site-packages (from torch>=1.11.0->sentence_transformers) (3.1.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/homebrew/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (1.24.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/homebrew/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (2023.5.5)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers<5.0.0,>=4.41.0->sentence_transformers)\n",
      "  Obtaining dependency information for tokenizers<0.22,>=0.21 from https://files.pythonhosted.org/packages/22/7a/88e58bb297c22633ed1c9d16029316e5b5ac5ee44012164c2edede599a5e/tokenizers-0.21.0-cp39-abi3-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading tokenizers-0.21.0-cp39-abi3-macosx_11_0_arm64.whl.metadata (6.7 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers<5.0.0,>=4.41.0->sentence_transformers)\n",
      "  Obtaining dependency information for safetensors>=0.4.1 from https://files.pythonhosted.org/packages/b8/3b/11f1b4a2f5d2ab7da34ecc062b0bc301f2be024d110a6466726bec8c055c/safetensors-0.5.3-cp38-abi3-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading safetensors-0.5.3-cp38-abi3-macosx_11_0_arm64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/homebrew/lib/python3.11/site-packages (from scikit-learn->sentence_transformers) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/homebrew/lib/python3.11/site-packages (from scikit-learn->sentence_transformers) (3.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/homebrew/lib/python3.11/site-packages (from jinja2->torch>=1.11.0->sentence_transformers) (2.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/homebrew/lib/python3.11/site-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/homebrew/lib/python3.11/site-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/homebrew/lib/python3.11/site-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/lib/python3.11/site-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (2022.12.7)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/homebrew/lib/python3.11/site-packages (from sympy->torch>=1.11.0->sentence_transformers) (1.3.0)\n",
      "Using cached sentence_transformers-3.4.1-py3-none-any.whl (275 kB)\n",
      "Using cached huggingface_hub-0.29.1-py3-none-any.whl (468 kB)\n",
      "Using cached transformers-4.49.0-py3-none-any.whl (10.0 MB)\n",
      "Downloading fsspec-2025.2.0-py3-none-any.whl (184 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.5/184.5 kB\u001b[0m \u001b[31m982.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:01\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached safetensors-0.5.3-cp38-abi3-macosx_11_0_arm64.whl (418 kB)\n",
      "Using cached tokenizers-0.21.0-cp39-abi3-macosx_11_0_arm64.whl (2.6 MB)\n",
      "Installing collected packages: safetensors, fsspec, huggingface-hub, tokenizers, transformers, sentence_transformers\n",
      "  Attempting uninstall: safetensors\n",
      "    Found existing installation: safetensors 0.3.1\n",
      "    Uninstalling safetensors-0.3.1:\n",
      "      Successfully uninstalled safetensors-0.3.1\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2023.4.0\n",
      "    Uninstalling fsspec-2023.4.0:\n",
      "      Successfully uninstalled fsspec-2023.4.0\n",
      "  Attempting uninstall: huggingface-hub\n",
      "    Found existing installation: huggingface-hub 0.14.1\n",
      "    Uninstalling huggingface-hub-0.14.1:\n",
      "      Successfully uninstalled huggingface-hub-0.14.1\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.13.3\n",
      "    Uninstalling tokenizers-0.13.3:\n",
      "      Successfully uninstalled tokenizers-0.13.3\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.30.2\n",
      "    Uninstalling transformers-4.30.2:\n",
      "      Successfully uninstalled transformers-4.30.2\n",
      "Successfully installed fsspec-2025.2.0 huggingface-hub-0.29.1 safetensors-0.5.3 sentence_transformers-3.4.1 tokenizers-0.21.0 transformers-4.49.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.11 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install sentence_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#</th>\n",
       "      <th>Prompt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Plan a recruitment event for the psychology cl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Organize a fundraising campaign for an environ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Develop a content calendar for a social media ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Prepare a business pitch deck for a startup co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Write a research paper on the impact of AI on ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Plan a personal productivity routine to balanc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Create a step-by-step guide for launching an o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Organize a community clean-up event for a loca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Develop a mobile app prototype for a time-mana...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Plan a corporate team-building retreat for bet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>Design a 3-month study plan for an upcoming ce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>Prepare a budget and financial plan for a smal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>Launch an email marketing campaign for an e-co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>Coordinate a product launch event for a new te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>Write a job description and hiring process for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>Develop a training program for onboarding new ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>Create a project management workflow for a sof...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>Organize a virtual summit featuring industry e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>Design a curriculum for an online course on di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>Prepare a crisis management plan for handling ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     #                                             Prompt\n",
       "0    1  Plan a recruitment event for the psychology cl...\n",
       "1    2  Organize a fundraising campaign for an environ...\n",
       "2    3  Develop a content calendar for a social media ...\n",
       "3    4  Prepare a business pitch deck for a startup co...\n",
       "4    5  Write a research paper on the impact of AI on ...\n",
       "5    6  Plan a personal productivity routine to balanc...\n",
       "6    7  Create a step-by-step guide for launching an o...\n",
       "7    8  Organize a community clean-up event for a loca...\n",
       "8    9  Develop a mobile app prototype for a time-mana...\n",
       "9   10  Plan a corporate team-building retreat for bet...\n",
       "10  11  Design a 3-month study plan for an upcoming ce...\n",
       "11  12  Prepare a budget and financial plan for a smal...\n",
       "12  13  Launch an email marketing campaign for an e-co...\n",
       "13  14  Coordinate a product launch event for a new te...\n",
       "14  15  Write a job description and hiring process for...\n",
       "15  16  Develop a training program for onboarding new ...\n",
       "16  17  Create a project management workflow for a sof...\n",
       "17  18  Organize a virtual summit featuring industry e...\n",
       "18  19  Design a curriculum for an online course on di...\n",
       "19  20  Prepare a crisis management plan for handling ..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"../../../../../../Downloads/haX_Testing_Prompt - Sheet1.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin\n",
    "\n",
    "def get_favicon(url):\n",
    "    \"\"\"Fetch the favicon URL from a website.\"\"\"\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        if response.status_code == 200:\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "            favicon_url = None\n",
    "            for link in soup.find_all('link', rel=['icon', 'shortcut icon', 'apple-touch-icon']):\n",
    "                favicon_url = link.get('href')\n",
    "                if favicon_url:\n",
    "                    break\n",
    "            \n",
    "            if favicon_url:\n",
    "                return urljoin(url, favicon_url)  # Ensure the favicon URL is absolute\n",
    "            else:\n",
    "                return None\n",
    "        else:\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "def call_google_search_api(query):\n",
    "    \"\"\"\n",
    "    Calls the Google Search API to retrieve search results and also includes the website favicon.\n",
    "    Args:\n",
    "        query (str): The search query.\n",
    "    Returns:\n",
    "        dict: A dictionary containing evidence or an error message, including favicons.\n",
    "    \"\"\"\n",
    "    api_key = \"AIzaSyDYO5BSod8opzI20moUfGLfcYO1ez1vMQU\"\n",
    "    search_engine_id = \"c5297ee11db07449c\"  # Replace with your custom search engine ID\n",
    "    base_url = \"https://www.googleapis.com/customsearch/v1\"\n",
    "\n",
    "    # Construct the request parameters\n",
    "    params = {\n",
    "        \"key\": api_key,\n",
    "        \"cx\": search_engine_id,\n",
    "        \"q\": query\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        # Make the API request\n",
    "        response = requests.get(base_url, params=params)\n",
    "        response.raise_for_status()  # Raise HTTPError for bad responses\n",
    "\n",
    "        # Parse the JSON response\n",
    "        data = response.json()\n",
    "\n",
    "        # Extract relevant information, including favicon\n",
    "        if \"items\" in data:\n",
    "            results = []\n",
    "            for item in data[\"items\"]:\n",
    "                title = item.get(\"title\")\n",
    "                link = item.get(\"link\")\n",
    "                snippet = item.get(\"snippet\")\n",
    "\n",
    "                # Fetch the favicon using the helper function\n",
    "                favicon_url = get_favicon(link)\n",
    "                \n",
    "                results.append({\n",
    "                    \"title\": title,\n",
    "                    \"link\": link,\n",
    "                    \"snippet\": snippet,\n",
    "                    \"favicon\": favicon_url  # Store the actual favicon URL\n",
    "                })\n",
    "\n",
    "            return {\"success\": True, \"evidence\": results}\n",
    "        else:\n",
    "            return {\"success\": False, \"error\": \"No results found.\"}\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        return {\"success\": False, \"error\": str(e)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity_score(query, search):\n",
    "    \"\"\"\n",
    "    Performs similarity search between a prompt and text partitions.\n",
    "\n",
    "    Args:\n",
    "        prompt (str): The search query.\n",
    "        partitions (list of str): List of partitioned text.\n",
    "        threshold (float): Minimum similarity score for filtering.\n",
    "\n",
    "    Returns:\n",
    "        list: Relevant partitions with similarity scores.\n",
    "    \"\"\"\n",
    "    # Generate embeddings\n",
    "    prompt_embedding = [model.encode(query)]\n",
    "    partition_embeddings = [model.encode(search)]\n",
    "    # print(prompt_embedding.shape, partition_embeddings.shape)\n",
    "\n",
    "\n",
    "    # Compute cosine similarity\n",
    "    similarity = cosine_similarity(prompt_embedding, partition_embeddings)\n",
    "\n",
    "    # Sort by relevance (descending similarity)\n",
    "    # filtered_partitions.sort(key=lambda x: x[\"score\"], reverse=True)\n",
    "\n",
    "    return similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.32609707\n"
     ]
    }
   ],
   "source": [
    "api_key = \"AIzaSyDYO5BSod8opzI20moUfGLfcYO1ez1vMQU\"\n",
    "search_engine_id = \"c5297ee11db07449c\"  # Replace with your custom search engine ID\n",
    "base_url = \"https://www.googleapis.com/customsearch/v1\"\n",
    "\n",
    "# Construct the request parameters\n",
    "params = {\n",
    "    \"key\": api_key,\n",
    "    \"cx\": search_engine_id,\n",
    "    \"q\": \"CMU\"\n",
    "}\n",
    "\n",
    "\n",
    "# Make the API request\n",
    "response = requests.get(base_url, params=params)\n",
    "response.raise_for_status()  # Raise HTTPError for bad responses\n",
    "\n",
    "# Parse the JSON response\n",
    "data = {\"items\": {\"A\"}}\n",
    "\n",
    "# Extract relevant information, including favicon\n",
    "# Extract relevant information, including favicon\n",
    "if \"items\" in data:\n",
    "    results = []\n",
    "    # Compute similarity scores\n",
    "    scores = [similarity_score(\"CMU\", \"AAA\") for item in data[\"items\"]]\n",
    "\n",
    "    # Sort data[\"items\"] based on scores in descending order\n",
    "    sorted_items_with_scores = sorted(\n",
    "        zip(scores, data[\"items\"]), key=lambda x: x[0], reverse=True\n",
    "    )\n",
    "\n",
    "    for score, item in sorted_items_with_scores:\n",
    "        print(score[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "Scraped|[{'text': 'One fun fact about me is I love to paint banners for birthdays or other events! Caroline Readinger Vice President Member Development Ella McCutchin Vice President Membership Cate Laudadio Facilities Director Hometown: Houston, TX Major: Public Health Reese Venghaus Events Director Hometown: Houston, TX Major: Elementary Education My name is Reese Venghaus, and I am from Houston, Texas! I am an elementary education major, and I hope to someday be a 3rd or 4th grade teacher. I love working with children, and I cannot wait to design my own classroom someday and create a positive and fun learning environment for my future students. I have always had a passion for design as well, which has led me to recently become the Campus Manager of Fresh Prints at Texas A&M University. I will find clients and work hands-on with them in order to help them design their own custom apparel while organizing their orders. My other hobbies include Pilates, baking for friends and family, playing pickleball, and shopping. I cannot wait to be the next events director and to serve this chapter that I love so dearly! Caroline Patton Panhellenic Delegate Hometown: Dallas, TX Major: Kinesiology Hi my name is Caroline Patton and I am a Kinesiology - BS, Exercise Science Track, Basic Exercise Physiology Concentration major from Dallas Texas. I am a member of Pre-Dental Society and plan to attend dental school post-grad. One of my favorite hobbies is baking in my free time. Regan Williams Philanthropy Director Hometown: Dallas, TX Major: Finance My name is Regan Williams and I am a Finance Major from Dallas Texas. As well as serving as the Philanthropy Director for Kappa, I am also on the Finance Committee for Aggie Women in Business.', 'score': 0.32891285, 'score2': 0.768071838356865}, {'text': 'Post grad I plan to pursue an MBA or a master’s degree in finance. I love going on walks with friends, reading, and pickleball, and being outdoors! Megan Medlenka Risk Prevention Director Hometown: Houston, TX Major: Marketing Hi! My name is Megan Medlenka and I am a Marketing major from Houston, Texas. This year for Kappa I am the Risk Prevention Director. Outside of Kappa, I am a part of the Aggie Greek life concert planning group working on the Risk Management team. I also have been helping Outside life working as a representative for the Kappa ski trip. Some of my hobbies include working out and hanging out with friends. After graduation I plan to do something with event planning! RaeAnne Bradshaw Public Relations Director Hometown: Dallas, TX Major: Public Health Hi my name is RaeAnne Bradshaw and I am a junior Public Health major from Dallas, Texas. Outside of Kappa I am a volunteer at the Elizabeth House Maternity Home and Aggieland Pregnancy Outreach. After college I hope to attend an accelerated nursing program and pursue a career in Pediatric Oncology nursing. In the summers I love working as a camp counselor at Camp Ozark in Arkansas. Some of my favorite pastimes are yoga, doing skincare, and shopping. Epsilon Rho CHAPTER Texas A&M University 1502 Athens Drive College Station, TX 77840 epsilonrhokkg@gmail.com SIGN INTO YOUR ACCOUNT CONNECT WITH US CONNECT WITH HQ ©2025 Copyright OmegaOne | Kappa Kappa Gamma Last Updated: 03-13-2025 8:26PM UTC || Parent Organization Last Updated : NEVER ©2025 Copyright OmegaOne | Kappa Kappa Gamma.', 'score': 0.31179976, 'score2': 0.7550153834617082}, {'text': 'This is a preview of your page content. To close this preview and resume editing, click here. To save your changes, click here. Chapter Officers Isabel Acevedo President Hometown: Houston, TX Major: Marketing Hi! My name is Isabel Acevedo and I am so honored to serve as the president of this chapter this year. Kappa has been my biggest college blessing and I’m looking forward to being able to give back to this chapter! I am from Houston and I am a Marketing major on the Strategic Retail path. I am also doing a minor in Communications . After I graduate I hope to become a buyer for a fashion retail company. Outside of Kappa, I am also part of the Student Retailing Association and am a Zales Leadership Scholar through the Center for Retailing Studies at Mays. My favorite thing to do is hang out with my friends but other than that I also really enjoy playing pickleball, going on walks, baking, traveling, and shopping! I have loved every second of being a KKG! Kennedy Mayer Vice President Standards Hometown: Houston, TX Major: Accounting Katie Berggren Vice President Finance Hometown: Houston, TX Major: Finance Hi! My name is Katie Berggren, and I am a junior finance major. Outside of Kappa, I am involved in other organizations on campus such as Aggies on Wall Street and Horizons Finance Guild. Post grad, I am hoping to secure a job in finance, specifically within investment banking or private equity. A hobby I have recently picked up is running! I ran my first half marathon in October, and I can’t wait to run more in the future.', 'score': 0.25101936, 'score2': 0.7392351830145961}, {'text': 'Sarah Rose Gambrell Vice President Operations Hometown: Dallas, TX Major: Communications Hi! My name is Sarah Rose Gambrell and I am a Junior communications major from Dallas, TX! This year I am serving as the Vice President of Operations for Epsilon Rho. Aside from Kappa, I am involved in TAMU Sales Clubs as well as the Students in Communications Association. I love baking, running, and hanging out with my friends. I plan to move back to Dallas after graduation. Channing Hill Vice President External Affairs Hometown: Houston , TX Major: Finance I am a finance major in the Mays Business school! I am serving as the Vice President of External Affairs for Kappa Kappa Gamma and was the Events Director last year! I studied abroad after my freshman year at the London School of Economics and studied abroad last summer in Rome, Italy through Lead Abroad! I like cooking, traveling, and going on walks! Ashlyn Dickens Vice President Internal Affairs Hometown: Fort Worth, TX Major: Communications + Minor in Business Hi! My name is Ashlyn Dickens and I am a Junior Communications major with a minor in business from Fort Worth, Texas. This is my second term serving on Kappa’s Executive Board and I am so grateful that I have the opportunity to give back to the chapter that has given me so much. After graduation I plan on continuing my education and going to grad school here at A&M before going into food and beverage sales. I love yoga, going on walks, trying new restaurants, and of course, Aggie Baseball.', 'score': 0.21006086, 'score2': 0.7280819037164856}]\n",
      "Searched|Scraped|[{'text': \"Club recruitment ideas business card lollie pops! Coffee Themed Recruitment Board for FBLA! Club Bulletin Board Key Club International How To Get Your Group Noticed On Campus Note: This post may contain affiliate links. Please see my disclosure for more details. Thanks for supporting the brands that make The Happy Arkansan possible! Recruitment and getting your organization's name out there is difficult as a registered student organization, whether your organization is old or new. Today on The Happy Arkansan we are discussing […] Recruitment COB Event Teacher Recruitment Ideas Love these- great PR Fccla Recruitment Ideas RA Program Sorority Membership Ideas RA Program Related interests Explore related boards Ag Club cob DG Social Media Delta zeta deepher.\", 'score': 0.57825506, 'score2': 0.8432692848353869}]\n",
      "Searched|"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Sample larger than population or is negative",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[76], line 23\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28mprint\u001b[39m(results)\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSearched\u001b[39m\u001b[38;5;124m\"\u001b[39m,  end \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m|\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 23\u001b[0m     final_results \u001b[38;5;241m=\u001b[39m \u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresults\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m requests\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mRequestException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28mprint\u001b[39m(e)\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.11/3.11.6/Frameworks/Python.framework/Versions/3.11/lib/python3.11/random.py:456\u001b[0m, in \u001b[0;36mRandom.sample\u001b[0;34m(self, population, k, counts)\u001b[0m\n\u001b[1;32m    454\u001b[0m randbelow \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_randbelow\n\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;241m0\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m k \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m n:\n\u001b[0;32m--> 456\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSample larger than population or is negative\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    457\u001b[0m result \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;01mNone\u001b[39;00m] \u001b[38;5;241m*\u001b[39m k\n\u001b[1;32m    458\u001b[0m setsize \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m21\u001b[39m        \u001b[38;5;66;03m# size of a small set minus size of an empty list\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: Sample larger than population or is negative"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import requests\n",
    "\n",
    "for i in range(final_df.shape[0]):\n",
    "    if final_df['Evidence'][i] == \"forbidden\":\n",
    "        prompt = final_df['Prompt'][i]\n",
    "        A = call_google_search_api(prompt)\n",
    "        B = [A['evidence'][i]['link'] for i in range(len(A['evidence']))]\n",
    "        print(len(B))\n",
    "        urls = random.sample(B, k=3)\n",
    "        for url in urls: \n",
    "            try:\n",
    "                web_text = scrape_website(url)\n",
    "                print(\"Scraped\", end = \"|\")\n",
    "                # Step 2: Partition text\n",
    "                partitions = split_text(web_text)\n",
    "\n",
    "                # Step 3: Perform similarity search\n",
    "                results = similarity_search(prompt, partitions, threshold)\n",
    "                print(results)\n",
    "                print(\"Searched\",  end = \"|\")\n",
    "\n",
    "                final_results = random.sample(results, k=min(len(results), 3))\n",
    "            except requests.exceptions.RequestException as e:\n",
    "                print(e)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "text_elements = soup.find_all(['p', 'h1', 'h2', 'h3', 'h4', 'h5', 'h6'])\n",
    "text = \" \".join(element.get_text() for element in text_elements)\n",
    "\n",
    "# Remove extra spaces, newlines, and special characters\n",
    "text = re.sub(r\"\\s+\", \" \", text).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "def scrape_website(url):\n",
    "    \"\"\"\n",
    "    Scrapes text content from a given website URL.\n",
    "\n",
    "    Args:\n",
    "        url (str): The webpage URL.\n",
    "\n",
    "    Returns:\n",
    "        str: Extracted text content.\n",
    "    \"\"\"\n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "    session = requests.Session()\n",
    "    session.headers.update(headers)\n",
    "\n",
    "    response = session.get(url)\n",
    "\n",
    "    response.raise_for_status()  # Ensure successful request\n",
    "\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "     # Extract meaningful content (paragraphs and headers)\n",
    "    text_elements = soup.find_all(['p', 'h1', 'h2', 'h3', 'h4', 'h5', 'h6'])\n",
    "    text = \" \".join(element.get_text() for element in text_elements)\n",
    "\n",
    "    # Remove extra spaces, newlines, and special characters\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "\n",
    "    return text\n",
    "\n",
    "def split_text(text, chunk_size=300):\n",
    "    \"\"\"\n",
    "    Splits a large text into smaller partitions, ensuring each partition ends with a period.\n",
    "    \n",
    "    Args:\n",
    "        text (str): The full text.\n",
    "        chunk_size (int): Approximate number of words per partition.\n",
    "        \n",
    "    Returns:\n",
    "        list: List of text partitions.\n",
    "    \"\"\"\n",
    "    # First, split text into sentences.\n",
    "    # The regex splits after a period (keeping the period with the sentence).\n",
    "    sentences = re.split(r'(?<=[.])\\s+', text)\n",
    "    \n",
    "    partitions = []\n",
    "    current_partition = \"\"\n",
    "    current_word_count = 0\n",
    "\n",
    "    for sentence in sentences:\n",
    "        # Count words in the sentence.\n",
    "        sentence_word_count = len(sentence.split())\n",
    "        \n",
    "        # If adding this sentence exceeds the chunk size and there is content in the current partition,\n",
    "        # finalize the current partition.\n",
    "        if current_partition and current_word_count + sentence_word_count > chunk_size:\n",
    "            # Ensure the partition ends with a period.\n",
    "            if not current_partition.endswith('.'):\n",
    "                current_partition = current_partition.rstrip() + '.'\n",
    "            partitions.append(current_partition.strip())\n",
    "            # Start a new partition with the current sentence.\n",
    "            current_partition = sentence\n",
    "            current_word_count = sentence_word_count\n",
    "        else:\n",
    "            # Otherwise, add the sentence to the current partition.\n",
    "            if current_partition:\n",
    "                current_partition += \" \" + sentence\n",
    "            else:\n",
    "                current_partition = sentence\n",
    "            current_word_count += sentence_word_count\n",
    "\n",
    "    # Add the last partition.\n",
    "    if current_partition:\n",
    "        if not current_partition.endswith('.'):\n",
    "            current_partition = current_partition.rstrip() + '.'\n",
    "        partitions.append(current_partition.strip())\n",
    "\n",
    "    return partitions\n",
    "\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))  # Store API key securely\n",
    "\n",
    "def get_openai_embedding(text):\n",
    "    \"\"\"\n",
    "    Gets an embedding vector for a given text using OpenAI's API.\n",
    "\n",
    "    Args:\n",
    "        text (str): Input text to embed.\n",
    "\n",
    "    Returns:\n",
    "        np.array: Embedding vector.\n",
    "    \"\"\"\n",
    "    response = client.embeddings.create(\n",
    "        input=text,\n",
    "        model=\"text-embedding-ada-002\"\n",
    "    )\n",
    "    return np.array(response.data[0].embedding)\n",
    "\n",
    "def similarity_search(prompt, partitions, threshold=0.5):\n",
    "    \"\"\"\n",
    "    Performs similarity search between a prompt and text partitions.\n",
    "\n",
    "    Args:\n",
    "        prompt (str): The search query.\n",
    "        partitions (list of str): List of partitioned text.\n",
    "        threshold (float): Minimum similarity score for filtering.\n",
    "\n",
    "    Returns:\n",
    "        list: Relevant partitions with similarity scores.\n",
    "    \"\"\"\n",
    "    similarities = [0, 0]\n",
    "    for i in range(2):\n",
    "        if i == 0:\n",
    "            model = SentenceTransformer(\"all-MiniLM-L6-v2\")  # Efficient embedding model\n",
    "            # Generate embeddings\n",
    "            prompt_embedding = model.encode([prompt])\n",
    "            partition_embeddings = model.encode(partitions)\n",
    "            # print(prompt_embedding.shape, partition_embeddings.shape)\n",
    "        else:\n",
    "            prompt_embedding = get_openai_embedding(prompt).reshape(-1, 1).T\n",
    "            partition_embeddings = np.array([get_openai_embedding(p) for p in partitions])\n",
    "            # print(prompt_embedding.shape, partition_embeddings.shape)\n",
    "\n",
    "\n",
    "        # Compute cosine similarity\n",
    "        similarities[i] = cosine_similarity(prompt_embedding, partition_embeddings)[0]\n",
    "\n",
    "        # Filter partitions based on threshold\n",
    "    filtered_partitions = [\n",
    "        {\"text\": partitions[i], \"score\": similarities[0][i], \"score2\": similarities[1][i]}\n",
    "        for i in range(len(partitions))\n",
    "        if similarities[0][i] > threshold\n",
    "    ]\n",
    "\n",
    "    # Sort by relevance (descending similarity)\n",
    "    filtered_partitions.sort(key=lambda x: x[\"score\"], reverse=True)\n",
    "\n",
    "    return filtered_partitions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127\n"
     ]
    }
   ],
   "source": [
    "A = \"\"\"/content/drive/MyDrive/Bee Wing Variation and Imaging/Wing Venation Computer Vision/data/all_wings_isolated/Osmia californica/UCSB-IZC00043780_R.JPG\n",
    "1/1 ━━━━━━━━━━━━━━━━━━━━ 3s 3s/step\n",
    "/content/drive/MyDrive/Bee Wing Variation and Imaging/Wing Venation Computer Vision/data/all_wings_isolated/Osmia californica/UCSB-IZC00043780_L.JPG\n",
    "1/1 ━━━━━━━━━━━━━━━━━━━━ 3s 3s/step\n",
    "/content/drive/MyDrive/Bee Wing Variation and Imaging/Wing Venation Computer Vision/data/all_wings_isolated/Agapostemon texanus/UCSB-IZC00036306_L.JPG\n",
    "1/1 ━━━━━━━━━━━━━━━━━━━━ 3s 3s/step\n",
    "/content/drive/MyDrive/Bee Wing Variation and Imaging/Wing Venation Computer Vision/data/all_wings_isolated/Agapostemon texanus/UCSB-IZC00030767_L.JPG\n",
    "1/1 ━━━━━━━━━━━━━━━━━━━━ 3s 3s/step\n",
    "/content/drive/MyDrive/Bee Wing Variation and Imaging/Wing Venation Computer Vision/data/all_wings_isolated/Agapostemon texanus/UCSB-IZC00036306_R.JPG\n",
    "1/1 ━━━━━━━━━━━━━━━━━━━━ 4s 4s/step\n",
    "/content/drive/MyDrive/Bee Wing Variation and Imaging/Wing Venation Computer Vision/data/all_wings_isolated/Agapostemon texanus/UCSB-IZC00030767_R.JPG\n",
    "1/1 ━━━━━━━━━━━━━━━━━━━━ 3s 3s/step\n",
    "/content/drive/MyDrive/Bee Wing Variation and Imaging/Wing Venation Computer Vision/data/all_wings_isolated/Agapostemon texanus/UCSB-IZC00030694_L.JPG\n",
    "1/1 ━━━━━━━━━━━━━━━━━━━━ 5s 5s/step\n",
    "/content/drive/MyDrive/Bee Wing Variation and Imaging/Wing Venation Computer Vision/data/all_wings_isolated/Agapostemon texanus/UCSB-IZC00030694_R.JPG\n",
    "1/1 ━━━━━━━━━━━━━━━━━━━━ 3s 3s/step\n",
    "/content/drive/MyDrive/Bee Wing Variation and Imaging/Wing Venation Computer Vision/data/all_wings_isolated/Agapostemon texanus/UCSB-IZC00037256_L.JPG\n",
    "1/1 ━━━━━━━━━━━━━━━━━━━━ 3s 3s/step\n",
    "/content/drive/MyDrive/Bee Wing Variation and Imaging/Wing Venation Computer Vision/data/all_wings_isolated/Agapostemon texanus/UCSB-IZC00037256_R.JPG\n",
    "1/1 ━━━━━━━━━━━━━━━━━━━━ 4s 4s/step\n",
    "/content/drive/MyDrive/Bee Wing Variation and Imaging/Wing Venation Computer Vision/data/all_wings_isolated/Agapostemon texanus/UCSB-IZC00041624_L.JPG\n",
    "1/1 ━━━━━━━━━━━━━━━━━━━━ 3s 3s/step\n",
    "/content/drive/MyDrive/Bee Wing Variation and Imaging/Wing Venation Computer Vision/data/all_wings_isolated/Agapostemon texanus/UCSB-IZC00041624_R.JPG\n",
    "1/1 ━━━━━━━━━━━━━━━━━━━━ 3s 3s/step\n",
    "/content/drive/MyDrive/Bee Wing Variation and Imaging/Wing Venation Computer Vision/data/all_wings_isolated/Andrena piperi/UCSB-IZC00044044_L.JPG\n",
    "1/1 ━━━━━━━━━━━━━━━━━━━━ 3s 3s/step\n",
    "/content/drive/MyDrive/Bee Wing Variation and Imaging/Wing Venation Computer Vision/data/all_wings_isolated/Andrena piperi/UCSB-IZC00044044_R.JPG\n",
    "1/1 ━━━━━━━━━━━━━━━━━━━━ 3s 3s/step\n",
    "/content/drive/MyDrive/Bee Wing Variation and Imaging/Wing Venation Computer Vision/data/all_wings_isolated/Anthophora californica/UCSB-IZC00009028_L.JPG\n",
    "1/1 ━━━━━━━━━━━━━━━━━━━━ 3s 3s/step\n",
    "/content/drive/MyDrive/Bee Wing Variation and Imaging/Wing Venation Computer Vision/data/all_wings_isolated/Anthophora californica/UCSB-IZC00043095_L.JPG\n",
    "1/1 ━━━━━━━━━━━━━━━━━━━━ 5s 5s/step\n",
    "/content/drive/MyDrive/Bee Wing Variation and Imaging/Wing Venation Computer Vision/data/all_wings_isolated/Anthophora californica/UCSB-IZC00009028_R.JPG\n",
    "1/1 ━━━━━━━━━━━━━━━━━━━━ 3s 3s/step\n",
    "/content/drive/MyDrive/Bee Wing Variation and Imaging/Wing Venation Computer Vision/data/all_wings_isolated/Anthophora californica/UCSB-IZC00043095_R.JPG\n",
    "1/1 ━━━━━━━━━━━━━━━━━━━━ 4s 4s/step\n",
    "/content/drive/MyDrive/Bee Wing Variation and Imaging/Wing Venation Computer Vision/data/all_wings_isolated/Anthophora californica/UCSB-IZC00064947_L.JPG\n",
    "1/1 ━━━━━━━━━━━━━━━━━━━━ 3s 3s/step\n",
    "/content/drive/MyDrive/Bee Wing Variation and Imaging/Wing Venation Computer Vision/data/all_wings_isolated/Anthophora californica/UCSB-IZC00064947_R.JPG\n",
    "1/1 ━━━━━━━━━━━━━━━━━━━━ 4s 4s/step\n",
    "/content/drive/MyDrive/Bee Wing Variation and Imaging/Wing Venation Computer Vision/data/all_wings_isolated/Anthophora californica/SBMNHENT0116662_L.JPG\n",
    "1/1 ━━━━━━━━━━━━━━━━━━━━ 3s 3s/step\n",
    "/content/drive/MyDrive/Bee Wing Variation and Imaging/Wing Venation Computer Vision/data/all_wings_isolated/Anthophora californica/SBMNHENT0116662_R.JPG\n",
    "1/1 ━━━━━━━━━━━━━━━━━━━━ 3s 3s/step\n",
    "/content/drive/MyDrive/Bee Wing Variation and Imaging/Wing Venation Computer Vision/data/all_wings_isolated/Anthophora californica/SBMNHENT0116667_R.JPG\n",
    "1/1 ━━━━━━━━━━━━━━━━━━━━ 3s 3s/step\n",
    "/content/drive/MyDrive/Bee Wing Variation and Imaging/Wing Venation Computer Vision/data/all_wings_isolated/Anthophora californica/SBMNHENT0116667_L.JPG\n",
    "1/1 ━━━━━━━━━━━━━━━━━━━━ 4s 4s/step\n",
    "/content/drive/MyDrive/Bee Wing Variation and Imaging/Wing Venation Computer Vision/data/all_wings_isolated/Anthophora curta/UCSB-IZC00030135_L.JPG\n",
    "1/1 ━━━━━━━━━━━━━━━━━━━━ 3s 3s/step\n",
    "/content/drive/MyDrive/Bee Wing Variation and Imaging/Wing Venation Computer Vision/data/all_wings_isolated/Anthophora curta/UCSB-IZC00030135_R.JPG\n",
    "1/1 ━━━━━━━━━━━━━━━━━━━━ 4s 4s/step\n",
    "/content/drive/MyDrive/Bee Wing Variation and Imaging/Wing Venation Computer Vision/data/all_wings_isolated/Anthophora curta/UCSB-IZC00064964_L.JPG\n",
    "1/1 ━━━━━━━━━━━━━━━━━━━━ 3s 3s/step\n",
    "/content/drive/MyDrive/Bee Wing Variation and Imaging/Wing Venation Computer Vision/data/all_wings_isolated/Anthophora curta/UCSB-IZC00064964_R.JPG\n",
    "1/1 ━━━━━━━━━━━━━━━━━━━━ 3s 3s/step\n",
    "/content/drive/MyDrive/Bee Wing Variation and Imaging/Wing Venation Computer Vision/data/all_wings_isolated/Anthophora curta/UCSB-IZC00045340_L.JPG\n",
    "1/1 ━━━━━━━━━━━━━━━━━━━━ 3s 3s/step\n",
    "/content/drive/MyDrive/Bee Wing Variation and Imaging/Wing Venation Computer Vision/data/all_wings_isolated/Anthophora curta/UCSB-IZC00045340_R.JPG\n",
    "1/1 ━━━━━━━━━━━━━━━━━━━━ 3s 3s/step\n",
    "/content/drive/MyDrive/Bee Wing Variation and Imaging/Wing Venation Computer Vision/data/all_wings_isolated/Anthophora curta/UCSB-IZC00045302_L.JPG\n",
    "1/1 ━━━━━━━━━━━━━━━━━━━━ 5s 5s/step\n",
    "/content/drive/MyDrive/Bee Wing Variation and Imaging/Wing Venation Computer Vision/data/all_wings_isolated/Anthophora curta/UCSB-IZC00045302_R.JPG\n",
    "1/1 ━━━━━━━━━━━━━━━━━━━━ 3s 3s/step\n",
    "/content/drive/MyDrive/Bee Wing Variation and Imaging/Wing Venation Computer Vision/data/all_wings_isolated/Anthophora curta/UCSB-IZC00038954_L.JPG\n",
    "1/1 ━━━━━━━━━━━━━━━━━━━━ 4s 4s/step\n",
    "/content/drive/MyDrive/Bee Wing Variation and Imaging/Wing Venation Computer Vision/data/all_wings_isolated/Anthophora curta/UCSB-IZC00038954_R.JPG\n",
    "1/1 ━━━━━━━━━━━━━━━━━━━━ 3s 3s/step\n",
    "/content/drive/MyDrive/Bee Wing Variation and Imaging/Wing Venation Computer Vision/data/all_wings_isolated/Anthophora urbana/UCSB-IZC00009010_L.JPG\n",
    "1/1 ━━━━━━━━━━━━━━━━━━━━ 4s 4s/step\n",
    "/content/drive/MyDrive/Bee Wing Variation and Imaging/Wing Venation Computer Vision/data/all_wings_isolated/Anthophora urbana/UCSB-IZC00009010_R.JPG\n",
    "1/1 ━━━━━━━━━━━━━━━━━━━━ 3s 3s/step\n",
    "/content/drive/MyDrive/Bee Wing Variation and Imaging/Wing Venation Computer Vision/data/all_wings_isolated/Anthophora urbana/UCSB-IZC00028548_L.JPG\n",
    "1/1 ━━━━━━━━━━━━━━━━━━━━ 4s 4s/step\n",
    "/content/drive/MyDrive/Bee Wing Variation and Imaging/Wing Venation Computer Vision/data/all_wings_isolated/Anthophora urbana/UCSB-IZC00028548_R.JPG\n",
    "1/1 ━━━━━━━━━━━━━━━━━━━━ 3s 3s/step\n",
    "/content/drive/MyDrive/Bee Wing Variation and Imaging/Wing Venation Computer Vision/data/all_wings_isolated/Anthophora urbana/UCSB-IZC00010375_L.JPG\n",
    "1/1 ━━━━━━━━━━━━━━━━━━━━ 3s 3s/step\n",
    "/content/drive/MyDrive/Bee Wing Variation and Imaging/Wing Venation Computer Vision/data/all_wings_isolated/Anthophora urbana/UCSB-IZC00010375_R.JPG\n",
    "1/1 ━━━━━━━━━━━━━━━━━━━━ 5s 5s/step\n",
    "/content/drive/MyDrive/Bee Wing Variation and Imaging/Wing Venation Computer Vision/data/all_wings_isolated/Anthophora urbana/UCSB-IZC00038622_L.JPG\n",
    "1/1 ━━━━━━━━━━━━━━━━━━━━ 3s 3s/step\n",
    "/content/drive/MyDrive/Bee Wing Variation and Imaging/Wing Venation Computer Vision/data/all_wings_isolated/Anthophora urbana/UCSB-IZC00038622_R.JPG\n",
    "1/1 ━━━━━━━━━━━━━━━━━━━━ 4s 4s/step\n",
    "/content/drive/MyDrive/Bee Wing Variation and Imaging/Wing Venation Computer Vision/data/all_wings_isolated/Anthophora urbana/UCSB-IZC00040909_L.JPG\n",
    "1/1 ━━━━━━━━━━━━━━━━━━━━ 3s 3s/step\n",
    "/content/drive/MyDrive/Bee Wing Variation and Imaging/Wing Venation Computer Vision/data/all_wings_isolated/Anthophora urbana/UCSB-IZC00040909_R.JPG\n",
    "1/1 ━━━━━━━━━━━━━━━━━━━━ 3s 3s/step\n",
    "/content/drive/MyDrive/Bee Wing Variation and Imaging/Wing Venation Computer Vision/data/all_wings_isolated/Apis mellifera/UCSB-IZC00010835_L.JPG\n",
    "1/1 ━━━━━━━━━━━━━━━━━━━━ 3s 3s/step\n",
    "/content/drive/MyDrive/Bee Wing Variation and Imaging/Wing Venation Computer Vision/data/all_wings_isolated/Apis mellifera/UCSB-IZC00010835_R.JPG\n",
    "1/1 ━━━━━━━━━━━━━━━━━━━━ 3s 3s/step\n",
    "/content/drive/MyDrive/Bee Wing Variation and Imaging/Wing Venation Computer Vision/data/all_wings_isolated/Apis mellifera/UCSB-IZC00010448_L.JPG\n",
    "1/1 ━━━━━━━━━━━━━━━━━━━━ 3s 3s/step\n",
    "/content/drive/MyDrive/Bee Wing Variation and Imaging/Wing Venation Computer Vision/data/all_wings_isolated/Apis mellifera/UCSB-IZC00010467_L.JPG\n",
    "1/1 ━━━━━━━━━━━━━━━━━━━━ 4s 4s/step\n",
    "/content/drive/MyDrive/Bee Wing Variation and Imaging/Wing Venation Computer Vision/data/all_wings_isolated/Apis mellifera/UCSB-IZC00010467_R.JPG\n",
    "1/1 ━━━━━━━━━━━━━━━━━━━━ 3s 3s/step\n",
    "/content/drive/MyDrive/Bee Wing Variation and Imaging/Wing Venation Computer Vision/data/all_wings_isolated/Apis mellifera/UCSB-IZC00010824_L.JPG\n",
    "1/1 ━━━━━━━━━━━━━━━━━━━━ 3s 3s/step\n",
    "/content/drive/MyDrive/Bee Wing Variation and Imaging/Wing Venation Computer Vision/data/all_wings_isolated/Apis mellifera/UCSB-IZC00010824_R.JPG\n",
    "1/1 ━━━━━━━━━━━━━━━━━━━━ 3s 3s/step\n",
    "/content/drive/MyDrive/Bee Wing Variation and Imaging/Wing Venation Computer Vision/data/all_wings_isolated/Apis mellifera/UCSB-IZC00010537_L.JPG\n",
    "1/1 ━━━━━━━━━━━━━━━━━━━━ 3s 3s/step\n",
    "/content/drive/MyDrive/Bee Wing Variation and Imaging/Wing Venation Computer Vision/data/all_wings_isolated/Apis mellifera/UCSB-IZC00010537_R.JPG\n",
    "1/1 ━━━━━━━━━━━━━━━━━━━━ 3s 3s/step\n",
    "/content/drive/MyDrive/Bee Wing Variation and Imaging/Wing Venation Computer Vision/data/all_wings_isolated/Apis mellifera/UCSB-IZC00010448_R.JPG\n",
    "1/1 ━━━━━━━━━━━━━━━━━━━━ 3s 3s/step\n",
    "/content/drive/MyDrive/Bee Wing Variation and Imaging/Wing Venation Computer Vision/data/all_wings_isolated/Bombus melanopygus/UCSB-IZC00009120_L.JPG\n",
    "1/1 ━━━━━━━━━━━━━━━━━━━━ 3s 3s/step\n",
    "/content/drive/MyDrive/Bee Wing Variation and Imaging/Wing Venation Computer Vision/data/all_wings_isolated/Bombus melanopygus/UCSB-IZC00009120_R.JPG\n",
    "1/1 ━━━━━━━━━━━━━━━━━━━━ 3s 3s/step\n",
    "/content/drive/MyDrive/Bee Wing Variation and Imaging/Wing Venation Computer Vision/data/all_wings_isolated/Bombus melanopygus/UCSB-IZC00028362_L.JPG\n",
    "1/1 ━━━━━━━━━━━━━━━━━━━━ 3s 3s/step\n",
    "/content/drive/MyDrive/Bee Wing Variation and Imaging/Wing Venation Computer Vision/data/all_wings_isolated/Bombus melanopygus/UCSB-IZC00028362_R.JPG\n",
    "1/1 ━━━━━━━━━━━━━━━━━━━━ 3s 3s/step\n",
    "/content/drive/MyDrive/Bee Wing Variation and Imaging/Wing Venation Computer Vision/data/all_wings_isolated/Bombus melanopygus/UCSB-IZC00035612_L.JPG\n",
    "1/1 ━━━━━━━━━━━━━━━━━━━━ 4s 4s/step\n",
    "/content/drive/MyDrive/Bee Wing Variation and Imaging/Wing Venation Computer Vision/data/all_wings_isolated/Bombus melanopygus/UCSB-IZC00035612_R.JPG\n",
    "1/1 ━━━━━━━━━━━━━━━━━━━━ 3s 3s/step\n",
    "/content/drive/MyDrive/Bee Wing Variation and Imaging/Wing Venation Computer Vision/data/all_wings_isolated/Bombus melanopygus/UCSB-IZC00064955_L.JPG\n",
    "1/1 ━━━━━━━━━━━━━━━━━━━━ 5s 5s/step\n",
    "/content/drive/MyDrive/Bee Wing Variation and Imaging/Wing Venation Computer Vision/data/all_wings_isolated/Bombus melanopygus/UCSB-IZC00064955_R.JPG\n",
    "1/1 ━━━━━━━━━━━━━━━━━━━━ 3s 3s/step\n",
    "/content/drive/MyDrive/Bee Wing Variation and Imaging/Wing Venation Computer Vision/data/all_wings_isolated/Bombus melanopygus/UCSB-IZC00035570_R.JPG\n",
    "1/1 ━━━━━━━━━━━━━━━━━━━━ 4s 4s/step\n",
    "/content/drive/MyDrive/Bee Wing Variation \"\"\"\n",
    "print(len(A.split(\"\\n\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "import random\n",
    "import time\n",
    "import traceback\n",
    "import pymupdf\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "def scrape_website(url):\n",
    "    \"\"\"\n",
    "    Scrapes text content from a given website URL.\n",
    "\n",
    "    Args:\n",
    "        url (str): The webpage URL.\n",
    "\n",
    "    Returns:\n",
    "        str: Extracted text content.\n",
    "    \"\"\"\n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "    session = requests.Session()\n",
    "    session.headers.update(headers)\n",
    "\n",
    "    if url.lower().endswith(\".pdf\"):\n",
    "        response = session.get(url)\n",
    "        response.raise_for_status()\n",
    "\n",
    "        with open(\"temp.pdf\", \"wb\") as f:\n",
    "            f.write(response.content)\n",
    "\n",
    "        # Use PyMuPDF to extract text\n",
    "        doc = pymupdf.open(\"temp.pdf\") # open a document\n",
    "        text = \"\"\n",
    "        for page in doc: # iterate the document pages\n",
    "            text += page.get_text()\n",
    "        os.remove(\"temp.pdf\")  # Clean up\n",
    "        return re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    else:\n",
    "\n",
    "        response = session.get(url)\n",
    "\n",
    "        response.raise_for_status()  # Ensure successful request\n",
    "\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "        # Extract meaningful content (paragraphs and headers)\n",
    "        text_elements = soup.find_all(['p', 'h1', 'h2', 'h3', 'h4', 'h5', 'h6'])\n",
    "        text = \" \".join(element.get_text() for element in text_elements)\n",
    "\n",
    "        # Remove extra spaces, newlines, and special characters\n",
    "        text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "\n",
    "        return text\n",
    "\n",
    "def split_text(text, chunk_size=300):\n",
    "    \"\"\"\n",
    "    Splits a large text into smaller partitions, ensuring each partition ends with a period.\n",
    "    \n",
    "    Args:\n",
    "        text (str): The full text.\n",
    "        chunk_size (int): Approximate number of words per partition.\n",
    "        \n",
    "    Returns:\n",
    "        list: List of text partitions.\n",
    "    \"\"\"\n",
    "    # First, split text into sentences.\n",
    "    # The regex splits after a period (keeping the period with the sentence).\n",
    "    sentences = re.split(r'(?<=[.])\\s+', text)\n",
    "    \n",
    "    partitions = []\n",
    "    current_partition = \"\"\n",
    "    current_word_count = 0\n",
    "\n",
    "    for sentence in sentences:\n",
    "        # Count words in the sentence.\n",
    "        sentence_word_count = len(sentence.split())\n",
    "        \n",
    "        # If adding this sentence exceeds the chunk size and there is content in the current partition,\n",
    "        # finalize the current partition.\n",
    "        if current_partition and current_word_count + sentence_word_count > chunk_size:\n",
    "            # Ensure the partition ends with a period.\n",
    "            if not current_partition.endswith('.'):\n",
    "                current_partition = current_partition.rstrip() + '.'\n",
    "            partitions.append(current_partition.strip())\n",
    "            # Start a new partition with the current sentence.\n",
    "            current_partition = sentence\n",
    "            current_word_count = sentence_word_count\n",
    "        else:\n",
    "            # Otherwise, add the sentence to the current partition.\n",
    "            if current_partition:\n",
    "                current_partition += \" \" + sentence\n",
    "            else:\n",
    "                current_partition = sentence\n",
    "            current_word_count += sentence_word_count\n",
    "\n",
    "    # Add the last partition.\n",
    "    if current_partition:\n",
    "        if not current_partition.endswith('.'):\n",
    "            current_partition = current_partition.rstrip() + '.'\n",
    "        partitions.append(current_partition.strip())\n",
    "\n",
    "    return partitions\n",
    "\n",
    "def similarity_search(prompt, partitions, threshold=0.5):\n",
    "    \"\"\"\n",
    "    Performs similarity search between a prompt and text partitions.\n",
    "\n",
    "    Args:\n",
    "        prompt (str): The search query.\n",
    "        partitions (list of str): List of partitioned text.\n",
    "        threshold (float): Minimum similarity score for filtering.\n",
    "\n",
    "    Returns:\n",
    "        list: Relevant partitions with similarity scores.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        model = SentenceTransformer(\"all-MiniLM-L6-v2\")  # Efficient embedding model\n",
    "        # Generate embeddings\n",
    "        prompt_embedding = model.encode([prompt])\n",
    "        partition_embeddings = model.encode(partitions)\n",
    "        # print(prompt_embedding.shape, partition_embeddings.shape)\n",
    "\n",
    "\n",
    "        # Compute cosine similarity\n",
    "        similarity = cosine_similarity(prompt_embedding, partition_embeddings)[0]\n",
    "\n",
    "            # Filter partitions based on threshold\n",
    "        filtered_partitions = [\n",
    "            {\"text\": partitions[i], \"score\": similarity[i]}\n",
    "            for i in range(len(partitions))\n",
    "            if similarity[i] > threshold\n",
    "        ]\n",
    "\n",
    "        # Sort by relevance (descending similarity)\n",
    "        # filtered_partitions.sort(key=lambda x: x[\"score\"], reverse=True)\n",
    "        filtered_partitions.sort(key=lambda item: item['score'], reverse=True)\n",
    "        return filtered_partitions\n",
    "    except Exception as e:\n",
    "        print(\"Error during similarity search:\", e)\n",
    "        traceback.print_exc()\n",
    "        return []\n",
    "\n",
    "\n",
    "def retrieve_evidence(prompt, url, threshold):\n",
    "    logs = {}\n",
    "    print(prompt, url)\n",
    "    try:\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Step 1: Scrape\n",
    "        scrape_start = time.time()\n",
    "        web_text = scrape_website(url)\n",
    "        scrape_end = time.time()\n",
    "        logs[\"scrape_time\"] = scrape_end - scrape_start\n",
    "        print(1)\n",
    "        # Step 2: Partition\n",
    "        split_start = time.time()\n",
    "        partitions = split_text(web_text)\n",
    "        split_end = time.time()\n",
    "        logs[\"split_time\"] = split_end - split_start\n",
    "        print(1)\n",
    "\n",
    "        # Step 3: Similarity search\n",
    "        sim_start = time.time()\n",
    "        results = similarity_search(prompt, partitions, threshold)\n",
    "        sim_end = time.time()\n",
    "        logs[\"similarity_search_time\"] = sim_end - sim_start\n",
    "        print(1)\n",
    "\n",
    "        # Step 4: Final selection\n",
    "        final_start = time.time()\n",
    "        final_results = random.sample(results, k=min(10, len(results)))\n",
    "        final_end = time.time()\n",
    "        logs[\"filtering_time\"] = final_end - final_start\n",
    "        print(1)\n",
    "\n",
    "        total_time = time.time() - start_time\n",
    "        logs[\"total_time\"] = total_time\n",
    "        logs[\"num_results\"] = len(final_results)\n",
    "        print(1)\n",
    "        \n",
    "        # Save log to file\n",
    "        log_dir = \"logs\"\n",
    "        os.makedirs(log_dir, exist_ok=True)\n",
    "        timestamp = int(time.time())\n",
    "        # log_path = os.path.join(log_dir, f\"logs/log_{timestamp}.json\")\n",
    "        # with open(log_path, \"w\") as f:\n",
    "        #     json.dump(logs, f, indent=2)\n",
    "\n",
    "        return final_results\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(e)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pymupdf\n",
      "  Obtaining dependency information for pymupdf from https://files.pythonhosted.org/packages/4e/55/43b64fa6cd048d2ea4574c045b5ac05d023254b91c2c703185f6f8a77b30/pymupdf-1.25.5-cp39-abi3-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading pymupdf-1.25.5-cp39-abi3-macosx_11_0_arm64.whl.metadata (3.4 kB)\n",
      "Downloading pymupdf-1.25.5-cp39-abi3-macosx_11_0_arm64.whl (18.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.6/18.6 MB\u001b[0m \u001b[31m306.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pymupdf\n",
      "Successfully installed pymupdf-1.25.5\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.11 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install --upgrade pymupdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': 'California Indian Food and Culture PHOEBE A. HEARST MUSEUM OF ANTHROPOLOGY Written and Designed by Nicole Mullen Contributors: Ira Jacknis, Barbara Takiguchi, and Liberty Winn. Sources Consulted The former exhibition: Food in California Indian Culture at the Phoebe A. Hearst Museum of Anthropology. Ortiz, Beverly, as told by Julia Parker. It Will Live Forever. Heyday Books, Berkeley, CA 1991. Jacknis, Ira. Food in California Indian Culture. Hearst Museum Publications, Berkeley, CA, 2004. Copyright © 2003. Phoebe A. Hearst Museum of Anthropology and the Regents of the University of California, Berkeley. All Rights Reserved. PHOEBE A. HEARST MUSEUM OF ANTHROPOLOGY Table of Contents 1. Glossary 2. Topics of Discussion for Lessons 3. Map of California Cultural Areas 4. General Overview of California Indians 5. Plants and Plant Processing 6. Animals and Hunting 7. Food from the Sea and Fishing 8. Insects 9. Beverages 10. Salt 11. Drying Foods 12. Earth Ovens 13. Serving Utensils 14. Food Storage 15. Feasts 16. Children 17. California Indian Myths 18. Review Questions and Activities PHOEBE A. HEARST MUSEUM OF ANTHROPOLOGY Glossary basin an open, shallow, usually round container used for holding liquids carbohydrate Carbohydrates are found in foods like pasta, cereals, breads, rice and potatoes, and serve as a major energy source in the diet. Central Valley The Central Valley lies between the Coast Mountain Ranges and the Sierra Nevada Mountain Ranges. It has two major river systems, the Sacramento and the San Joaquin. Much of it is flat, and looks like a broad, open plain. It forms the largest and most important farming area in California and produces a great variety of crops. cider the juice pressed out of apples or manzanita berries used for drinking condiment a seasoning such as salt or mustard used to flavor food PHOEBE A.',\n",
       "  'score': 0.37952667},\n",
       " {'text': \"* Will you make acorn bread for the feast? * What else will you prepare for people to eat? * Will you hunt game or catch fish? * What types of sea creatures or land animals will you catch and how will you catch them? Draw a picture of the feast to go along with your story. PHOEBE A. HEARST MUSEUM OF ANTHROPOLOGY Research Report Now that you have completed all the lessons on California Indian Food and Culture, pick one tribe to do a research report on. Go to your library and look up this California tribe. What else would you like to learn about this tribe that was not taught in these lessons? For example, what type of clothing did the tribe wear, what types of games did they play or what types of homes did they live in? Write a one-page report. Read your report out loud to the class so that all your class members can learn more about each tribe. TAKING THINGS A STEP FURTHER PHOEBE A. HEARST MUSEUM OF ANTHROPOLOGY Art Project The Mojave made spoons out of clay, like the ones pictured on this page. Bring in some air-dry clay from home and make your own spoon simular to a Mohave spoon. Let your spoons dry overnight, then paint them in a simular style to the ones you see pictured. You won't be able to eat with your spoon but you'll get an idea of what it was like to make your own utensils. Display your spoons in class. TAKING THINGS A STEP FURTHER California Indian Word Search Find the California Indian tribes listed below. Words are horizontal, vertical, diagonal and backward.\",\n",
       "  'score': 0.37060398},\n",
       " {'text': 'berry juices, ciders, nut drinks, and herbal teas PHOEBE A. HEARST MUSEUM OF ANTHROPOLOGY 7. California Indians often dried foods like fish and acorns. Drying is a way to preserve food so that is does not go bad. Can you think of two other types of foods that California Indians dried? wild grapes, berries, the peeled fruit of the prickly pear cactus corn, beans, muskmelons, wild plants, deer meat, seaweed cakes 8. What foods can you think of that are dried today? fruit roll-ups, beef jerky, dried fruits, raisins, beans, pumpkin seeds, sunflower seeds 9. What are some other ways of preserving food today and what are some of these foods? Canning is another way of preserving foods today, such as fruits and vegetables. 10. California Indians gathered salt from four sources. List one source California Indians gathered salt from. seaweed, grass, mineral deposits, and saline water (marshes, springs, lakes, and the ocean) 11. California Indians did not use forks.What types of utensils did Native Californians use to eat with? mussel shells, spoons, pots, ladles, baskets, bowls, trays, mats 12. California Indians stored dried acorns for the winter months. Name two types of storage containers that different California Indian groups used. baskets, pots, granaries 13. We have feasts for birthday parties and holidays.What types of important events did California Indians have feasts for? weddings, the first salmon arrival, acorn harvests 14. Children often helped their parents hunt and gather food. A what age did children learn to hunt or gather food? eight to ten years old.',\n",
       "  'score': 0.34642994},\n",
       " {'text': 'What foods can you think of that are dried today? 10. What are some other ways of preserving food today and what are some of these foods? 11. California Indians did not eat with forks. What types of utensils did Native Californians use to eat with? 12. California Indians stored dried acorns for the winter months. List two types of storage containers that different California Indian groups used. 13. We have feasts for birthday parties and holidays. What types of important events did California Indians have feasts for? 14. Children often helped their parents hunt and gather food. At what age did children learn to hunt or gather food? PHOEBE A. HEARST MUSEUM OF ANTHROPOLOGY Answer Sheet 1. California Indian women were responsible for gathering plants. List three plant foods California Indians ate. acorns, mushrooms, seaweed, flowering plants, seeds, berries, nuts, leaves, stems, roots 2. California Indian women boiled food in two ways. Name the two ways California Indians boiled foods. A clay or stone pot was filled with water and was placed over a fire until the water began to boil or by stone boiling, placing hot rocks that were heated by fire in baskets. 3. List three types of animals that California Indians ate. rabbits, squirrels, mice, quail, grouse, deer, elk, antelope, mountain sheep, and bear 4. California Indians that lived near the ocean, rivers and lakes fished often. What types of tools did they use to catch fish? hooks, harpoons, traps, and poison plants 5. Insects were high in protein and California Indians ate crickets, earthworms, and flies. How were insects gathered? They were gathered by hand or collected in baskets. 6. California Indians drank other beverages besides water. Name two types of beverages that California Indians drank.',\n",
       "  'score': 0.33896375},\n",
       " {'text': 'HEARST MUSEUM OF ANTHROPOLOGY Critical Thinking Questions California Indians lived in different ecological zones. Certain foods were available in one region but not in another. The Nisenan in the mountains traded black oak acorns and sugar-pine nuts for salt, game, and fish with those who lived by the sea. 1. What type of region do you live in? Do you live close to the sea or close to a river or do you live in the desert? 2. Are there foods available that are not from the region you live in? Where do you think these foods might come from? Why are they available? How are they preserved? 3. Acorns were a natural resource for California Indians. Can you think of some natural resources and how they are used? PHOEBE A. HEARST MUSEUM OF ANTHROPOLOGY Review Questions 1. California Indian women were responsible for gathering plants. List three plant foods California Indians ate. 2. California Indian women boiled food in two ways. Name the two ways California Indians boiled foods. 3. List three types of animals that California Indians ate. 4. California Indians that lived near the ocean, rivers and lakes fished often. What types of tools did they use to catch fish? 5. Insects were high in protein and California Indians ate earthworms, crickets, and flies. How were insects gathered? 6. California Indians drank other beverages besides water. Name two types of beverages that California Indians drank. 7. California Indians gathered salt from four sources. List one source California Indians gathered salt from. PHOEBE A. HEARST MUSEUM OF ANTHROPOLOGY 8. California Indians often dried foods like fish and acorns. Drying is a way to preserve food so that is does not go bad. Can you think of two other types of foods that California Indians dried? 9.',\n",
       "  'score': 0.33556485},\n",
       " {'text': 'Review questions are supplied at the end of the lessons to spur further discussion; as well as activities which can be used as the starting point for hands-on interaction with the material. Here are some questions you might ask before beginning the lesson to get students interested in the topic: What type of foods do you like to eat? What do you usually eat for dinner? Do you know how your food is cooked? What type of foods do you think California Indians ate? PHOEBE A. HEARST MUSEUM OF ANTHROPOLOGY California Indians were the first people to live in the area now known as California. California had a population of about 310,000 people when Spanish settlers reached the state in 1769. California tribes differed in the languages they spoke, the regions they lived in, and the foods that they ate. California Indians lived all over the state. They lived in different ecological zones. Some tribes lived near the sea, while others lived near rivers or lakes. There were also tribes that lived in the mountains, valleys, and the desert. Certain natural resources were found throughout the state. Groups from different ecological zones often traded. The Nisenan in the mountains traded black oak acorns and sugar-pine nuts for salt, game, fish, roots, grasses, beads, and shells with tribes living near the sea. Tribes living away from the ocean, such as the Cahuilla, traveled to the coast to fish and gather seafood and seaweed. California Indians PHOEBE A. HEARST MUSEUM OF ANTHROPOLOGY Plants California Indians ate many different plant foods; such as acorns, mushrooms, seaweed, and flowering plants. Seeds, berries, nuts, leaves, stems and roots were all parts of plants that were eaten. Plants were gathered from both the land and the sea.',\n",
       "  'score': 0.30869645},\n",
       " {'text': 'The Mohave dried corn, beans, muskmelons, and wild plants by the sun. Yurok, drying surf fish at the beach, Humboldt Co.; 1928 PHOEBE A. HEARST MUSEUM OF ANTHROPOLOGY Earth Ovens California Indians made different kinds of earth ovens to cook meat or plants in. A hole was dug in the earth and was lined with hot rocks. A layer of green leaves was then put over the hot rocks. Next, a thin layer of food, then another layer of leaves, then stones were added. These layers were repeated several times until the pit was filled to the top. Finally, a layer of soil was placed on the top and a fire was lit. The food was left to cook overnight. The Wintu used pits for baking salmon. The Pomo baked Indian potatoes and buckeyes in earth ovens. The Sierra Miwok baked greens and acorn bread in pits. Family of Essie Parrish (Kashaya Pomo) opening up a pit oven with acorn bread, Gualala River, Mendocino Co.; 1961 PHOEBE A. HEARST MUSEUM OF ANTHROPOLOGY Serving Utensils The most important utensil was a spoon. Knives were only used to prepare food. Forks were not used. The most common kind of spoon in the region was a large mussel shell. The Tübatulabal used antelope horn and wood to carve spoons with. The Mohave made spoons and ladles from clay. In the Klamath River Region spoons were made from elk antler. Hupa wooden spoon,Yurok elk antler spoon,Yurok deer bone spoon, Pomo mussel shell spoon, Mohave painted ceramic spoon PHOEBE A. HEARST MUSEUM OF ANTHROPOLOGY Food Storage Food was often stored in baskets and pots. The Yurok and the Pomo stored dried fish in large baskets. Southern groups such as the Cahuilla stored seeds and other foods in large clay pots.',\n",
       "  'score': 0.29847705},\n",
       " {'text': \"He saw a woman and he thought to himself, “How can I trick this woman into feeding me?” The woman did not know that Coyote was a great trickster. And so he walked up to the woman and said, “I can make a fine stew out of stones.” The woman asked, “How are you going to do that?” Coyote said, “Well, watch me!” He asked for the frying pan, and he put some rocks in it. Then he asked the woman for a little lard, and then he asked her for a little meat, and then a little garlic, and then a little tomato and onion, and some salt. He put each of the ingredients together in a frying pan. The woman was astonished at Coyote's way of cooking. He said, “That's my way of cooking stew!” He then ate all of the stew, leaving only the rocks. Coyote’s Stone Stew Writing Activity Now that you have read two California Indian myths, write your own! I. Illustrate your story with a picture. II. Divide your class into groups. Choose a myth from each group to act out in class. Each character should wear a mask to represent the character they are playing. Make these masks in class using paints, crayon, magic markers, paper plates and string. TAKING THINGS A STEP FURTHER PHOEBE A. HEARST MUSEUM OF ANTHROPOLOGY PHOEBE A. HEARST MUSEUM OF ANTHROPOLOGY TAKING THINGS A STEP FURTHER Writing Activity Write a short story about a feast you are going to prepare. What are you going to celebrate at this feast? Describe the foods you will serve and how to prepare them. Write about what you will cook in your earth oven and describe how you will cook your acorn mush.\",\n",
       "  'score': 0.29841775},\n",
       " {'text': 'They used bows and arrows, throwing sticks, clubs, spears, knives, slings, snares, nets, traps, pits, and dogs. Individuals or small groups of men usually did the hunting, although women and children helped catch rabbits, squirrels, mice, and other small game. When families left the village on food-gathering trips, the men hunted and the women collected plants. Eastern Pomo sling for killing ducks and mud hens, with basket and 24 clay balls Yurok Bow Hunting PHOEBE A. HEARST MUSEUM OF ANTHROPOLOGY Fish such as salmon, trout, and eel were often the main animal foods for many California Indians. Like acorns, fish can be dried and stored easily. Fish was eaten by tribes that lived close to rivers and streams. Groups living near the ocean ate clams, mussels, and crabs. Clamshells were often used to make beads. Groups living near the ocean also hunted sea mammals such as seals, sea lions, and sea otters. Although California Indians did not hunt whales, if one died and was washed ashore, it was eaten. Food from the Sea, Rivers and Lakes Karuk man fishing with an A-frame lifting net, Klamath River, Humboldt Co.; 1901-1907 Fishing Fish were caught with nets, hooks, harpoons, traps, and poison plants. Soaproot, buckeye nuts, and wild cucumber root can be used to capture fish. The plant or nut is mashed up and thrown into the water. The toxins in the plant para- lyze the fish and they float to the surface of the water. The fish are easily gathered up in this paralyzed state. The fish only stay paralyzed for a short time. If they are not gathered quickly enough, they come back to their senses and swim away.',\n",
       "  'score': 0.27081105},\n",
       " {'text': 'Southern tribes also stored large amounts of food in granaries made of twigs. Miwok granaries could hold up to 500 pounds of dry acorns! In the northern and eastern regions, pits were often used to store food. Pits were dug in the ground and lined with bark or grass. The Karuk stored dried fish in a pit at the back of the house. Miwok acorn cache, Calaveras Co.; 1906 PHOEBE A. HEARST MUSEUM OF ANTHROPOLOGY Feasts Native Californians looked forward to feasts where they had the chance to eat special foods. Neighboring groups met and socialized at feasts. Feasts were a time for trading, games, and dances. Many occasions called for feasts. Weddings were celebrated with feasts, as well as seasonal events such as the arrival of the first salmon or the acorn harvest. Feasts were often a time for trading foods after a harvest. Owens Valley Paiute traded salt, pine nuts, and other seeds for acorns and manzanita berries brought by the Western Mono, who lived nearby. Mary Eslick and Bertha Peters (Yurok sisters) cooking acorn soup, Ferndale, Humboldt Co.; 1996 PHOEBE A. HEARST MUSEUM OF ANTHROPOLOGY California Indians learned to gather food when they were about the same age as a fourth grader. As children played they also learned how to look for food. When Atsugewi children were about 8 years old they went food gathering with their parents. Boys went with their fathers and girls with their mothers. Girls played \"house\". Using sticks they pretended to dig roots and pound dirt like acorns. At the age of ten boys would hunt with their fathers and girls helped gather and prepare acorns with their mothers. Children Rae Navarro (Chumash) with an ear of roasted corn, Pow-wow, Santa Ynez, 1996 PHOEBE A.',\n",
       "  'score': 0.24789175},\n",
       " {'text': 'The toxins are not dangerous to humans and they do not change the taste of the fish or make it harmful to eat. PHOEBE A. HEARST MUSEUM OF ANTHROPOLOGY Salmon Recipe Ask an adult if they will help you make this recipe sometime when you are camping or at the beach. Ingredients: Salmon Preparation: 1. Build a fire. 2. Clean the fish and cut it in half or cut into meal size chunks. 3. Skewer the fish on a stick (preferably a sturdy willow). 4. Place the fish on a stick into the ground very close to the hot coals (like the picture shows.) 5. Turn the fish over, as the bottom will cook quickly. This is a great campfire meal. Serve with salad, a baked potato or corn on the cob. Salmon cooking over an alder wood fire, Yurok Brush Dance, mouth of the Klamath River, 1993 PHOEBE A. HEARST MUSEUM OF ANTHROPOLOGY PHOEBE A. HEARST MUSEUM OF ANTHROPOLOGY Yurok Fishing Equipment Yurok, salmon dip net Yurok, sea lion harpoon point Yurok, eel trap PHOEBE A. HEARST MUSEUM OF ANTHROPOLOGY Insects Many kinds of insects were gathered especially in the Great Basin Area. These included grasshoppers, crickets, caterpillars, earthworms, and flies. Insects are high in protein. They were gathered by hand and collected in baskets. The Maidu really liked dried locusts and crickets, and they traded them. The Nisenan preferred grasshoppers. The Eastern Mono ate caterpillars. Insects were often roasted over hot coals. The Maidu liked to eat grasshoppers that were dried or roasted. The Wintu usually boiled and dried grasshoppers. The Cauhilla liked to roast or dry crickets. Josepea Dick (Central Pomo) with a basket of army worms, near Ukiah, Mendocino Co.; 1904 PHOEBE A. HEARST MUSEUM OF ANTHROPOLOGY PHOEBE A.',\n",
       "  'score': 0.23022965},\n",
       " {'text': 'HEARST MUSEUM OF ANTHROPOLOGY mortar a stone or wood object used with a pestle as a bowl to pound acorns, seeds and nuts into flour natural resource goods supplied by nature such as water, timber and oil that are valuable to humans pestle a stone or wood object used along with a mortar to pound acorns, seeds and nuts into flour preserve to prepare (food) for future use, to prevent food from decaying or spoiling protein Protein is found in foods like beans, cheese, eggs, milk, yogurt, meat, poultry, fish and nuts and is important for growth and development. region a land surface having certain common geographical features such as the Rocky Mountain region, like an ecological zone PHOEBE A. HEARST MUSEUM OF ANTHROPOLOGY saline containing salt stone anvil a heavy, flat-topped stone on which acorns and other nuts are cracked open tannic acid a substance in acorns that tastes bitter and can make a person sick; the tannic acid is leached out of the acorns before cooking toxin a poisonous substance tribe a group of people with common social or cultural characteristics living near each other PHOEBE A. HEARST MUSEUM OF ANTHROPOLOGY Topics of Discussion for California Indian Food and Culture Lessons This kit is designed to explain the various ways in which Native Californians collected, prepared, and stored the foods they ate. There was a great variety of plant and wildlife resources available to these groups. This teaching guide will describe differences in food preferences and common lifeways patterns. You may teach the kit in lessons, organize it into chapters, or rearrange the materials to best suit your curriculum. A glossary is included; you may wish to supplement this list.',\n",
       "  'score': 0.22320762},\n",
       " {'text': 'One way was to boil the mush in a clay or stone pot over a fire. The other way to boil food was by stone boiling. Boiling baskets were often coated with a thin layer of acorn gruel. The gruel was like a glue that coated the basket so that no water would leak from it. Hot rocks the size of tennis balls were heated by fire. Then, they were put into baskets filled with water and acorn meal. Essie Parish (Kashaya Pomo) boiling acorn meal, shore of Gualala River, Mendocino Co.; 1960 PHOEBE A. HEARST MUSEUM OF ANTHROPOLOGY The stones were stirred in the baskets gently and slowly with a wooden paddle or looped stirrer. When the mixture began to boil it was cooked. The stones were then removed from the basket with wooden tongs. The mush that dried onto the rocks was a special treat that children liked to peel off and eat. These pieces were called \"acorn chips.\" Essie Parrish (Kashaya Pomo) cooking acorn bread on hot rocks, Kashaya Rancheria, Sonoma Co.; 1960 PHOEBE A. HEARST MUSEUM OF ANTHROPOLOGY Animals California Indians ate many different kinds of animals. Meat and fish provided them with the protein their bodies needed. Small animals were plentiful, and many groups ate rabbits, rats, squirrels, mice, and chipmunks. Water and land birds such as quail and grouse were also important food for California Indians, especially for those groups that lived in the marshy Central Valley. Large animals such as deer, elk, antelope, mountain sheep, and bear were also eaten, though they were more difficult to hunt and kill. PHOEBE A. HEARST MUSEUM OF ANTHROPOLOGY Hunters used many different tools to capture and kill the animals they ate.',\n",
       "  'score': 0.20167577}]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Step 1: Gather resources on Indian vegetarian cuisine for Research vegetarian dishes. for Weekly vegetarian meal plan with Indian and Italian dishes.\" \n",
    "url = \"https://hearstmuseum.berkeley.edu/wp-content/uploads/TeachingKit_CaliforniaIndianFoodAndCulture-1.pdf\"\n",
    "\n",
    "logs = {}\n",
    "start_time = time.time()\n",
    "\n",
    "# Step 1: Scrape\n",
    "scrape_start = time.time()\n",
    "web_text = scrape_website(url)\n",
    "scrape_end = time.time()\n",
    "logs[\"scrape_time\"] = scrape_end - scrape_start\n",
    "print(1)\n",
    "# Step 2: Partition\n",
    "split_start = time.time()\n",
    "partitions = split_text(web_text)\n",
    "split_end = time.time()\n",
    "logs[\"split_time\"] = split_end - split_start\n",
    "print(1)\n",
    "\n",
    "# Step 3: Similarity search\n",
    "sim_start = time.time()\n",
    "results = similarity_search(prompt, partitions, threshold=0.2)\n",
    "sim_end = time.time()\n",
    "logs[\"similarity_search_time\"] = sim_end - sim_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['California Indian Food and Culture PHOEBE A. HEARST MUSEUM OF ANTHROPOLOGY Written and Designed by Nicole Mullen Contributors: Ira Jacknis, Barbara Takiguchi, and Liberty Winn. Sources Consulted The former exhibition: Food in California Indian Culture at the Phoebe A. Hearst Museum of Anthropology. Ortiz, Beverly, as told by Julia Parker. It Will Live Forever. Heyday Books, Berkeley, CA 1991. Jacknis, Ira. Food in California Indian Culture. Hearst Museum Publications, Berkeley, CA, 2004. Copyright © 2003. Phoebe A. Hearst Museum of Anthropology and the Regents of the University of California, Berkeley. All Rights Reserved. PHOEBE A. HEARST MUSEUM OF ANTHROPOLOGY Table of Contents 1. Glossary 2. Topics of Discussion for Lessons 3. Map of California Cultural Areas 4. General Overview of California Indians 5. Plants and Plant Processing 6. Animals and Hunting 7. Food from the Sea and Fishing 8. Insects 9. Beverages 10. Salt 11. Drying Foods 12. Earth Ovens 13. Serving Utensils 14. Food Storage 15. Feasts 16. Children 17. California Indian Myths 18. Review Questions and Activities PHOEBE A. HEARST MUSEUM OF ANTHROPOLOGY Glossary basin an open, shallow, usually round container used for holding liquids carbohydrate Carbohydrates are found in foods like pasta, cereals, breads, rice and potatoes, and serve as a major energy source in the diet. Central Valley The Central Valley lies between the Coast Mountain Ranges and the Sierra Nevada Mountain Ranges. It has two major river systems, the Sacramento and the San Joaquin. Much of it is flat, and looks like a broad, open plain. It forms the largest and most important farming area in California and produces a great variety of crops. cider the juice pressed out of apples or manzanita berries used for drinking condiment a seasoning such as salt or mustard used to flavor food PHOEBE A.',\n",
       " \"HEARST MUSEUM OF ANTHROPOLOGY culture the sum of the language, customs, beliefs, and art considered characteristic of a particular group of people ecological zone an area with certain physical and/or cultural traits that make it different from other areas game wild animals hunted for food such as rabbits and deer granary structures often made out of plant materials, to hold acorns or other foods for storage Great Basin The Great Basin is a large desert region in the western United States. The basin covers land in California, Idaho, Nevada, Oregon, Utah and Wyoming. gruel thin boiled grain such as oatmeal PHOEBE A. HEARST MUSEUM OF ANTHROPOLOGY hammerstones small hand held stones used for cracking open acorns and other nuts Klamath River region The Klamath is California's second largest river. The Klamath River flows through the state's northwestern counties and to the ocean through Redwood National Park. leaching The process of using water to remove a poison from a plant, such as removing tannic acid from acorns so that they are safe to eat. meal coarsely ground grain, such as corn meal or dry cream of wheat milling stone a large long stone used to pound acorns into meal mineral deposit natural substances, usually having crystalline structures and a hardness, existing beneath the ground (such as salt) PHOEBE A.\",\n",
       " 'HEARST MUSEUM OF ANTHROPOLOGY mortar a stone or wood object used with a pestle as a bowl to pound acorns, seeds and nuts into flour natural resource goods supplied by nature such as water, timber and oil that are valuable to humans pestle a stone or wood object used along with a mortar to pound acorns, seeds and nuts into flour preserve to prepare (food) for future use, to prevent food from decaying or spoiling protein Protein is found in foods like beans, cheese, eggs, milk, yogurt, meat, poultry, fish and nuts and is important for growth and development. region a land surface having certain common geographical features such as the Rocky Mountain region, like an ecological zone PHOEBE A. HEARST MUSEUM OF ANTHROPOLOGY saline containing salt stone anvil a heavy, flat-topped stone on which acorns and other nuts are cracked open tannic acid a substance in acorns that tastes bitter and can make a person sick; the tannic acid is leached out of the acorns before cooking toxin a poisonous substance tribe a group of people with common social or cultural characteristics living near each other PHOEBE A. HEARST MUSEUM OF ANTHROPOLOGY Topics of Discussion for California Indian Food and Culture Lessons This kit is designed to explain the various ways in which Native Californians collected, prepared, and stored the foods they ate. There was a great variety of plant and wildlife resources available to these groups. This teaching guide will describe differences in food preferences and common lifeways patterns. You may teach the kit in lessons, organize it into chapters, or rearrange the materials to best suit your curriculum. A glossary is included; you may wish to supplement this list.',\n",
       " 'Review questions are supplied at the end of the lessons to spur further discussion; as well as activities which can be used as the starting point for hands-on interaction with the material. Here are some questions you might ask before beginning the lesson to get students interested in the topic: What type of foods do you like to eat? What do you usually eat for dinner? Do you know how your food is cooked? What type of foods do you think California Indians ate? PHOEBE A. HEARST MUSEUM OF ANTHROPOLOGY California Indians were the first people to live in the area now known as California. California had a population of about 310,000 people when Spanish settlers reached the state in 1769. California tribes differed in the languages they spoke, the regions they lived in, and the foods that they ate. California Indians lived all over the state. They lived in different ecological zones. Some tribes lived near the sea, while others lived near rivers or lakes. There were also tribes that lived in the mountains, valleys, and the desert. Certain natural resources were found throughout the state. Groups from different ecological zones often traded. The Nisenan in the mountains traded black oak acorns and sugar-pine nuts for salt, game, fish, roots, grasses, beads, and shells with tribes living near the sea. Tribes living away from the ocean, such as the Cahuilla, traveled to the coast to fish and gather seafood and seaweed. California Indians PHOEBE A. HEARST MUSEUM OF ANTHROPOLOGY Plants California Indians ate many different plant foods; such as acorns, mushrooms, seaweed, and flowering plants. Seeds, berries, nuts, leaves, stems and roots were all parts of plants that were eaten. Plants were gathered from both the land and the sea.',\n",
       " 'These plants supplied most of the carbohydrates for California Indians. Acorns were a popular food for many groups because during the harvest season they were plenti- ful and could be dried and stored easily for the winter. PHOEBE A. HEARST MUSEUM OF ANTHROPOLOGY Acorn Preparation Tools Pomo boiling stones, boiling basket, tongs, mush paddle soaproot brushes mortar looped stirrers PHOEBE A. HEARST MUSEUM OF ANTHROPOLOGY From centuries of experence, California Indian women learned how to gather the very best acorns from oak trees. Newly picked acorns are too soft to cook with. After being collected in baskets, the acorns had to be dried. Fresh acorns were usually stored for one year before they were used. Once the acorns dried, their shells were cracked open in order to reach the nutmeat. Acorn shells could be opened with small hammer stones and stone anvils. The shells were then removed by hand. Essie Parrish (Kashaya Pomo) cracking and shelling acorns, Sonoma Co.; 1960 Acorn Preparation PHOEBE A. HEARST MUSEUM OF ANTHROPOLOGY Winnowing Once all the acorns were cracked open it was time for winnowing. Like peanuts, acorns have a thin skin around them that needs to be removed. The acorns were put into a scoop shaped basket and rubbed by hand until the skins loosened. Then they were tossed into the air and their lightweight skins blew away in the breeze. The heavy acorns dropped back into the basket. winnowing basket and pine nuts PHOEBE A. HEARST MUSEUM OF ANTHROPOLOGY Acorn Pounding California Indian women used two types of tools to pound acorns. These tools are called mortars and pestles and milling stones. Acorn pounding was hard work. Women often spent an entire day pounding acorns into meal.',\n",
       " 'Women sang songs and made time for talking, teasing, and laughing while pounding acorns to make the chore fun. Essie Parrish (Kashaya Pomo) pounding acorn with a milling stone, Sonoma Co.; 1960 PHOEBE A. HEARST MUSEUM OF ANTHROPOLOGY Acorn Sifting After the acorn meal was pounded, it was then carefully sifted into a fine flour. A few handfuls of meal were put in the sifting basket and the basket was shaken carefully. The fine meal stuck to the basket and the heavier pieces rose to the surface. The larger pieces were put into another basket and the fine flour was swept into a third basket with a soaproot brush. The larger pieces were then pounded again with the next batch of acorns. Essie Parrish (Kashaya Pomo) sifting acorn, Sonoma Co.; 1960 PHOEBE A. HEARST MUSEUM OF ANTHROPOLOGY Leaching Acorns contain a poison called tannic acid. Once all the acorns were pounded into meal, the poison was removed in order to make them safe to eat. First, women scooped out a large basin in the ground. Next, they spread the acorn meal out in the basin and placed branches over it. Then, they poured water through the branches into the basin. Once the acorn meal no longer tasted bitter, the soaking could stop. After the acorn meal drained, it was scooped out of the hole by hand. This is called leaching. Now the meal was ready to be cooked. Essie Parish (Kashaya Pomo) leaching acorn meal, shore of Gualala River, Mendocino Co.; 1961 PHOEBE A. HEARST MUSEUM OF ANTHROPOLOGY Boiling Water and acorn meal were mixed together and boiled into a thin soup or thicker mush. There were two ways that California Indian women boiled food.',\n",
       " 'One way was to boil the mush in a clay or stone pot over a fire. The other way to boil food was by stone boiling. Boiling baskets were often coated with a thin layer of acorn gruel. The gruel was like a glue that coated the basket so that no water would leak from it. Hot rocks the size of tennis balls were heated by fire. Then, they were put into baskets filled with water and acorn meal. Essie Parish (Kashaya Pomo) boiling acorn meal, shore of Gualala River, Mendocino Co.; 1960 PHOEBE A. HEARST MUSEUM OF ANTHROPOLOGY The stones were stirred in the baskets gently and slowly with a wooden paddle or looped stirrer. When the mixture began to boil it was cooked. The stones were then removed from the basket with wooden tongs. The mush that dried onto the rocks was a special treat that children liked to peel off and eat. These pieces were called \"acorn chips.\" Essie Parrish (Kashaya Pomo) cooking acorn bread on hot rocks, Kashaya Rancheria, Sonoma Co.; 1960 PHOEBE A. HEARST MUSEUM OF ANTHROPOLOGY Animals California Indians ate many different kinds of animals. Meat and fish provided them with the protein their bodies needed. Small animals were plentiful, and many groups ate rabbits, rats, squirrels, mice, and chipmunks. Water and land birds such as quail and grouse were also important food for California Indians, especially for those groups that lived in the marshy Central Valley. Large animals such as deer, elk, antelope, mountain sheep, and bear were also eaten, though they were more difficult to hunt and kill. PHOEBE A. HEARST MUSEUM OF ANTHROPOLOGY Hunters used many different tools to capture and kill the animals they ate.',\n",
       " 'They used bows and arrows, throwing sticks, clubs, spears, knives, slings, snares, nets, traps, pits, and dogs. Individuals or small groups of men usually did the hunting, although women and children helped catch rabbits, squirrels, mice, and other small game. When families left the village on food-gathering trips, the men hunted and the women collected plants. Eastern Pomo sling for killing ducks and mud hens, with basket and 24 clay balls Yurok Bow Hunting PHOEBE A. HEARST MUSEUM OF ANTHROPOLOGY Fish such as salmon, trout, and eel were often the main animal foods for many California Indians. Like acorns, fish can be dried and stored easily. Fish was eaten by tribes that lived close to rivers and streams. Groups living near the ocean ate clams, mussels, and crabs. Clamshells were often used to make beads. Groups living near the ocean also hunted sea mammals such as seals, sea lions, and sea otters. Although California Indians did not hunt whales, if one died and was washed ashore, it was eaten. Food from the Sea, Rivers and Lakes Karuk man fishing with an A-frame lifting net, Klamath River, Humboldt Co.; 1901-1907 Fishing Fish were caught with nets, hooks, harpoons, traps, and poison plants. Soaproot, buckeye nuts, and wild cucumber root can be used to capture fish. The plant or nut is mashed up and thrown into the water. The toxins in the plant para- lyze the fish and they float to the surface of the water. The fish are easily gathered up in this paralyzed state. The fish only stay paralyzed for a short time. If they are not gathered quickly enough, they come back to their senses and swim away.',\n",
       " 'The toxins are not dangerous to humans and they do not change the taste of the fish or make it harmful to eat. PHOEBE A. HEARST MUSEUM OF ANTHROPOLOGY Salmon Recipe Ask an adult if they will help you make this recipe sometime when you are camping or at the beach. Ingredients: Salmon Preparation: 1. Build a fire. 2. Clean the fish and cut it in half or cut into meal size chunks. 3. Skewer the fish on a stick (preferably a sturdy willow). 4. Place the fish on a stick into the ground very close to the hot coals (like the picture shows.) 5. Turn the fish over, as the bottom will cook quickly. This is a great campfire meal. Serve with salad, a baked potato or corn on the cob. Salmon cooking over an alder wood fire, Yurok Brush Dance, mouth of the Klamath River, 1993 PHOEBE A. HEARST MUSEUM OF ANTHROPOLOGY PHOEBE A. HEARST MUSEUM OF ANTHROPOLOGY Yurok Fishing Equipment Yurok, salmon dip net Yurok, sea lion harpoon point Yurok, eel trap PHOEBE A. HEARST MUSEUM OF ANTHROPOLOGY Insects Many kinds of insects were gathered especially in the Great Basin Area. These included grasshoppers, crickets, caterpillars, earthworms, and flies. Insects are high in protein. They were gathered by hand and collected in baskets. The Maidu really liked dried locusts and crickets, and they traded them. The Nisenan preferred grasshoppers. The Eastern Mono ate caterpillars. Insects were often roasted over hot coals. The Maidu liked to eat grasshoppers that were dried or roasted. The Wintu usually boiled and dried grasshoppers. The Cauhilla liked to roast or dry crickets. Josepea Dick (Central Pomo) with a basket of army worms, near Ukiah, Mendocino Co.; 1904 PHOEBE A. HEARST MUSEUM OF ANTHROPOLOGY PHOEBE A.',\n",
       " 'HEARST MUSEUM OF ANTHROPOLOGY Beverages Drinks included water, berry juices, ciders, nut drinks, and herbal teas. Berry ciders and herbal teas were popular, especially as medicines. Berry juices were a favorite. The Pomo made juices from elderberries and manzanita berries. The Chukchansi Yokuts drank fresh wild grape juice. Many groups made drinks from pounded nuts. Tübatulabal mixed small seeds with cold water to make a thick gruel. Mothers often served the gruel to their children as a snack between meals. Mollie Cheepo (North Fork Mono) winnowing manzanita meal in preparation for making manzanita cider, Madera Co.; 1918 PHOEBE A. HEARST MUSEUM OF ANTHROPOLOGY Salt The most important mineral was salt, which was used by almost all California groups as a condiment to flavor food. A lump of salt might also be chewed by itself. In some areas salt was considered a medicine for curing stomachaches and colds. Salt came from seaweed, grass, mineral deposits, and saline water (from marshes, springs, lakes, and the ocean). Sara Smith Ballard (Coast Miwok) gathering salt with brush and shell spoon, Bodega Bay, Sonoma Co.; 1961 PHOEBE A. HEARST MUSEUM OF ANTHROPOLOGY Drying Foods Many foods were dried either by the sun, by fire, or by smoke before they were eaten. Drying food was a way to preserve it so it would not spoil. Food was also dried to be stored for the winter months. If fish like salmon was not eaten fresh, it was cut into strips and smoke-dried. Some groups also smoke-dried deer meat and acorns. The Tolowa dried their seaweed cakes in the sun. The Tübatulabal laid out wild grapes in the sun to make raisins. The Owens Valley Paiute dried berries. The Luiseño dried the peeled fruit of the prickly pear cactus in the sun.',\n",
       " 'The Mohave dried corn, beans, muskmelons, and wild plants by the sun. Yurok, drying surf fish at the beach, Humboldt Co.; 1928 PHOEBE A. HEARST MUSEUM OF ANTHROPOLOGY Earth Ovens California Indians made different kinds of earth ovens to cook meat or plants in. A hole was dug in the earth and was lined with hot rocks. A layer of green leaves was then put over the hot rocks. Next, a thin layer of food, then another layer of leaves, then stones were added. These layers were repeated several times until the pit was filled to the top. Finally, a layer of soil was placed on the top and a fire was lit. The food was left to cook overnight. The Wintu used pits for baking salmon. The Pomo baked Indian potatoes and buckeyes in earth ovens. The Sierra Miwok baked greens and acorn bread in pits. Family of Essie Parrish (Kashaya Pomo) opening up a pit oven with acorn bread, Gualala River, Mendocino Co.; 1961 PHOEBE A. HEARST MUSEUM OF ANTHROPOLOGY Serving Utensils The most important utensil was a spoon. Knives were only used to prepare food. Forks were not used. The most common kind of spoon in the region was a large mussel shell. The Tübatulabal used antelope horn and wood to carve spoons with. The Mohave made spoons and ladles from clay. In the Klamath River Region spoons were made from elk antler. Hupa wooden spoon,Yurok elk antler spoon,Yurok deer bone spoon, Pomo mussel shell spoon, Mohave painted ceramic spoon PHOEBE A. HEARST MUSEUM OF ANTHROPOLOGY Food Storage Food was often stored in baskets and pots. The Yurok and the Pomo stored dried fish in large baskets. Southern groups such as the Cahuilla stored seeds and other foods in large clay pots.',\n",
       " 'Southern tribes also stored large amounts of food in granaries made of twigs. Miwok granaries could hold up to 500 pounds of dry acorns! In the northern and eastern regions, pits were often used to store food. Pits were dug in the ground and lined with bark or grass. The Karuk stored dried fish in a pit at the back of the house. Miwok acorn cache, Calaveras Co.; 1906 PHOEBE A. HEARST MUSEUM OF ANTHROPOLOGY Feasts Native Californians looked forward to feasts where they had the chance to eat special foods. Neighboring groups met and socialized at feasts. Feasts were a time for trading, games, and dances. Many occasions called for feasts. Weddings were celebrated with feasts, as well as seasonal events such as the arrival of the first salmon or the acorn harvest. Feasts were often a time for trading foods after a harvest. Owens Valley Paiute traded salt, pine nuts, and other seeds for acorns and manzanita berries brought by the Western Mono, who lived nearby. Mary Eslick and Bertha Peters (Yurok sisters) cooking acorn soup, Ferndale, Humboldt Co.; 1996 PHOEBE A. HEARST MUSEUM OF ANTHROPOLOGY California Indians learned to gather food when they were about the same age as a fourth grader. As children played they also learned how to look for food. When Atsugewi children were about 8 years old they went food gathering with their parents. Boys went with their fathers and girls with their mothers. Girls played \"house\". Using sticks they pretended to dig roots and pound dirt like acorns. At the age of ten boys would hunt with their fathers and girls helped gather and prepare acorns with their mothers. Children Rae Navarro (Chumash) with an ear of roasted corn, Pow-wow, Santa Ynez, 1996 PHOEBE A.',\n",
       " \"HEARST MUSEUM OF ANTHROPOLOGY Woodrat and his sister were both married. His sister's husband was Red- headed-woodpecker. The two families lived in separate houses and had separate stores of food. All year round, Red-headed-woodpecker had plenty of acorns. Woodrat also had saved up a large store of acorns. Unfortunately, during the winter his store became exhausted. He heard his sister pounding acorns to make mush so he went over to visit her. After she had pounded the acorns into meal, she took it home and leached it in the usual manner. Then she placed the meal in the basket and began to cook mush with hot rocks. Woodrat thought he had better wash his hands so he could eat some of the mush when it was cooked. He did this and sat down on the opposite side of the fire and waited. However, Red-headed-woodpecker, who was a very stingy fellow came home. Woodrat's sister had, at times before this been generous and given Woodrat something to eat, but Red-headed-woodpecker would give him nothing. Woodrat is Refused Food by his Brother-in-law PHOEBE A. HEARST MUSEUM OF ANTHROPOLOGY Woodrat sat there and watched them eat but ate no food himself. Then he began to weep and he wept so long that his eyes became red and his eye-lids swelled until they nearly closed his eyes. He has had very small eyes ever since. When his sister began to cook mush he thought he was going to eat some, so he went out and washed his hands very thoroughly. This is the reason why he has always had white hands ever since. PHOEBE A. HEARST MUSEUM OF ANTHROPOLOGY Once Coyote was traveling along and he was very hun- gry.\",\n",
       " \"He saw a woman and he thought to himself, “How can I trick this woman into feeding me?” The woman did not know that Coyote was a great trickster. And so he walked up to the woman and said, “I can make a fine stew out of stones.” The woman asked, “How are you going to do that?” Coyote said, “Well, watch me!” He asked for the frying pan, and he put some rocks in it. Then he asked the woman for a little lard, and then he asked her for a little meat, and then a little garlic, and then a little tomato and onion, and some salt. He put each of the ingredients together in a frying pan. The woman was astonished at Coyote's way of cooking. He said, “That's my way of cooking stew!” He then ate all of the stew, leaving only the rocks. Coyote’s Stone Stew Writing Activity Now that you have read two California Indian myths, write your own! I. Illustrate your story with a picture. II. Divide your class into groups. Choose a myth from each group to act out in class. Each character should wear a mask to represent the character they are playing. Make these masks in class using paints, crayon, magic markers, paper plates and string. TAKING THINGS A STEP FURTHER PHOEBE A. HEARST MUSEUM OF ANTHROPOLOGY PHOEBE A. HEARST MUSEUM OF ANTHROPOLOGY TAKING THINGS A STEP FURTHER Writing Activity Write a short story about a feast you are going to prepare. What are you going to celebrate at this feast? Describe the foods you will serve and how to prepare them. Write about what you will cook in your earth oven and describe how you will cook your acorn mush.\",\n",
       " \"* Will you make acorn bread for the feast? * What else will you prepare for people to eat? * Will you hunt game or catch fish? * What types of sea creatures or land animals will you catch and how will you catch them? Draw a picture of the feast to go along with your story. PHOEBE A. HEARST MUSEUM OF ANTHROPOLOGY Research Report Now that you have completed all the lessons on California Indian Food and Culture, pick one tribe to do a research report on. Go to your library and look up this California tribe. What else would you like to learn about this tribe that was not taught in these lessons? For example, what type of clothing did the tribe wear, what types of games did they play or what types of homes did they live in? Write a one-page report. Read your report out loud to the class so that all your class members can learn more about each tribe. TAKING THINGS A STEP FURTHER PHOEBE A. HEARST MUSEUM OF ANTHROPOLOGY Art Project The Mojave made spoons out of clay, like the ones pictured on this page. Bring in some air-dry clay from home and make your own spoon simular to a Mohave spoon. Let your spoons dry overnight, then paint them in a simular style to the ones you see pictured. You won't be able to eat with your spoon but you'll get an idea of what it was like to make your own utensils. Display your spoons in class. TAKING THINGS A STEP FURTHER California Indian Word Search Find the California Indian tribes listed below. Words are horizontal, vertical, diagonal and backward.\",\n",
       " 'CHUMASH EASTERN MONO YANA MAIDU CAHUILLA MODOC SIERRA MIWOK LUISENO ATSUGEWI WINTU YUROK MOHAVE KARUK KUMEYAAY TUBATULABAL OHOLONE POMO SHASTA NISENAN YUKI P O M O L S I C T L Z O N E A S I T S C Z A O R F I Q T U R P H S M T L X N O H F T D A P E D A B S A O A L S I J E E U L J O S E R R K A A Z L L H U R W S K M B E C A H R O P T N E O E S G N G A P A F O P G H A A I U S M N E K E I N O F S C A R B O M L L L A S E G I W P M O L H M I O R H I L E A U A D A N I L I M P S J R C X Z W I D B N O H F I N H M D R I G U A T E O U A A T P A R E C A N D E N A E S P O K H Y L A R B V E R J A B B A L E S M O N A P E B L A M I L P R A D R J U E M P W C L Y O H A L P O K O R U Y H E A K M I D E R O H Y P V A L L N R A K A R U K R R A M I W O K O A B A I I V J U M K I N Y A A Y E M U K U L N S A N S C O A S P L C O P L D E P O S L E Z L L C R U S U L E A S T E R N M O N N I G A L B U T D E A M K I P H O M L P A E N R Q A N M K R B R P J E E F P O T N N L E I I E R A S B C O N D I M E N T O R I N W A K S B E E T K G P L U I S E N O K S H A S T A I N M A N Z A P R O P K D U M A N Z A M A I D U L O U R D E E K M Y PHOEBE A.',\n",
       " 'HEARST MUSEUM OF ANTHROPOLOGY Critical Thinking Questions California Indians lived in different ecological zones. Certain foods were available in one region but not in another. The Nisenan in the mountains traded black oak acorns and sugar-pine nuts for salt, game, and fish with those who lived by the sea. 1. What type of region do you live in? Do you live close to the sea or close to a river or do you live in the desert? 2. Are there foods available that are not from the region you live in? Where do you think these foods might come from? Why are they available? How are they preserved? 3. Acorns were a natural resource for California Indians. Can you think of some natural resources and how they are used? PHOEBE A. HEARST MUSEUM OF ANTHROPOLOGY Review Questions 1. California Indian women were responsible for gathering plants. List three plant foods California Indians ate. 2. California Indian women boiled food in two ways. Name the two ways California Indians boiled foods. 3. List three types of animals that California Indians ate. 4. California Indians that lived near the ocean, rivers and lakes fished often. What types of tools did they use to catch fish? 5. Insects were high in protein and California Indians ate earthworms, crickets, and flies. How were insects gathered? 6. California Indians drank other beverages besides water. Name two types of beverages that California Indians drank. 7. California Indians gathered salt from four sources. List one source California Indians gathered salt from. PHOEBE A. HEARST MUSEUM OF ANTHROPOLOGY 8. California Indians often dried foods like fish and acorns. Drying is a way to preserve food so that is does not go bad. Can you think of two other types of foods that California Indians dried? 9.',\n",
       " 'What foods can you think of that are dried today? 10. What are some other ways of preserving food today and what are some of these foods? 11. California Indians did not eat with forks. What types of utensils did Native Californians use to eat with? 12. California Indians stored dried acorns for the winter months. List two types of storage containers that different California Indian groups used. 13. We have feasts for birthday parties and holidays. What types of important events did California Indians have feasts for? 14. Children often helped their parents hunt and gather food. At what age did children learn to hunt or gather food? PHOEBE A. HEARST MUSEUM OF ANTHROPOLOGY Answer Sheet 1. California Indian women were responsible for gathering plants. List three plant foods California Indians ate. acorns, mushrooms, seaweed, flowering plants, seeds, berries, nuts, leaves, stems, roots 2. California Indian women boiled food in two ways. Name the two ways California Indians boiled foods. A clay or stone pot was filled with water and was placed over a fire until the water began to boil or by stone boiling, placing hot rocks that were heated by fire in baskets. 3. List three types of animals that California Indians ate. rabbits, squirrels, mice, quail, grouse, deer, elk, antelope, mountain sheep, and bear 4. California Indians that lived near the ocean, rivers and lakes fished often. What types of tools did they use to catch fish? hooks, harpoons, traps, and poison plants 5. Insects were high in protein and California Indians ate crickets, earthworms, and flies. How were insects gathered? They were gathered by hand or collected in baskets. 6. California Indians drank other beverages besides water. Name two types of beverages that California Indians drank.',\n",
       " 'berry juices, ciders, nut drinks, and herbal teas PHOEBE A. HEARST MUSEUM OF ANTHROPOLOGY 7. California Indians often dried foods like fish and acorns. Drying is a way to preserve food so that is does not go bad. Can you think of two other types of foods that California Indians dried? wild grapes, berries, the peeled fruit of the prickly pear cactus corn, beans, muskmelons, wild plants, deer meat, seaweed cakes 8. What foods can you think of that are dried today? fruit roll-ups, beef jerky, dried fruits, raisins, beans, pumpkin seeds, sunflower seeds 9. What are some other ways of preserving food today and what are some of these foods? Canning is another way of preserving foods today, such as fruits and vegetables. 10. California Indians gathered salt from four sources. List one source California Indians gathered salt from. seaweed, grass, mineral deposits, and saline water (marshes, springs, lakes, and the ocean) 11. California Indians did not use forks.What types of utensils did Native Californians use to eat with? mussel shells, spoons, pots, ladles, baskets, bowls, trays, mats 12. California Indians stored dried acorns for the winter months. Name two types of storage containers that different California Indian groups used. baskets, pots, granaries 13. We have feasts for birthday parties and holidays.What types of important events did California Indians have feasts for? weddings, the first salmon arrival, acorn harvests 14. Children often helped their parents hunt and gather food. A what age did children learn to hunt or gather food? eight to ten years old.']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Gather resources on Indian vegetarian cuisine for Research vegetarian dishes. for Weekly vegetarian meal plan with Indian and Italian dishes. https://hearstmuseum.berkeley.edu/wp-content/uploads/TeachingKit_CaliforniaIndianFoodAndCulture-1.pdf\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'text': 'Southern tribes also stored large amounts of food in granaries made of twigs. Miwok granaries could hold up to 500 pounds of dry acorns! In the northern and eastern regions, pits were often used to store food. Pits were dug in the ground and lined with bark or grass. The Karuk stored dried fish in a pit at the back of the house. Miwok acorn cache, Calaveras Co.; 1906 PHOEBE A. HEARST MUSEUM OF ANTHROPOLOGY Feasts Native Californians looked forward to feasts where they had the chance to eat special foods. Neighboring groups met and socialized at feasts. Feasts were a time for trading, games, and dances. Many occasions called for feasts. Weddings were celebrated with feasts, as well as seasonal events such as the arrival of the first salmon or the acorn harvest. Feasts were often a time for trading foods after a harvest. Owens Valley Paiute traded salt, pine nuts, and other seeds for acorns and manzanita berries brought by the Western Mono, who lived nearby. Mary Eslick and Bertha Peters (Yurok sisters) cooking acorn soup, Ferndale, Humboldt Co.; 1996 PHOEBE A. HEARST MUSEUM OF ANTHROPOLOGY California Indians learned to gather food when they were about the same age as a fourth grader. As children played they also learned how to look for food. When Atsugewi children were about 8 years old they went food gathering with their parents. Boys went with their fathers and girls with their mothers. Girls played \"house\". Using sticks they pretended to dig roots and pound dirt like acorns. At the age of ten boys would hunt with their fathers and girls helped gather and prepare acorns with their mothers. Children Rae Navarro (Chumash) with an ear of roasted corn, Pow-wow, Santa Ynez, 1996 PHOEBE A.',\n",
       "  'score': 0.24789175},\n",
       " {'text': 'berry juices, ciders, nut drinks, and herbal teas PHOEBE A. HEARST MUSEUM OF ANTHROPOLOGY 7. California Indians often dried foods like fish and acorns. Drying is a way to preserve food so that is does not go bad. Can you think of two other types of foods that California Indians dried? wild grapes, berries, the peeled fruit of the prickly pear cactus corn, beans, muskmelons, wild plants, deer meat, seaweed cakes 8. What foods can you think of that are dried today? fruit roll-ups, beef jerky, dried fruits, raisins, beans, pumpkin seeds, sunflower seeds 9. What are some other ways of preserving food today and what are some of these foods? Canning is another way of preserving foods today, such as fruits and vegetables. 10. California Indians gathered salt from four sources. List one source California Indians gathered salt from. seaweed, grass, mineral deposits, and saline water (marshes, springs, lakes, and the ocean) 11. California Indians did not use forks.What types of utensils did Native Californians use to eat with? mussel shells, spoons, pots, ladles, baskets, bowls, trays, mats 12. California Indians stored dried acorns for the winter months. Name two types of storage containers that different California Indian groups used. baskets, pots, granaries 13. We have feasts for birthday parties and holidays.What types of important events did California Indians have feasts for? weddings, the first salmon arrival, acorn harvests 14. Children often helped their parents hunt and gather food. A what age did children learn to hunt or gather food? eight to ten years old.',\n",
       "  'score': 0.34642994},\n",
       " {'text': \"HEARST MUSEUM OF ANTHROPOLOGY culture the sum of the language, customs, beliefs, and art considered characteristic of a particular group of people ecological zone an area with certain physical and/or cultural traits that make it different from other areas game wild animals hunted for food such as rabbits and deer granary structures often made out of plant materials, to hold acorns or other foods for storage Great Basin The Great Basin is a large desert region in the western United States. The basin covers land in California, Idaho, Nevada, Oregon, Utah and Wyoming. gruel thin boiled grain such as oatmeal PHOEBE A. HEARST MUSEUM OF ANTHROPOLOGY hammerstones small hand held stones used for cracking open acorns and other nuts Klamath River region The Klamath is California's second largest river. The Klamath River flows through the state's northwestern counties and to the ocean through Redwood National Park. leaching The process of using water to remove a poison from a plant, such as removing tannic acid from acorns so that they are safe to eat. meal coarsely ground grain, such as corn meal or dry cream of wheat milling stone a large long stone used to pound acorns into meal mineral deposit natural substances, usually having crystalline structures and a hardness, existing beneath the ground (such as salt) PHOEBE A.\",\n",
       "  'score': 0.12125036},\n",
       " {'text': 'The Mohave dried corn, beans, muskmelons, and wild plants by the sun. Yurok, drying surf fish at the beach, Humboldt Co.; 1928 PHOEBE A. HEARST MUSEUM OF ANTHROPOLOGY Earth Ovens California Indians made different kinds of earth ovens to cook meat or plants in. A hole was dug in the earth and was lined with hot rocks. A layer of green leaves was then put over the hot rocks. Next, a thin layer of food, then another layer of leaves, then stones were added. These layers were repeated several times until the pit was filled to the top. Finally, a layer of soil was placed on the top and a fire was lit. The food was left to cook overnight. The Wintu used pits for baking salmon. The Pomo baked Indian potatoes and buckeyes in earth ovens. The Sierra Miwok baked greens and acorn bread in pits. Family of Essie Parrish (Kashaya Pomo) opening up a pit oven with acorn bread, Gualala River, Mendocino Co.; 1961 PHOEBE A. HEARST MUSEUM OF ANTHROPOLOGY Serving Utensils The most important utensil was a spoon. Knives were only used to prepare food. Forks were not used. The most common kind of spoon in the region was a large mussel shell. The Tübatulabal used antelope horn and wood to carve spoons with. The Mohave made spoons and ladles from clay. In the Klamath River Region spoons were made from elk antler. Hupa wooden spoon,Yurok elk antler spoon,Yurok deer bone spoon, Pomo mussel shell spoon, Mohave painted ceramic spoon PHOEBE A. HEARST MUSEUM OF ANTHROPOLOGY Food Storage Food was often stored in baskets and pots. The Yurok and the Pomo stored dried fish in large baskets. Southern groups such as the Cahuilla stored seeds and other foods in large clay pots.',\n",
       "  'score': 0.29847705},\n",
       " {'text': 'One way was to boil the mush in a clay or stone pot over a fire. The other way to boil food was by stone boiling. Boiling baskets were often coated with a thin layer of acorn gruel. The gruel was like a glue that coated the basket so that no water would leak from it. Hot rocks the size of tennis balls were heated by fire. Then, they were put into baskets filled with water and acorn meal. Essie Parish (Kashaya Pomo) boiling acorn meal, shore of Gualala River, Mendocino Co.; 1960 PHOEBE A. HEARST MUSEUM OF ANTHROPOLOGY The stones were stirred in the baskets gently and slowly with a wooden paddle or looped stirrer. When the mixture began to boil it was cooked. The stones were then removed from the basket with wooden tongs. The mush that dried onto the rocks was a special treat that children liked to peel off and eat. These pieces were called \"acorn chips.\" Essie Parrish (Kashaya Pomo) cooking acorn bread on hot rocks, Kashaya Rancheria, Sonoma Co.; 1960 PHOEBE A. HEARST MUSEUM OF ANTHROPOLOGY Animals California Indians ate many different kinds of animals. Meat and fish provided them with the protein their bodies needed. Small animals were plentiful, and many groups ate rabbits, rats, squirrels, mice, and chipmunks. Water and land birds such as quail and grouse were also important food for California Indians, especially for those groups that lived in the marshy Central Valley. Large animals such as deer, elk, antelope, mountain sheep, and bear were also eaten, though they were more difficult to hunt and kill. PHOEBE A. HEARST MUSEUM OF ANTHROPOLOGY Hunters used many different tools to capture and kill the animals they ate.',\n",
       "  'score': 0.20167577},\n",
       " {'text': 'California Indian Food and Culture PHOEBE A. HEARST MUSEUM OF ANTHROPOLOGY Written and Designed by Nicole Mullen Contributors: Ira Jacknis, Barbara Takiguchi, and Liberty Winn. Sources Consulted The former exhibition: Food in California Indian Culture at the Phoebe A. Hearst Museum of Anthropology. Ortiz, Beverly, as told by Julia Parker. It Will Live Forever. Heyday Books, Berkeley, CA 1991. Jacknis, Ira. Food in California Indian Culture. Hearst Museum Publications, Berkeley, CA, 2004. Copyright © 2003. Phoebe A. Hearst Museum of Anthropology and the Regents of the University of California, Berkeley. All Rights Reserved. PHOEBE A. HEARST MUSEUM OF ANTHROPOLOGY Table of Contents 1. Glossary 2. Topics of Discussion for Lessons 3. Map of California Cultural Areas 4. General Overview of California Indians 5. Plants and Plant Processing 6. Animals and Hunting 7. Food from the Sea and Fishing 8. Insects 9. Beverages 10. Salt 11. Drying Foods 12. Earth Ovens 13. Serving Utensils 14. Food Storage 15. Feasts 16. Children 17. California Indian Myths 18. Review Questions and Activities PHOEBE A. HEARST MUSEUM OF ANTHROPOLOGY Glossary basin an open, shallow, usually round container used for holding liquids carbohydrate Carbohydrates are found in foods like pasta, cereals, breads, rice and potatoes, and serve as a major energy source in the diet. Central Valley The Central Valley lies between the Coast Mountain Ranges and the Sierra Nevada Mountain Ranges. It has two major river systems, the Sacramento and the San Joaquin. Much of it is flat, and looks like a broad, open plain. It forms the largest and most important farming area in California and produces a great variety of crops. cider the juice pressed out of apples or manzanita berries used for drinking condiment a seasoning such as salt or mustard used to flavor food PHOEBE A.',\n",
       "  'score': 0.37952667},\n",
       " {'text': 'These plants supplied most of the carbohydrates for California Indians. Acorns were a popular food for many groups because during the harvest season they were plenti- ful and could be dried and stored easily for the winter. PHOEBE A. HEARST MUSEUM OF ANTHROPOLOGY Acorn Preparation Tools Pomo boiling stones, boiling basket, tongs, mush paddle soaproot brushes mortar looped stirrers PHOEBE A. HEARST MUSEUM OF ANTHROPOLOGY From centuries of experence, California Indian women learned how to gather the very best acorns from oak trees. Newly picked acorns are too soft to cook with. After being collected in baskets, the acorns had to be dried. Fresh acorns were usually stored for one year before they were used. Once the acorns dried, their shells were cracked open in order to reach the nutmeat. Acorn shells could be opened with small hammer stones and stone anvils. The shells were then removed by hand. Essie Parrish (Kashaya Pomo) cracking and shelling acorns, Sonoma Co.; 1960 Acorn Preparation PHOEBE A. HEARST MUSEUM OF ANTHROPOLOGY Winnowing Once all the acorns were cracked open it was time for winnowing. Like peanuts, acorns have a thin skin around them that needs to be removed. The acorns were put into a scoop shaped basket and rubbed by hand until the skins loosened. Then they were tossed into the air and their lightweight skins blew away in the breeze. The heavy acorns dropped back into the basket. winnowing basket and pine nuts PHOEBE A. HEARST MUSEUM OF ANTHROPOLOGY Acorn Pounding California Indian women used two types of tools to pound acorns. These tools are called mortars and pestles and milling stones. Acorn pounding was hard work. Women often spent an entire day pounding acorns into meal.',\n",
       "  'score': 0.16247344},\n",
       " {'text': \"He saw a woman and he thought to himself, “How can I trick this woman into feeding me?” The woman did not know that Coyote was a great trickster. And so he walked up to the woman and said, “I can make a fine stew out of stones.” The woman asked, “How are you going to do that?” Coyote said, “Well, watch me!” He asked for the frying pan, and he put some rocks in it. Then he asked the woman for a little lard, and then he asked her for a little meat, and then a little garlic, and then a little tomato and onion, and some salt. He put each of the ingredients together in a frying pan. The woman was astonished at Coyote's way of cooking. He said, “That's my way of cooking stew!” He then ate all of the stew, leaving only the rocks. Coyote’s Stone Stew Writing Activity Now that you have read two California Indian myths, write your own! I. Illustrate your story with a picture. II. Divide your class into groups. Choose a myth from each group to act out in class. Each character should wear a mask to represent the character they are playing. Make these masks in class using paints, crayon, magic markers, paper plates and string. TAKING THINGS A STEP FURTHER PHOEBE A. HEARST MUSEUM OF ANTHROPOLOGY PHOEBE A. HEARST MUSEUM OF ANTHROPOLOGY TAKING THINGS A STEP FURTHER Writing Activity Write a short story about a feast you are going to prepare. What are you going to celebrate at this feast? Describe the foods you will serve and how to prepare them. Write about what you will cook in your earth oven and describe how you will cook your acorn mush.\",\n",
       "  'score': 0.29841775},\n",
       " {'text': \"HEARST MUSEUM OF ANTHROPOLOGY Woodrat and his sister were both married. His sister's husband was Red- headed-woodpecker. The two families lived in separate houses and had separate stores of food. All year round, Red-headed-woodpecker had plenty of acorns. Woodrat also had saved up a large store of acorns. Unfortunately, during the winter his store became exhausted. He heard his sister pounding acorns to make mush so he went over to visit her. After she had pounded the acorns into meal, she took it home and leached it in the usual manner. Then she placed the meal in the basket and began to cook mush with hot rocks. Woodrat thought he had better wash his hands so he could eat some of the mush when it was cooked. He did this and sat down on the opposite side of the fire and waited. However, Red-headed-woodpecker, who was a very stingy fellow came home. Woodrat's sister had, at times before this been generous and given Woodrat something to eat, but Red-headed-woodpecker would give him nothing. Woodrat is Refused Food by his Brother-in-law PHOEBE A. HEARST MUSEUM OF ANTHROPOLOGY Woodrat sat there and watched them eat but ate no food himself. Then he began to weep and he wept so long that his eyes became red and his eye-lids swelled until they nearly closed his eyes. He has had very small eyes ever since. When his sister began to cook mush he thought he was going to eat some, so he went out and washed his hands very thoroughly. This is the reason why he has always had white hands ever since. PHOEBE A. HEARST MUSEUM OF ANTHROPOLOGY Once Coyote was traveling along and he was very hun- gry.\",\n",
       "  'score': 0.10980332},\n",
       " {'text': 'What foods can you think of that are dried today? 10. What are some other ways of preserving food today and what are some of these foods? 11. California Indians did not eat with forks. What types of utensils did Native Californians use to eat with? 12. California Indians stored dried acorns for the winter months. List two types of storage containers that different California Indian groups used. 13. We have feasts for birthday parties and holidays. What types of important events did California Indians have feasts for? 14. Children often helped their parents hunt and gather food. At what age did children learn to hunt or gather food? PHOEBE A. HEARST MUSEUM OF ANTHROPOLOGY Answer Sheet 1. California Indian women were responsible for gathering plants. List three plant foods California Indians ate. acorns, mushrooms, seaweed, flowering plants, seeds, berries, nuts, leaves, stems, roots 2. California Indian women boiled food in two ways. Name the two ways California Indians boiled foods. A clay or stone pot was filled with water and was placed over a fire until the water began to boil or by stone boiling, placing hot rocks that were heated by fire in baskets. 3. List three types of animals that California Indians ate. rabbits, squirrels, mice, quail, grouse, deer, elk, antelope, mountain sheep, and bear 4. California Indians that lived near the ocean, rivers and lakes fished often. What types of tools did they use to catch fish? hooks, harpoons, traps, and poison plants 5. Insects were high in protein and California Indians ate crickets, earthworms, and flies. How were insects gathered? They were gathered by hand or collected in baskets. 6. California Indians drank other beverages besides water. Name two types of beverages that California Indians drank.',\n",
       "  'score': 0.33896375}]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieve_evidence(prompt, url, threshold=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
